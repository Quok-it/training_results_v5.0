+ echo 'Beginning trial 1 of 3'
Beginning trial 1 of 3
+ echo ':::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 381 8 GPU-[790,1006,726,892,498,419,47,753] '\''unknown'\'' DGXH100_008x08x004'
:::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 381 8 GPU-[790,1006,726,892,498,419,47,753] 'unknown' DGXH100_008x08x004
++ srun --ntasks=1 --container-name=single_stage_detector_381 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=single_stage_detector_381 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
:::GITCOMMITID  
+ srun -N1 -n1 --container-name=single_stage_detector_381 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on GPU-790
Clearing cache on GPU-1006
Clearing cache on GPU-753
Clearing cache on GPU-47
Clearing cache on GPU-726
Clearing cache on GPU-419
Clearing cache on GPU-498
Clearing cache on GPU-892
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector_381 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746041577908, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041577977, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041577990, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041578008, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041578097, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041578103, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041578118, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746041578119, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746041608'
RUNANDTIME_START 1746041608
+ srun --ntasks=64 --ntasks-per-node=8 --time=20 --container-name=single_stage_detector_381 --container-mounts=/mnt/localdisk5/mlperf/ssd/data/open-images-v6:/datasets/open-images-v6,/home/ubuntu/sd/ssd/log:/results,/mnt/localdisk5/mlperf/ssd/data/torch-home/hub/checkpoints:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 29: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 25: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 15: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 21: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 16: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 22: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 18: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 41: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 41, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 44: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 44, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 42: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 42, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 47: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 47, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 43: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 43, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 46: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 46, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 45: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 45, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 40: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 40, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 39: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 39, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 33: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 33, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 37: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 37, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 36: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 36, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
RANK 32: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 32, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 34: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 34, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 35: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 35, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 38: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 38, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 3: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 54: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 54, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 52: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 52, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 48: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 48, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 49: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 49, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 55: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 55, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 53: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 53, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 51: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 51, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 50: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 50, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 62: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 62, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 58: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 58, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 60: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 60, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 61: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 61, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 63: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 63, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 57: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 57, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 56: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 56, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:33:34 PM
RANK 59: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 59, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
| distributed init (rank 50): env://
| distributed init (rank 32): env://
| distributed init (rank 48): env://
| distributed init (rank 51): env://
| distributed init (rank 8): env://
| distributed init (rank 40): env://
| distributed init (rank 53): env://
| distributed init (rank 54): env://
| distributed init (rank 49): env://
| distributed init (rank 55): env://
| distributed init (rank 52): env://
| distributed init (rank 25): env://
| distributed init (rank 14): env://
| distributed init (rank 13): env://
| distributed init (rank 10): env://
| distributed init (rank 34): env://
| distributed init (rank 35): env://
| distributed init (rank 9): env://
| distributed init (rank 38): env://
| distributed init (rank 33): env://
| distributed init (rank 39): env://
| distributed init (rank 36): env://
| distributed init (rank 37): env://
| distributed init (rank 24): env://
| distributed init (rank 46): env://
| distributed init (rank 44): env://
| distributed init (rank 45): env://
| distributed init (rank 29): env://
| distributed init (rank 31): env://
| distributed init (rank 26): env://
| distributed init (rank 30): env://
| distributed init (rank 28): env://
| distributed init (rank 41): env://
| distributed init (rank 47): env://
| distributed init (rank 42): env://
| distributed init (rank 27): env://
| distributed init (rank 43): env://
| distributed init (rank 15): env://
| distributed init (rank 12): env://
| distributed init (rank 11): env://
| distributed init (rank 16): env://
| distributed init (rank 21): env://
| distributed init (rank 19): env://
| distributed init (rank 23): env://
| distributed init (rank 22): env://
| distributed init (rank 17): env://
| distributed init (rank 18): env://
| distributed init (rank 20): env://
| distributed init (rank 0): env://
[W430 19:33:40.134987185 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.057643274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.980262321 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.218103089 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 6): env://
| distributed init (rank 2): env://
[W430 19:33:40.714783407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.714808195 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 56): env://
[W430 19:33:40.043628274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.685799153 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 57): env://
[W430 19:33:40.687938874 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 60): env://
[W430 19:33:40.689662464 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.254560043 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.280412635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.283339430 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 58): env://
[W430 19:33:40.715011388 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.281735436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.311848411 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.168133619 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.248693275 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 7): env://
[W430 19:33:40.776415011 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.271354414 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 5): env://
| distributed init (rank 3): env://
[W430 19:33:40.793024372 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.793964668 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 4): env://
[W430 19:33:40.320441415 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.798856386 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 1): env://
[W430 19:33:40.808781557 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 63): env://
[W430 19:33:40.776020700 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 62): env://
[W430 19:33:40.794885760 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.377133659 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.163299577 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 59): env://
[W430 19:33:40.811008038 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 61): env://
[W430 19:33:40.816652784 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.345728085 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.465215007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.497146129 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.496615283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.480558471 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.503711852 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.507820422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.478297722 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.549403041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.351063342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.439214513 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.559100365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.454272125 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.377448821 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.608030875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:40.563619957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.496180905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.596271511 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.643507168 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.492916451 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.506836083 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.624262544 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.789413967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.667899120 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.676158559 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.827347160 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.913494909 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.986740779 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.000777172 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.012119199 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.091637267 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.905038533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:33:41.586261968 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
NCCL version 2.22.3+cuda12.6
:::MLLOG {"namespace": "", "time_ms": 1746041625318, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "retinanet", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746041625318, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746041625318, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746041625318, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746041625318, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746041625319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1746041625351, "event_type": "POINT_IN_TIME", "key": "seed", "value": 204463670, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1746041625351, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 4, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1746041625351, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1746041625351, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1746041625351, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=64, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=4, eval_batch_size=32, lr=0.0001, warmup_epochs=1, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=204463670, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=64, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=False, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=0, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], num_train_ranks=64, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1746041625361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625380, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625380, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625382, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625518, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625519, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625519, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625519, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625519, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625519, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625520, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625520, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625520, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625520, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625520, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625521, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625521, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625521, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625522, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625522, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625523, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625523, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625524, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625525, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625525, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625525, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625526, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625526, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625527, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625528, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625528, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625531, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625533, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625536, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625536, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625538, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625541, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625541, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625544, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625546, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625546, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625549, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625551, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625552, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625554, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625556, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625557, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625559, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625564, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625565, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625574, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625583, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625593, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625594, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041625603, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
:::MLLOG {"namespace": "", "time_ms": 1746041625612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
:::MLLOG {"namespace": "", "time_ms": 1746041625614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 21.4M/95.8M [00:00<00:00, 222MB/s] 52%|█████▏    | 49.5M/95.8M [00:00<00:00, 264MB/s] 78%|███████▊  | 74.8M/95.8M [00:00<00:00, 258MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 264MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 31%|███       | 29.8M/95.8M [00:00<00:00, 310MB/s] 62%|██████▏   | 59.4M/95.8M [00:00<00:00, 261MB/s] 89%|████████▊ | 84.9M/95.8M [00:00<00:00, 258MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 263MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 17%|█▋        | 16.6M/95.8M [00:00<00:00, 173MB/s] 35%|███▍      | 33.2M/95.8M [00:00<00:00, 169MB/s] 57%|█████▋    | 55.0M/95.8M [00:00<00:00, 195MB/s] 88%|████████▊ | 84.4M/95.8M [00:00<00:00, 239MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 221MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|█▊        | 17.6M/95.8M [00:00<00:00, 183MB/s] 37%|███▋      | 35.1M/95.8M [00:00<00:00, 173MB/s] 59%|█████▉    | 56.5M/95.8M [00:00<00:00, 195MB/s] 91%|█████████ | 87.2M/95.8M [00:00<00:00, 244MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 217MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 21.4M/95.8M [00:00<00:00, 224MB/s] 45%|████▍     | 42.8M/95.8M [00:00<00:00, 224MB/s] 69%|██████▉   | 66.2M/95.8M [00:00<00:00, 233MB/s] 93%|█████████▎| 88.6M/95.8M [00:00<00:00, 232MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 212MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 17%|█▋        | 16.5M/95.8M [00:00<00:00, 173MB/s] 43%|████▎     | 41.1M/95.8M [00:00<00:00, 222MB/s] 65%|██████▌   | 62.4M/95.8M [00:00<00:00, 201MB/s] 85%|████████▌ | 81.8M/95.8M [00:00<00:00, 193MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 206MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|█▊        | 17.8M/95.8M [00:00<00:00, 184MB/s] 37%|███▋      | 35.4M/95.8M [00:00<00:00, 137MB/s] 66%|██████▌   | 62.8M/95.8M [00:00<00:00, 195MB/s] 87%|████████▋ | 83.1M/95.8M [00:00<00:00, 200MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 198MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 23%|██▎       | 21.9M/95.8M [00:00<00:00, 228MB/s] 47%|████▋     | 44.9M/95.8M [00:00<00:00, 235MB/s] 70%|███████   | 67.4M/95.8M [00:00<00:00, 187MB/s] 94%|█████████▎| 89.8M/95.8M [00:00<00:00, 201MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 200MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 31%|███▏      | 30.1M/95.8M [00:00<00:00, 313MB/s] 63%|██████▎   | 60.0M/95.8M [00:00<00:00, 275MB/s] 90%|█████████ | 86.6M/95.8M [00:00<00:00, 198MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 202MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 21.2M/95.8M [00:00<00:00, 223MB/s] 46%|████▌     | 44.1M/95.8M [00:00<00:00, 232MB/s] 69%|██████▉   | 66.4M/95.8M [00:00<00:00, 200MB/s] 90%|████████▉ | 86.0M/95.8M [00:00<00:00, 199MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 202MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|█▊        | 17.0M/95.8M [00:00<00:00, 178MB/s] 44%|████▍     | 42.1M/95.8M [00:00<00:00, 228MB/s] 67%|██████▋   | 63.9M/95.8M [00:00<00:00, 185MB/s] 86%|████████▌ | 82.2M/95.8M [00:00<00:00, 176MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 197MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|██▌       | 24.0M/95.8M [00:00<00:00, 251MB/s] 50%|█████     | 48.0M/95.8M [00:00<00:00, 242MB/s] 74%|███████▍  | 71.1M/95.8M [00:00<00:00, 173MB/s] 95%|█████████▍| 90.9M/95.8M [00:00<00:00, 184MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 197MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|█▊        | 17.9M/95.8M [00:00<00:00, 185MB/s] 37%|███▋      | 35.6M/95.8M [00:00<00:00, 157MB/s] 59%|█████▉    | 56.5M/95.8M [00:00<00:00, 181MB/s] 79%|███████▊  | 75.4M/95.8M [00:00<00:00, 187MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 188MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▌        | 15.5M/95.8M [00:00<00:00, 161MB/s] 40%|████      | 38.5M/95.8M [00:00<00:00, 206MB/s] 61%|██████    | 58.2M/95.8M [00:00<00:00, 186MB/s] 82%|████████▏ | 78.4M/95.8M [00:00<00:00, 195MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 189MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|█▊        | 17.8M/95.8M [00:00<00:00, 184MB/s] 43%|████▎     | 40.8M/95.8M [00:00<00:00, 217MB/s] 66%|██████▌   | 62.8M/95.8M [00:00<00:00, 223MB/s] 88%|████████▊ | 84.1M/95.8M [00:00<00:00, 167MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 186MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|█▊        | 17.5M/95.8M [00:00<00:00, 183MB/s] 37%|███▋      | 35.0M/95.8M [00:00<00:00, 171MB/s] 60%|█████▉    | 57.2M/95.8M [00:00<00:00, 198MB/s] 80%|███████▉  | 76.2M/95.8M [00:00<00:00, 180MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 190MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 21.4M/95.8M [00:00<00:00, 224MB/s] 49%|████▉     | 46.9M/95.8M [00:00<00:00, 249MB/s] 74%|███████▎  | 70.6M/95.8M [00:00<00:00, 169MB/s] 95%|█████████▍| 90.6M/95.8M [00:00<00:00, 181MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 191MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 21.5M/95.8M [00:00<00:00, 225MB/s] 45%|████▍     | 43.0M/95.8M [00:00<00:00, 209MB/s] 67%|██████▋   | 64.5M/95.8M [00:00<00:00, 216MB/s] 89%|████████▉ | 85.2M/95.8M [00:00<00:00, 166MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 184MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.2M/95.8M [00:00<00:00, 139MB/s] 37%|███▋      | 35.6M/95.8M [00:00<00:00, 195MB/s] 57%|█████▋    | 54.2M/95.8M [00:00<00:00, 158MB/s] 77%|███████▋  | 73.6M/95.8M [00:00<00:00, 172MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 189MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 20.8M/95.8M [00:00<00:00, 217MB/s] 43%|████▎     | 41.5M/95.8M [00:00<00:00, 187MB/s] 62%|██████▏   | 59.6M/95.8M [00:00<00:00, 163MB/s] 85%|████████▌ | 81.5M/95.8M [00:00<00:00, 185MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 187MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 20.6M/95.8M [00:00<00:00, 216MB/s] 43%|████▎     | 41.4M/95.8M [00:00<00:00, 215MB/s] 65%|██████▍   | 61.9M/95.8M [00:00<00:00, 146MB/s] 92%|█████████▏| 87.8M/95.8M [00:00<00:00, 184MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 190MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 17%|█▋        | 16.4M/95.8M [00:00<00:00, 171MB/s] 37%|███▋      | 35.8M/95.8M [00:00<00:00, 189MB/s] 56%|█████▌    | 53.9M/95.8M [00:00<00:00, 178MB/s] 82%|████████▏ | 78.4M/95.8M [00:00<00:00, 208MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 186MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 21%|██        | 20.1M/95.8M [00:00<00:00, 210MB/s] 46%|████▌     | 44.1M/95.8M [00:00<00:00, 234MB/s] 69%|██████▉   | 66.5M/95.8M [00:00<00:00, 178MB/s] 90%|█████████ | 86.2M/95.8M [00:00<00:00, 187MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 182MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 20%|█▉        | 18.8M/95.8M [00:00<00:00, 195MB/s] 40%|████      | 38.8M/95.8M [00:00<00:00, 203MB/s] 61%|██████    | 58.2M/95.8M [00:00<00:00, 161MB/s] 82%|████████▏ | 78.8M/95.8M [00:00<00:00, 177MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 182MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 26%|██▋       | 25.2M/95.8M [00:00<00:00, 264MB/s] 53%|█████▎    | 50.5M/95.8M [00:00<00:00, 239MB/s] 77%|███████▋  | 73.5M/95.8M [00:00<00:00, 159MB/s] 99%|█████████▉| 94.8M/95.8M [00:00<00:00, 177MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 184MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|██▏       | 21.5M/95.8M [00:00<00:00, 225MB/s] 45%|████▍     | 43.0M/95.8M [00:00<00:00, 166MB/s] 66%|██████▌   | 62.8M/95.8M [00:00<00:00, 181MB/s] 84%|████████▍ | 80.9M/95.8M [00:00<00:00, 168MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 184MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 12%|█▏        | 11.2M/95.8M [00:00<00:00, 116MB/s] 24%|██▍       | 23.0M/95.8M [00:00<00:00, 120MB/s] 37%|███▋      | 35.4M/95.8M [00:00<00:00, 124MB/s] 60%|█████▉    | 57.0M/95.8M [00:00<00:00, 164MB/s] 81%|████████  | 77.4M/95.8M [00:00<00:00, 182MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 180MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 10%|█         | 9.62M/95.8M [00:00<00:00, 100MB/s] 24%|██▍       | 23.0M/95.8M [00:00<00:00, 123MB/s] 43%|████▎     | 40.9M/95.8M [00:00<00:00, 152MB/s] 66%|██████▌   | 63.0M/95.8M [00:00<00:00, 183MB/s] 86%|████████▌ | 82.2M/95.8M [00:00<00:00, 190MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 182MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 13%|█▎        | 12.6M/95.8M [00:00<00:00, 132MB/s] 28%|██▊       | 26.5M/95.8M [00:00<00:00, 139MB/s] 44%|████▍     | 42.1M/95.8M [00:00<00:00, 150MB/s] 70%|███████   | 67.5M/95.8M [00:00<00:00, 196MB/s] 90%|█████████ | 86.2M/95.8M [00:00<00:00, 178MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 180MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.4M/95.8M [00:00<00:00, 140MB/s] 29%|██▉       | 28.0M/95.8M [00:00<00:00, 148MB/s] 46%|████▌     | 44.0M/95.8M [00:00<00:00, 156MB/s] 64%|██████▍   | 61.6M/95.8M [00:00<00:00, 166MB/s] 86%|████████▋ | 82.8M/95.8M [00:00<00:00, 185MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 181MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|█▊        | 17.2M/95.8M [00:00<00:00, 181MB/s] 36%|███▌      | 34.5M/95.8M [00:00<00:00, 138MB/s] 57%|█████▋    | 54.6M/95.8M [00:00<00:00, 166MB/s] 76%|███████▌  | 72.9M/95.8M [00:00<00:00, 172MB/s] 99%|█████████▉| 95.0M/95.8M [00:00<00:00, 192MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 179MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|█▉        | 18.6M/95.8M [00:00<00:00, 195MB/s] 39%|███▉      | 37.2M/95.8M [00:00<00:00, 167MB/s] 58%|█████▊    | 55.2M/95.8M [00:00<00:00, 176MB/s] 79%|███████▊  | 75.4M/95.8M [00:00<00:00, 189MB/s] 98%|█████████▊| 93.6M/95.8M [00:00<00:00, 179MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 179MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 15%|█▍        | 14.2M/95.8M [00:00<00:00, 148MB/s] 36%|███▌      | 34.6M/95.8M [00:00<00:00, 186MB/s] 60%|██████    | 57.5M/95.8M [00:00<00:00, 210MB/s] 81%|████████  | 77.6M/95.8M [00:00<00:00, 163MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 178MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|██▌       | 24.4M/95.8M [00:00<00:00, 255MB/s] 51%|█████     | 48.8M/95.8M [00:00<00:00, 174MB/s] 70%|██████▉   | 66.9M/95.8M [00:00<00:00, 170MB/s] 88%|████████▊ | 83.9M/95.8M [00:00<00:00, 153MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 175MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 21%|██        | 20.2M/95.8M [00:00<00:00, 210MB/s] 42%|████▏     | 40.4M/95.8M [00:00<00:00, 147MB/s] 60%|█████▉    | 57.1M/95.8M [00:00<00:00, 158MB/s] 76%|███████▌  | 73.0M/95.8M [00:00<00:00, 160MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 178MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▌        | 15.1M/95.8M [00:00<00:00, 158MB/s] 37%|███▋      | 35.4M/95.8M [00:00<00:00, 189MB/s] 56%|█████▌    | 53.5M/95.8M [00:00<00:00, 141MB/s] 77%|███████▋  | 73.9M/95.8M [00:00<00:00, 164MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 177MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.6M/95.8M [00:00<00:00, 143MB/s] 28%|██▊       | 27.2M/95.8M [00:00<00:00, 138MB/s] 43%|████▎     | 41.2M/95.8M [00:00<00:00, 142MB/s] 66%|██████▌   | 63.4M/95.8M [00:00<00:00, 176MB/s] 84%|████████▍ | 80.2M/95.8M [00:00<00:00, 175MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 176MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.4M/95.8M [00:00<00:00, 138MB/s] 28%|██▊       | 26.9M/95.8M [00:00<00:00, 139MB/s] 42%|████▏     | 40.2M/95.8M [00:00<00:00, 134MB/s] 59%|█████▊    | 56.2M/95.8M [00:00<00:00, 144MB/s] 77%|███████▋  | 73.4M/95.8M [00:00<00:00, 156MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 170MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 13%|█▎        | 12.5M/95.8M [00:00<00:00, 130MB/s] 26%|██▌       | 25.0M/95.8M [00:00<00:00, 117MB/s] 45%|████▍     | 42.8M/95.8M [00:00<00:00, 147MB/s] 66%|██████▌   | 63.4M/95.8M [00:00<00:00, 173MB/s] 84%|████████▍ | 80.8M/95.8M [00:00<00:00, 176MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 171MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.8M/95.8M [00:00<00:00, 143MB/s] 31%|███       | 29.4M/95.8M [00:00<00:00, 155MB/s] 47%|████▋     | 45.4M/95.8M [00:00<00:00, 161MB/s] 63%|██████▎   | 60.8M/95.8M [00:00<00:00, 145MB/s] 82%|████████▏ | 78.8M/95.8M [00:00<00:00, 159MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 172MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.9M/95.8M [00:00<00:00, 145MB/s] 32%|███▏      | 30.8M/95.8M [00:00<00:00, 164MB/s] 48%|████▊     | 46.4M/95.8M [00:00<00:00, 148MB/s] 63%|██████▎   | 60.8M/95.8M [00:00<00:00, 142MB/s] 78%|███████▊  | 74.5M/95.8M [00:00<00:00, 142MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 171MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▎        | 13.1M/95.8M [00:00<00:00, 138MB/s] 28%|██▊       | 26.8M/95.8M [00:00<00:00, 141MB/s] 43%|████▎     | 41.5M/95.8M [00:00<00:00, 147MB/s] 60%|█████▉    | 57.4M/95.8M [00:00<00:00, 154MB/s] 78%|███████▊  | 74.5M/95.8M [00:00<00:00, 163MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 171MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.2M/95.8M [00:00<00:00, 139MB/s] 28%|██▊       | 26.5M/95.8M [00:00<00:00, 136MB/s] 41%|████      | 39.5M/95.8M [00:00<00:00, 123MB/s] 54%|█████▍    | 51.5M/95.8M [00:00<00:00, 117MB/s] 84%|████████▍ | 80.8M/95.8M [00:00<00:00, 180MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 170MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 15%|█▌        | 14.5M/95.8M [00:00<00:00, 150MB/s] 30%|███       | 28.9M/95.8M [00:00<00:00, 148MB/s] 46%|████▋     | 44.5M/95.8M [00:00<00:00, 154MB/s] 62%|██████▏   | 59.2M/95.8M [00:00<00:00, 140MB/s] 78%|███████▊  | 75.0M/95.8M [00:00<00:00, 148MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 170MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▋        | 15.6M/95.8M [00:00<00:00, 163MB/s] 33%|███▎      | 31.2M/95.8M [00:00<00:00, 139MB/s] 49%|████▉     | 47.0M/95.8M [00:00<00:00, 150MB/s] 68%|██████▊   | 65.2M/95.8M [00:00<00:00, 165MB/s] 85%|████████▍ | 81.2M/95.8M [00:00<00:00, 157MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 168MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 15%|█▍        | 14.1M/95.8M [00:00<00:00, 148MB/s] 33%|███▎      | 32.0M/95.8M [00:00<00:00, 171MB/s] 51%|█████     | 48.4M/95.8M [00:00<00:00, 129MB/s] 71%|███████   | 68.1M/95.8M [00:00<00:00, 154MB/s] 94%|█████████▍| 90.0M/95.8M [00:00<00:00, 178MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 169MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s]  9%|▉         | 8.88M/95.8M [00:00<00:00, 92.2MB/s] 19%|█▊        | 17.8M/95.8M [00:00<00:01, 78.2MB/s] 40%|███▉      | 37.9M/95.8M [00:00<00:00, 133MB/s]  59%|█████▉    | 56.4M/95.8M [00:00<00:00, 155MB/s] 76%|███████▌  | 72.5M/95.8M [00:00<00:00, 159MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 165MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.2M/95.8M [00:00<00:00, 138MB/s] 28%|██▊       | 27.2M/95.8M [00:00<00:00, 143MB/s] 43%|████▎     | 40.9M/95.8M [00:00<00:00, 139MB/s] 59%|█████▉    | 56.6M/95.8M [00:00<00:00, 148MB/s] 74%|███████▍  | 70.9M/95.8M [00:00<00:00, 142MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 168MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|█▊        | 17.2M/95.8M [00:00<00:00, 179MB/s] 36%|███▌      | 34.4M/95.8M [00:00<00:00, 144MB/s] 51%|█████     | 48.5M/95.8M [00:00<00:00, 124MB/s] 64%|██████▍   | 61.2M/95.8M [00:00<00:00, 127MB/s] 96%|█████████▋| 92.2M/95.8M [00:00<00:00, 190MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 168MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▋        | 15.8M/95.8M [00:00<00:00, 164MB/s] 33%|███▎      | 31.5M/95.8M [00:00<00:00, 151MB/s] 48%|████▊     | 46.0M/95.8M [00:00<00:00, 137MB/s] 62%|██████▏   | 59.2M/95.8M [00:00<00:00, 117MB/s] 93%|█████████▎| 89.5M/95.8M [00:00<00:00, 177MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 164MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 15%|█▌        | 14.8M/95.8M [00:00<00:00, 154MB/s] 31%|███       | 29.5M/95.8M [00:00<00:00, 154MB/s] 46%|████▌     | 44.2M/95.8M [00:00<00:00, 119MB/s] 67%|██████▋   | 63.9M/95.8M [00:00<00:00, 148MB/s] 86%|████████▌ | 82.5M/95.8M [00:00<00:00, 163MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 167MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 17%|█▋        | 16.6M/95.8M [00:00<00:00, 174MB/s] 35%|███▍      | 33.2M/95.8M [00:00<00:00, 153MB/s] 50%|█████     | 48.1M/95.8M [00:00<00:00, 150MB/s] 68%|██████▊   | 65.0M/95.8M [00:00<00:00, 160MB/s] 84%|████████▍ | 80.4M/95.8M [00:00<00:00, 146MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 165MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▋        | 15.6M/95.8M [00:00<00:00, 163MB/s] 33%|███▎      | 31.2M/95.8M [00:00<00:00, 147MB/s] 48%|████▊     | 45.5M/95.8M [00:00<00:00, 105MB/s] 69%|██████▊   | 65.8M/95.8M [00:00<00:00, 137MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 166MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|█▉        | 18.0M/95.8M [00:00<00:00, 186MB/s] 37%|███▋      | 35.8M/95.8M [00:00<00:00, 143MB/s] 52%|█████▏    | 50.0M/95.8M [00:00<00:00, 137MB/s] 66%|██████▌   | 63.4M/95.8M [00:00<00:00, 129MB/s] 87%|████████▋ | 83.5M/95.8M [00:00<00:00, 155MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 162MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 13%|█▎        | 12.6M/95.8M [00:00<00:00, 131MB/s] 26%|██▌       | 25.1M/95.8M [00:00<00:00, 107MB/s] 52%|█████▏    | 49.9M/95.8M [00:00<00:00, 169MB/s] 70%|██████▉   | 66.9M/95.8M [00:00<00:00, 155MB/s] 89%|████████▉ | 85.6M/95.8M [00:00<00:00, 168MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 167MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.4M/95.8M [00:00<00:00, 139MB/s] 28%|██▊       | 26.8M/95.8M [00:00<00:00, 131MB/s] 43%|████▎     | 40.8M/95.8M [00:00<00:00, 137MB/s] 63%|██████▎   | 60.6M/95.8M [00:00<00:00, 165MB/s] 80%|███████▉  | 76.5M/95.8M [00:00<00:00, 151MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 166MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▋        | 15.6M/95.8M [00:00<00:00, 163MB/s] 33%|███▎      | 31.2M/95.8M [00:00<00:00, 147MB/s] 47%|████▋     | 45.4M/95.8M [00:00<00:00, 119MB/s] 65%|██████▍   | 61.9M/95.8M [00:00<00:00, 136MB/s] 82%|████████▏ | 78.5M/95.8M [00:00<00:00, 149MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 160MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.6M/95.8M [00:00<00:00, 143MB/s] 28%|██▊       | 27.2M/95.8M [00:00<00:00, 134MB/s] 47%|████▋     | 45.0M/95.8M [00:00<00:00, 156MB/s] 63%|██████▎   | 60.1M/95.8M [00:00<00:00, 125MB/s] 84%|████████▍ | 80.8M/95.8M [00:00<00:00, 153MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 163MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 13%|█▎        | 12.9M/95.8M [00:00<00:00, 135MB/s] 27%|██▋       | 25.8M/95.8M [00:00<00:00, 128MB/s] 40%|███▉      | 38.0M/95.8M [00:00<00:00, 107MB/s] 54%|█████▎    | 51.2M/95.8M [00:00<00:00, 117MB/s] 69%|██████▉   | 66.4M/95.8M [00:00<00:00, 131MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 162MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|█▌        | 15.2M/95.8M [00:00<00:00, 160MB/s] 32%|███▏      | 30.5M/95.8M [00:00<00:00, 135MB/s] 46%|████▌     | 43.6M/95.8M [00:00<00:00, 104MB/s] 59%|█████▉    | 56.4M/95.8M [00:00<00:00, 113MB/s] 86%|████████▌ | 82.5M/95.8M [00:00<00:00, 162MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 159MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 13%|█▎        | 12.9M/95.8M [00:00<00:00, 134MB/s] 27%|██▋       | 25.8M/95.8M [00:00<00:00, 126MB/s] 40%|███▉      | 38.1M/95.8M [00:00<00:00, 127MB/s] 52%|█████▏    | 50.2M/95.8M [00:00<00:00, 94.4MB/s] 90%|█████████ | 86.6M/95.8M [00:00<00:00, 177MB/s] 100%|██████████| 95.8M/95.8M [00:00<00:00, 161MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.5M/95.8M [00:00<00:00, 141MB/s] 32%|███▏      | 30.6M/95.8M [00:00<00:00, 162MB/s] 48%|████▊     | 46.1M/95.8M [00:00<00:00, 114MB/s] 65%|██████▌   | 62.4M/95.8M [00:00<00:00, 131MB/s] 91%|█████████▏| 87.5M/95.8M [00:00<00:00, 172MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 161MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|█▍        | 13.6M/95.8M [00:00<00:00, 142MB/s] 31%|███▏      | 30.0M/95.8M [00:00<00:00, 159MB/s] 49%|████▊     | 46.5M/95.8M [00:00<00:00, 165MB/s] 65%|██████▌   | 62.4M/95.8M [00:00<00:00, 163MB/s] 81%|████████▏ | 78.0M/95.8M [00:00<00:00, 147MB/s] 97%|█████████▋| 93.0M/95.8M [00:00<00:00, 149MB/s]100%|██████████| 95.8M/95.8M [00:00<00:00, 154MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746041626309, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626309, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626310, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626311, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626311, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626313, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626313, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626315, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626316, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626318, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626318, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626321, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626333, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626336, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626336, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626339, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626339, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626342, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626342, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626344, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626366, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626389, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626400, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626400, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626400, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626403, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626403, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626405, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626405, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626408, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626408, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746041626411, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|█▊        | 17.6M/95.8M [00:00<00:00, 184MB/s] 37%|███▋      | 35.2M/95.8M [00:00<00:00, 122MB/s] 50%|█████     | 48.0M/95.8M [00:00<00:00, 123MB/s] 63%|██████▎   | 60.4M/95.8M [00:00<00:00, 121MB/s] 76%|███████▌  | 72.4M/95.8M [00:00<00:00, 99.3MB/s] 96%|█████████▌| 91.8M/95.8M [00:00<00:00, 126MB/s] 100%|██████████| 95.8M/95.8M [00:00<00:00, 125MB/s]
Casting convolutional layers to half
:::MLLOG {"namespace": "", "time_ms": 1746041626700, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1746041626700, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1746041626700, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1746041626700, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1746041626700, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1746041626700, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Time: 53.30315637588501 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1746041704432, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1746041704434, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 579}}
:::MLLOG {"namespace": "", "time_ms": 1746041704434, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1746041704434, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 13, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 636}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1746041704435, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:01:20    time: 0.0176  data: 0.0001  max mem: 13749
Epoch: [0]  [  20/4572]  eta: 0:01:38    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [  40/4572]  eta: 0:01:38    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [  60/4572]  eta: 0:01:38    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [  80/4572]  eta: 0:01:41    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [0]  [ 100/4572]  eta: 0:01:42    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0]  [ 120/4572]  eta: 0:01:41    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [ 140/4572]  eta: 0:01:42    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [ 160/4572]  eta: 0:01:41    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [ 180/4572]  eta: 0:01:41    time: 0.0233  data: 0.0210  max mem: 13749
Epoch: [0]  [ 200/4572]  eta: 0:01:40    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [ 220/4572]  eta: 0:01:39    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [ 240/4572]  eta: 0:01:39    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [0]  [ 260/4572]  eta: 0:01:38    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [ 280/4572]  eta: 0:01:38    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 300/4572]  eta: 0:01:37    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [ 320/4572]  eta: 0:01:37    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 340/4572]  eta: 0:01:36    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [ 360/4572]  eta: 0:01:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 380/4572]  eta: 0:01:36    time: 0.0250  data: 0.0226  max mem: 13749
Epoch: [0]  [ 400/4572]  eta: 0:01:36    time: 0.0253  data: 0.0229  max mem: 13749
Epoch: [0]  [ 420/4572]  eta: 0:01:35    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [0]  [ 440/4572]  eta: 0:01:35    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [ 460/4572]  eta: 0:01:34    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [ 480/4572]  eta: 0:01:34    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [ 500/4572]  eta: 0:01:34    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 520/4572]  eta: 0:01:33    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [ 540/4572]  eta: 0:01:33    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [ 560/4572]  eta: 0:01:32    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [ 580/4572]  eta: 0:01:32    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [ 600/4572]  eta: 0:01:31    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [ 620/4572]  eta: 0:01:31    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [ 640/4572]  eta: 0:01:30    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [ 660/4572]  eta: 0:01:30    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [ 680/4572]  eta: 0:01:29    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 700/4572]  eta: 0:01:29    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 720/4572]  eta: 0:01:28    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [ 740/4572]  eta: 0:01:28    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [ 760/4572]  eta: 0:01:28    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [ 780/4572]  eta: 0:01:27    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [ 800/4572]  eta: 0:01:27    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [ 820/4572]  eta: 0:01:26    time: 0.0230  data: 0.0212  max mem: 13749
Epoch: [0]  [ 840/4572]  eta: 0:01:26    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [ 860/4572]  eta: 0:01:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [ 880/4572]  eta: 0:01:25    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [ 900/4572]  eta: 0:01:24    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 920/4572]  eta: 0:01:24    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [ 940/4572]  eta: 0:01:23    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [ 960/4572]  eta: 0:01:23    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 980/4572]  eta: 0:01:22    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [0]  [1000/4572]  eta: 0:01:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1020/4572]  eta: 0:01:21    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [1040/4572]  eta: 0:01:21    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1060/4572]  eta: 0:01:20    time: 0.0244  data: 0.0228  max mem: 13749
Epoch: [0]  [1080/4572]  eta: 0:01:20    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [0]  [1100/4572]  eta: 0:01:20    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [1120/4572]  eta: 0:01:19    time: 0.0236  data: 0.0219  max mem: 13749
Epoch: [0]  [1140/4572]  eta: 0:01:19    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [0]  [1160/4572]  eta: 0:01:18    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1180/4572]  eta: 0:01:18    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1200/4572]  eta: 0:01:17    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1220/4572]  eta: 0:01:17    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1240/4572]  eta: 0:01:16    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [1260/4572]  eta: 0:01:16    time: 0.0246  data: 0.0232  max mem: 13749
Epoch: [0]  [1280/4572]  eta: 0:01:15    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [1300/4572]  eta: 0:01:15    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [0]  [1320/4572]  eta: 0:01:14    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [0]  [1340/4572]  eta: 0:01:14    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [1360/4572]  eta: 0:01:13    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1380/4572]  eta: 0:01:13    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [1400/4572]  eta: 0:01:13    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1420/4572]  eta: 0:01:12    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [1440/4572]  eta: 0:01:12    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [0]  [1460/4572]  eta: 0:01:11    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [0]  [1480/4572]  eta: 0:01:11    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [0]  [1500/4572]  eta: 0:01:10    time: 0.0249  data: 0.0234  max mem: 13749
Epoch: [0]  [1520/4572]  eta: 0:01:10    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1540/4572]  eta: 0:01:09    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [1560/4572]  eta: 0:01:09    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1580/4572]  eta: 0:01:08    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [1600/4572]  eta: 0:01:08    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [1620/4572]  eta: 0:01:07    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [1640/4572]  eta: 0:01:07    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1660/4572]  eta: 0:01:07    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1680/4572]  eta: 0:01:06    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1700/4572]  eta: 0:01:06    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1720/4572]  eta: 0:01:05    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [1740/4572]  eta: 0:01:05    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1760/4572]  eta: 0:01:04    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [1780/4572]  eta: 0:01:04    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [1800/4572]  eta: 0:01:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [1820/4572]  eta: 0:01:03    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [1840/4572]  eta: 0:01:02    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [1860/4572]  eta: 0:01:02    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [0]  [1880/4572]  eta: 0:01:01    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [0]  [1900/4572]  eta: 0:01:01    time: 0.0248  data: 0.0232  max mem: 13749
Epoch: [0]  [1920/4572]  eta: 0:01:01    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [1940/4572]  eta: 0:01:00    time: 0.0245  data: 0.0231  max mem: 13749
Epoch: [0]  [1960/4572]  eta: 0:01:00    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [1980/4572]  eta: 0:00:59    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [0]  [2000/4572]  eta: 0:00:59    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [2020/4572]  eta: 0:00:58    time: 0.0223  data: 0.0204  max mem: 13749
Epoch: [0]  [2040/4572]  eta: 0:00:58    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [2060/4572]  eta: 0:00:57    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [2080/4572]  eta: 0:00:57    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2100/4572]  eta: 0:00:56    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [0]  [2120/4572]  eta: 0:00:56    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2140/4572]  eta: 0:00:56    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [2160/4572]  eta: 0:00:55    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [2180/4572]  eta: 0:00:55    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [2200/4572]  eta: 0:00:54    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2220/4572]  eta: 0:00:54    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2240/4572]  eta: 0:00:53    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [2260/4572]  eta: 0:00:53    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2280/4572]  eta: 0:00:52    time: 0.0226  data: 0.0209  max mem: 13749
Epoch: [0]  [2300/4572]  eta: 0:00:52    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [2320/4572]  eta: 0:00:51    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2340/4572]  eta: 0:00:51    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [2360/4572]  eta: 0:00:50    time: 0.0244  data: 0.0219  max mem: 13749
Epoch: [0]  [2380/4572]  eta: 0:00:50    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [2400/4572]  eta: 0:00:50    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [2420/4572]  eta: 0:00:49    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2440/4572]  eta: 0:00:49    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [0]  [2460/4572]  eta: 0:00:48    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [2480/4572]  eta: 0:00:48    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [0]  [2500/4572]  eta: 0:00:47    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [2520/4572]  eta: 0:00:47    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [0]  [2540/4572]  eta: 0:00:46    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [0]  [2560/4572]  eta: 0:00:46    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [0]  [2580/4572]  eta: 0:00:45    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2600/4572]  eta: 0:00:45    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2620/4572]  eta: 0:00:44    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2640/4572]  eta: 0:00:44    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2660/4572]  eta: 0:00:44    time: 0.0255  data: 0.0239  max mem: 13749
Epoch: [0]  [2680/4572]  eta: 0:00:43    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2700/4572]  eta: 0:00:43    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2720/4572]  eta: 0:00:42    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2740/4572]  eta: 0:00:42    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [2760/4572]  eta: 0:00:41    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2780/4572]  eta: 0:00:41    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2800/4572]  eta: 0:00:40    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [2820/4572]  eta: 0:00:40    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [2840/4572]  eta: 0:00:39    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [2860/4572]  eta: 0:00:39    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2880/4572]  eta: 0:00:38    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [2900/4572]  eta: 0:00:38    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [2920/4572]  eta: 0:00:38    time: 0.0238  data: 0.0218  max mem: 13749
Epoch: [0]  [2940/4572]  eta: 0:00:37    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [2960/4572]  eta: 0:00:37    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2980/4572]  eta: 0:00:36    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [3000/4572]  eta: 0:00:36    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3020/4572]  eta: 0:00:35    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3040/4572]  eta: 0:00:35    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3060/4572]  eta: 0:00:34    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [3080/4572]  eta: 0:00:34    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [3100/4572]  eta: 0:00:33    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3120/4572]  eta: 0:00:33    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [3140/4572]  eta: 0:00:32    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [3160/4572]  eta: 0:00:32    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [3180/4572]  eta: 0:00:32    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [3200/4572]  eta: 0:00:31    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [3220/4572]  eta: 0:00:31    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [3240/4572]  eta: 0:00:30    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3260/4572]  eta: 0:00:30    time: 0.0239  data: 0.0217  max mem: 13749
Epoch: [0]  [3280/4572]  eta: 0:00:29    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [3300/4572]  eta: 0:00:29    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [0]  [3320/4572]  eta: 0:00:28    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [3340/4572]  eta: 0:00:28    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3360/4572]  eta: 0:00:27    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [0]  [3380/4572]  eta: 0:00:27    time: 0.0236  data: 0.0217  max mem: 13749
Epoch: [0]  [3400/4572]  eta: 0:00:26    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [3420/4572]  eta: 0:00:26    time: 0.0230  data: 0.0210  max mem: 13749
Epoch: [0]  [3440/4572]  eta: 0:00:26    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3460/4572]  eta: 0:00:25    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [3480/4572]  eta: 0:00:25    time: 0.0236  data: 0.0215  max mem: 13749
Epoch: [0]  [3500/4572]  eta: 0:00:24    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [3520/4572]  eta: 0:00:24    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [3540/4572]  eta: 0:00:23    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3560/4572]  eta: 0:00:23    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3580/4572]  eta: 0:00:22    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3600/4572]  eta: 0:00:22    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [3620/4572]  eta: 0:00:21    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3640/4572]  eta: 0:00:21    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [3660/4572]  eta: 0:00:20    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3680/4572]  eta: 0:00:20    time: 0.0244  data: 0.0219  max mem: 13749
Epoch: [0]  [3700/4572]  eta: 0:00:20    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [0]  [3720/4572]  eta: 0:00:19    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [0]  [3740/4572]  eta: 0:00:19    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [3760/4572]  eta: 0:00:18    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3780/4572]  eta: 0:00:18    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [3800/4572]  eta: 0:00:17    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3820/4572]  eta: 0:00:17    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [3840/4572]  eta: 0:00:16    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3860/4572]  eta: 0:00:16    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3880/4572]  eta: 0:00:15    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [3900/4572]  eta: 0:00:15    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [0]  [3920/4572]  eta: 0:00:14    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [3940/4572]  eta: 0:00:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3960/4572]  eta: 0:00:14    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3980/4572]  eta: 0:00:13    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [4000/4572]  eta: 0:00:13    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [4020/4572]  eta: 0:00:12    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [4040/4572]  eta: 0:00:12    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [4060/4572]  eta: 0:00:11    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [4080/4572]  eta: 0:00:11    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [4100/4572]  eta: 0:00:10    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [4120/4572]  eta: 0:00:10    time: 0.0234  data: 0.0220  max mem: 13749
Epoch: [0]  [4140/4572]  eta: 0:00:09    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [4160/4572]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4180/4572]  eta: 0:00:09    time: 0.0229  data: 0.0206  max mem: 13749
Epoch: [0]  [4200/4572]  eta: 0:00:08    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [4220/4572]  eta: 0:00:08    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [4240/4572]  eta: 0:00:07    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4280/4572]  eta: 0:00:06    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [4300/4572]  eta: 0:00:06    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [4320/4572]  eta: 0:00:05    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [4340/4572]  eta: 0:00:05    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [4360/4572]  eta: 0:00:04    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4380/4572]  eta: 0:00:04    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [4400/4572]  eta: 0:00:03    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [4420/4572]  eta: 0:00:03    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [4440/4572]  eta: 0:00:03    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4460/4572]  eta: 0:00:02    time: 0.0236  data: 0.0222  max mem: 13749
Epoch: [0]  [4480/4572]  eta: 0:00:02    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [4500/4572]  eta: 0:00:01    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [4520/4572]  eta: 0:00:01    time: 0.0219  data: 0.0205  max mem: 13749
Epoch: [0]  [4540/4572]  eta: 0:00:00    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [0] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746041809626, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1746041809626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 173.91066795794922}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746041809629, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/13]  eta: 0:00:07  model_time: 0.5474 (0.5474)  evaluator_time: 0.0054 (0.0054)  time: 0.5577  data: 0.0005  max mem: 13749
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [12/13]  eta: 0:00:00  model_time: 0.3603 (0.3495)  evaluator_time: 0.0053 (0.0049)  time: 0.3556  data: 0.0008  max mem: 13749
Test: Total time: 0:00:04 (0.3557 s / it)
Averaged stats: model_time: 0.3603 (0.3588)  evaluator_time: 0.0053 (0.0050)
:::MLLOG {"namespace": "", "time_ms": 1746041815062, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:01:38    time: 0.0215  data: 0.0008  max mem: 13749
Epoch: [1]  [  20/4571]  eta: 0:01:40    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [  40/4571]  eta: 0:01:45    time: 0.0245  data: 0.0231  max mem: 13749
Epoch: [1]  [  60/4571]  eta: 0:01:43    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [  80/4571]  eta: 0:01:41    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [1]  [ 100/4571]  eta: 0:01:41    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [1]  [ 120/4571]  eta: 0:01:42    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [ 140/4571]  eta: 0:01:43    time: 0.0252  data: 0.0225  max mem: 13749
Epoch: [1]  [ 160/4571]  eta: 0:01:43    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [1]  [ 180/4571]  eta: 0:01:42    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [ 200/4571]  eta: 0:01:41    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [ 220/4571]  eta: 0:01:41    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [ 240/4571]  eta: 0:01:40    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [1]  [ 260/4571]  eta: 0:01:40    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [ 280/4571]  eta: 0:01:39    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [1]  [ 300/4571]  eta: 0:01:39    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [ 320/4571]  eta: 0:01:38    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [ 340/4571]  eta: 0:01:38    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [ 360/4571]  eta: 0:01:37    time: 0.0232  data: 0.0213  max mem: 13749
Epoch: [1]  [ 380/4571]  eta: 0:01:37    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [ 400/4571]  eta: 0:01:36    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [ 420/4571]  eta: 0:01:36    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 440/4571]  eta: 0:01:35    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [ 460/4571]  eta: 0:01:35    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [ 480/4571]  eta: 0:01:34    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [ 500/4571]  eta: 0:01:34    time: 0.0224  data: 0.0206  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746041827011, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1922144153523436, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746041827011, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 520/4571]  eta: 0:01:33    time: 0.0239  data: 0.0225  max mem: 13749
Epoch: [1]  [ 540/4571]  eta: 0:01:33    time: 0.0239  data: 0.0220  max mem: 13749
Epoch: [1]  [ 560/4571]  eta: 0:01:32    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 580/4571]  eta: 0:01:32    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 600/4571]  eta: 0:01:31    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [ 620/4571]  eta: 0:01:31    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [ 640/4571]  eta: 0:01:30    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 660/4571]  eta: 0:01:30    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [ 680/4571]  eta: 0:01:29    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [ 700/4571]  eta: 0:01:29    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [1]  [ 720/4571]  eta: 0:01:28    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [ 740/4571]  eta: 0:01:28    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [ 760/4571]  eta: 0:01:27    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [ 780/4571]  eta: 0:01:27    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [1]  [ 800/4571]  eta: 0:01:26    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [ 820/4571]  eta: 0:01:26    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [ 840/4571]  eta: 0:01:26    time: 0.0247  data: 0.0228  max mem: 13749
Epoch: [1]  [ 860/4571]  eta: 0:01:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [ 880/4571]  eta: 0:01:25    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [ 900/4571]  eta: 0:01:24    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [ 920/4571]  eta: 0:01:24    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [1]  [ 940/4571]  eta: 0:01:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [ 960/4571]  eta: 0:01:23    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [ 980/4571]  eta: 0:01:22    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [1000/4571]  eta: 0:01:22    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1020/4571]  eta: 0:01:21    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [1040/4571]  eta: 0:01:21    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1060/4571]  eta: 0:01:20    time: 0.0223  data: 0.0199  max mem: 13749
Epoch: [1]  [1080/4571]  eta: 0:01:20    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1100/4571]  eta: 0:01:19    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [1120/4571]  eta: 0:01:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1140/4571]  eta: 0:01:18    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [1]  [1160/4571]  eta: 0:01:18    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1180/4571]  eta: 0:01:18    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [1]  [1200/4571]  eta: 0:01:17    time: 0.0234  data: 0.0212  max mem: 13749
Epoch: [1]  [1220/4571]  eta: 0:01:17    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1240/4571]  eta: 0:01:16    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [1260/4571]  eta: 0:01:16    time: 0.0243  data: 0.0220  max mem: 13749
Epoch: [1]  [1280/4571]  eta: 0:01:15    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [1300/4571]  eta: 0:01:15    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [1320/4571]  eta: 0:01:14    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [1]  [1340/4571]  eta: 0:01:14    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1360/4571]  eta: 0:01:13    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1380/4571]  eta: 0:01:13    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [1]  [1400/4571]  eta: 0:01:12    time: 0.0228  data: 0.0208  max mem: 13749
Epoch: [1]  [1420/4571]  eta: 0:01:12    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [1440/4571]  eta: 0:01:11    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1460/4571]  eta: 0:01:11    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [1]  [1480/4571]  eta: 0:01:11    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [1500/4571]  eta: 0:01:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [1520/4571]  eta: 0:01:10    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [1540/4571]  eta: 0:01:09    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1560/4571]  eta: 0:01:09    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [1580/4571]  eta: 0:01:08    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [1600/4571]  eta: 0:01:08    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [1620/4571]  eta: 0:01:07    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [1640/4571]  eta: 0:01:07    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1660/4571]  eta: 0:01:06    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [1680/4571]  eta: 0:01:06    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1700/4571]  eta: 0:01:05    time: 0.0238  data: 0.0220  max mem: 13749
Epoch: [1]  [1720/4571]  eta: 0:01:05    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [1]  [1740/4571]  eta: 0:01:05    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [1760/4571]  eta: 0:01:04    time: 0.0221  data: 0.0203  max mem: 13749
Epoch: [1]  [1780/4571]  eta: 0:01:04    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [1800/4571]  eta: 0:01:03    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [1820/4571]  eta: 0:01:03    time: 0.0237  data: 0.0217  max mem: 13749
Epoch: [1]  [1840/4571]  eta: 0:01:02    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1860/4571]  eta: 0:01:02    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [1880/4571]  eta: 0:01:01    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1900/4571]  eta: 0:01:01    time: 0.0252  data: 0.0231  max mem: 13749
Epoch: [1]  [1920/4571]  eta: 0:01:00    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1940/4571]  eta: 0:01:00    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [1960/4571]  eta: 0:01:00    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [1]  [1980/4571]  eta: 0:00:59    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2000/4571]  eta: 0:00:59    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2020/4571]  eta: 0:00:58    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2060/4571]  eta: 0:00:57    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2080/4571]  eta: 0:00:57    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2100/4571]  eta: 0:00:56    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [2120/4571]  eta: 0:00:56    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2140/4571]  eta: 0:00:55    time: 0.0229  data: 0.0196  max mem: 13749
Epoch: [1]  [2160/4571]  eta: 0:00:55    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2180/4571]  eta: 0:00:54    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2200/4571]  eta: 0:00:54    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [2220/4571]  eta: 0:00:54    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [1]  [2240/4571]  eta: 0:00:53    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [1]  [2260/4571]  eta: 0:00:53    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [1]  [2280/4571]  eta: 0:00:52    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [2300/4571]  eta: 0:00:52    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [2320/4571]  eta: 0:00:51    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2340/4571]  eta: 0:00:51    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [1]  [2360/4571]  eta: 0:00:50    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [2380/4571]  eta: 0:00:50    time: 0.0234  data: 0.0214  max mem: 13749
Epoch: [1]  [2400/4571]  eta: 0:00:49    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [2420/4571]  eta: 0:00:49    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2440/4571]  eta: 0:00:48    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [2460/4571]  eta: 0:00:48    time: 0.0229  data: 0.0199  max mem: 13749
Epoch: [1]  [2480/4571]  eta: 0:00:48    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2500/4571]  eta: 0:00:47    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [1]  [2520/4571]  eta: 0:00:47    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2540/4571]  eta: 0:00:46    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [2560/4571]  eta: 0:00:46    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [1]  [2580/4571]  eta: 0:00:45    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [1]  [2600/4571]  eta: 0:00:45    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [2620/4571]  eta: 0:00:44    time: 0.0225  data: 0.0206  max mem: 13749
Epoch: [1]  [2640/4571]  eta: 0:00:44    time: 0.0240  data: 0.0223  max mem: 13749
Epoch: [1]  [2660/4571]  eta: 0:00:43    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2680/4571]  eta: 0:00:43    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2700/4571]  eta: 0:00:42    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [1]  [2720/4571]  eta: 0:00:42    time: 0.0222  data: 0.0202  max mem: 13749
Epoch: [1]  [2740/4571]  eta: 0:00:42    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [2760/4571]  eta: 0:00:41    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2780/4571]  eta: 0:00:41    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [2800/4571]  eta: 0:00:40    time: 0.0226  data: 0.0209  max mem: 13749
Epoch: [1]  [2820/4571]  eta: 0:00:40    time: 0.0255  data: 0.0240  max mem: 13749
Epoch: [1]  [2840/4571]  eta: 0:00:39    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2860/4571]  eta: 0:00:39    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [1]  [2880/4571]  eta: 0:00:38    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2900/4571]  eta: 0:00:38    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2920/4571]  eta: 0:00:37    time: 0.0225  data: 0.0205  max mem: 13749
Epoch: [1]  [2940/4571]  eta: 0:00:37    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [2960/4571]  eta: 0:00:37    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [2980/4571]  eta: 0:00:36    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3000/4571]  eta: 0:00:36    time: 0.0219  data: 0.0205  max mem: 13749
Epoch: [1]  [3020/4571]  eta: 0:00:35    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3040/4571]  eta: 0:00:35    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [3060/4571]  eta: 0:00:34    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [3080/4571]  eta: 0:00:34    time: 0.0221  data: 0.0195  max mem: 13749
Epoch: [1]  [3100/4571]  eta: 0:00:33    time: 0.0230  data: 0.0212  max mem: 13749
Epoch: [1]  [3120/4571]  eta: 0:00:33    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [1]  [3140/4571]  eta: 0:00:32    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3160/4571]  eta: 0:00:32    time: 0.0253  data: 0.0238  max mem: 13749
Epoch: [1]  [3180/4571]  eta: 0:00:31    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3200/4571]  eta: 0:00:31    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3220/4571]  eta: 0:00:31    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [3240/4571]  eta: 0:00:30    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3260/4571]  eta: 0:00:30    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3280/4571]  eta: 0:00:29    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [3300/4571]  eta: 0:00:29    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3320/4571]  eta: 0:00:28    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3340/4571]  eta: 0:00:28    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [3360/4571]  eta: 0:00:27    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [3380/4571]  eta: 0:00:27    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [3400/4571]  eta: 0:00:26    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [3420/4571]  eta: 0:00:26    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [3440/4571]  eta: 0:00:26    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3460/4571]  eta: 0:00:25    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [3480/4571]  eta: 0:00:25    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [3500/4571]  eta: 0:00:24    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [3520/4571]  eta: 0:00:24    time: 0.0233  data: 0.0212  max mem: 13749
Epoch: [1]  [3540/4571]  eta: 0:00:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [3560/4571]  eta: 0:00:23    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [3580/4571]  eta: 0:00:22    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [3600/4571]  eta: 0:00:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3620/4571]  eta: 0:00:21    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [1]  [3640/4571]  eta: 0:00:21    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [3660/4571]  eta: 0:00:20    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [1]  [3680/4571]  eta: 0:00:20    time: 0.0228  data: 0.0204  max mem: 13749
Epoch: [1]  [3700/4571]  eta: 0:00:20    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [3720/4571]  eta: 0:00:19    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [1]  [3740/4571]  eta: 0:00:19    time: 0.0223  data: 0.0205  max mem: 13749
Epoch: [1]  [3760/4571]  eta: 0:00:18    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3780/4571]  eta: 0:00:18    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [1]  [3800/4571]  eta: 0:00:17    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3820/4571]  eta: 0:00:17    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3840/4571]  eta: 0:00:16    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [3860/4571]  eta: 0:00:16    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [3880/4571]  eta: 0:00:15    time: 0.0236  data: 0.0222  max mem: 13749
Epoch: [1]  [3900/4571]  eta: 0:00:15    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [3920/4571]  eta: 0:00:14    time: 0.0244  data: 0.0230  max mem: 13749
Epoch: [1]  [3940/4571]  eta: 0:00:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3960/4571]  eta: 0:00:14    time: 0.0233  data: 0.0213  max mem: 13749
Epoch: [1]  [3980/4571]  eta: 0:00:13    time: 0.0217  data: 0.0203  max mem: 13749
Epoch: [1]  [4000/4571]  eta: 0:00:13    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [1]  [4020/4571]  eta: 0:00:12    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [4040/4571]  eta: 0:00:12    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [4060/4571]  eta: 0:00:11    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [4080/4571]  eta: 0:00:11    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [1]  [4100/4571]  eta: 0:00:10    time: 0.0239  data: 0.0225  max mem: 13749
Epoch: [1]  [4120/4571]  eta: 0:00:10    time: 0.0227  data: 0.0205  max mem: 13749
Epoch: [1]  [4140/4571]  eta: 0:00:09    time: 0.0241  data: 0.0215  max mem: 13749
Epoch: [1]  [4160/4571]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [4180/4571]  eta: 0:00:08    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [4200/4571]  eta: 0:00:08    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [4220/4571]  eta: 0:00:08    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [4240/4571]  eta: 0:00:07    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [4260/4571]  eta: 0:00:07    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [4280/4571]  eta: 0:00:06    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [4300/4571]  eta: 0:00:06    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [4320/4571]  eta: 0:00:05    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [4340/4571]  eta: 0:00:05    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [4360/4571]  eta: 0:00:04    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [4400/4571]  eta: 0:00:03    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [4420/4571]  eta: 0:00:03    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [4440/4571]  eta: 0:00:03    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [4460/4571]  eta: 0:00:02    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [4480/4571]  eta: 0:00:02    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [4500/4571]  eta: 0:00:01    time: 0.0219  data: 0.0205  max mem: 13749
Epoch: [1]  [4520/4571]  eta: 0:00:01    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [4540/4571]  eta: 0:00:00    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0253  data: 0.0238  max mem: 13749
Epoch: [1] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746041920195, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746041920195, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 173.97258557725308}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746041920197, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2865 (0.2865)  evaluator_time: 0.0034 (0.0034)  time: 0.2909  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2865 (0.2679)  evaluator_time: 0.0037 (0.0035)  time: 0.2724  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2725 s / it)
Averaged stats: model_time: 0.2865 (0.2745)  evaluator_time: 0.0037 (0.0036)
:::MLLOG {"namespace": "", "time_ms": 1746041924245, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:01:36    time: 0.0210  data: 0.0007  max mem: 13749
Epoch: [2]  [  20/4572]  eta: 0:01:42    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [  40/4572]  eta: 0:01:41    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [  60/4572]  eta: 0:01:40    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [  80/4572]  eta: 0:01:40    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [ 100/4572]  eta: 0:01:40    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 120/4572]  eta: 0:01:40    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [ 140/4572]  eta: 0:01:40    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [ 160/4572]  eta: 0:01:39    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [ 180/4572]  eta: 0:01:38    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [ 200/4572]  eta: 0:01:38    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [ 220/4572]  eta: 0:01:37    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [ 240/4572]  eta: 0:01:36    time: 0.0220  data: 0.0204  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746041929686, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.28040243695464295, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746041929686, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 260/4572]  eta: 0:01:36    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [ 280/4572]  eta: 0:01:36    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [ 300/4572]  eta: 0:01:36    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [2]  [ 320/4572]  eta: 0:01:35    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [2]  [ 340/4572]  eta: 0:01:35    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [ 360/4572]  eta: 0:01:34    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 380/4572]  eta: 0:01:34    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [ 400/4572]  eta: 0:01:34    time: 0.0237  data: 0.0218  max mem: 13749
Epoch: [2]  [ 420/4572]  eta: 0:01:33    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [ 440/4572]  eta: 0:01:33    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [ 460/4572]  eta: 0:01:33    time: 0.0241  data: 0.0221  max mem: 13749
Epoch: [2]  [ 480/4572]  eta: 0:01:32    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [2]  [ 500/4572]  eta: 0:01:32    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [ 520/4572]  eta: 0:01:31    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [ 540/4572]  eta: 0:01:31    time: 0.0237  data: 0.0218  max mem: 13749
Epoch: [2]  [ 560/4572]  eta: 0:01:30    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [ 580/4572]  eta: 0:01:30    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [ 600/4572]  eta: 0:01:30    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 620/4572]  eta: 0:01:29    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [2]  [ 640/4572]  eta: 0:01:29    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [ 660/4572]  eta: 0:01:28    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 680/4572]  eta: 0:01:28    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [ 700/4572]  eta: 0:01:27    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [ 720/4572]  eta: 0:01:27    time: 0.0225  data: 0.0202  max mem: 13749
Epoch: [2]  [ 740/4572]  eta: 0:01:26    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [2]  [ 760/4572]  eta: 0:01:26    time: 0.0253  data: 0.0238  max mem: 13749
Epoch: [2]  [ 780/4572]  eta: 0:01:26    time: 0.0250  data: 0.0236  max mem: 13749
Epoch: [2]  [ 800/4572]  eta: 0:01:26    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [ 820/4572]  eta: 0:01:25    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [2]  [ 840/4572]  eta: 0:01:25    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [ 860/4572]  eta: 0:01:24    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [ 880/4572]  eta: 0:01:24    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [ 900/4572]  eta: 0:01:23    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [ 920/4572]  eta: 0:01:23    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 940/4572]  eta: 0:01:22    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [ 960/4572]  eta: 0:01:22    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [ 980/4572]  eta: 0:01:21    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [2]  [1000/4572]  eta: 0:01:21    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [1020/4572]  eta: 0:01:21    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1040/4572]  eta: 0:01:20    time: 0.0248  data: 0.0229  max mem: 13749
Epoch: [2]  [1060/4572]  eta: 0:01:20    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [2]  [1080/4572]  eta: 0:01:19    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [1100/4572]  eta: 0:01:19    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [1120/4572]  eta: 0:01:19    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [2]  [1140/4572]  eta: 0:01:18    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [2]  [1160/4572]  eta: 0:01:18    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1180/4572]  eta: 0:01:17    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [1200/4572]  eta: 0:01:17    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1220/4572]  eta: 0:01:16    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1240/4572]  eta: 0:01:16    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [2]  [1260/4572]  eta: 0:01:15    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [1280/4572]  eta: 0:01:15    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [2]  [1300/4572]  eta: 0:01:14    time: 0.0230  data: 0.0210  max mem: 13749
Epoch: [2]  [1320/4572]  eta: 0:01:14    time: 0.0228  data: 0.0209  max mem: 13749
Epoch: [2]  [1340/4572]  eta: 0:01:14    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [1360/4572]  eta: 0:01:13    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [1380/4572]  eta: 0:01:13    time: 0.0220  data: 0.0202  max mem: 13749
Epoch: [2]  [1400/4572]  eta: 0:01:12    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [2]  [1420/4572]  eta: 0:01:12    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1440/4572]  eta: 0:01:11    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [1460/4572]  eta: 0:01:11    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1480/4572]  eta: 0:01:10    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1500/4572]  eta: 0:01:10    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1520/4572]  eta: 0:01:09    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [1540/4572]  eta: 0:01:09    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1560/4572]  eta: 0:01:08    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1580/4572]  eta: 0:01:08    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [2]  [1600/4572]  eta: 0:01:08    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [1620/4572]  eta: 0:01:07    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [2]  [1640/4572]  eta: 0:01:07    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1660/4572]  eta: 0:01:06    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [2]  [1680/4572]  eta: 0:01:06    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [1700/4572]  eta: 0:01:05    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1720/4572]  eta: 0:01:05    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1740/4572]  eta: 0:01:04    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [1760/4572]  eta: 0:01:04    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [1780/4572]  eta: 0:01:03    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1800/4572]  eta: 0:01:03    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [2]  [1820/4572]  eta: 0:01:02    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [1840/4572]  eta: 0:01:02    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1860/4572]  eta: 0:01:02    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [1880/4572]  eta: 0:01:01    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [2]  [1900/4572]  eta: 0:01:01    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1920/4572]  eta: 0:01:00    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1940/4572]  eta: 0:01:00    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [1960/4572]  eta: 0:00:59    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [1980/4572]  eta: 0:00:59    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [2000/4572]  eta: 0:00:58    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [2]  [2020/4572]  eta: 0:00:58    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [2040/4572]  eta: 0:00:57    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [2]  [2060/4572]  eta: 0:00:57    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2080/4572]  eta: 0:00:57    time: 0.0238  data: 0.0219  max mem: 13749
Epoch: [2]  [2100/4572]  eta: 0:00:56    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [2120/4572]  eta: 0:00:56    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [2140/4572]  eta: 0:00:55    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [2160/4572]  eta: 0:00:55    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [2]  [2180/4572]  eta: 0:00:54    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [2200/4572]  eta: 0:00:54    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2220/4572]  eta: 0:00:53    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2240/4572]  eta: 0:00:53    time: 0.0236  data: 0.0211  max mem: 13749
Epoch: [2]  [2260/4572]  eta: 0:00:52    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2280/4572]  eta: 0:00:52    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2300/4572]  eta: 0:00:51    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [2]  [2320/4572]  eta: 0:00:51    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [2]  [2340/4572]  eta: 0:00:51    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2360/4572]  eta: 0:00:50    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [2380/4572]  eta: 0:00:50    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [2400/4572]  eta: 0:00:49    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2420/4572]  eta: 0:00:49    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [2440/4572]  eta: 0:00:48    time: 0.0243  data: 0.0229  max mem: 13749
Epoch: [2]  [2460/4572]  eta: 0:00:48    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2480/4572]  eta: 0:00:47    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2500/4572]  eta: 0:00:47    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [2520/4572]  eta: 0:00:46    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [2]  [2540/4572]  eta: 0:00:46    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [2560/4572]  eta: 0:00:46    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2580/4572]  eta: 0:00:45    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2600/4572]  eta: 0:00:45    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [2620/4572]  eta: 0:00:44    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2640/4572]  eta: 0:00:44    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [2]  [2660/4572]  eta: 0:00:43    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2680/4572]  eta: 0:00:43    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [2700/4572]  eta: 0:00:42    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2720/4572]  eta: 0:00:42    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2740/4572]  eta: 0:00:41    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [2]  [2760/4572]  eta: 0:00:41    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [2]  [2780/4572]  eta: 0:00:41    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [2800/4572]  eta: 0:00:40    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [2820/4572]  eta: 0:00:40    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [2840/4572]  eta: 0:00:39    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [2860/4572]  eta: 0:00:39    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [2880/4572]  eta: 0:00:38    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [2900/4572]  eta: 0:00:38    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2920/4572]  eta: 0:00:37    time: 0.0248  data: 0.0232  max mem: 13749
Epoch: [2]  [2940/4572]  eta: 0:00:37    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [2960/4572]  eta: 0:00:36    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2980/4572]  eta: 0:00:36    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3000/4572]  eta: 0:00:35    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3020/4572]  eta: 0:00:35    time: 0.0235  data: 0.0211  max mem: 13749
Epoch: [2]  [3040/4572]  eta: 0:00:35    time: 0.0228  data: 0.0208  max mem: 13749
Epoch: [2]  [3060/4572]  eta: 0:00:34    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [3080/4572]  eta: 0:00:34    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [3100/4572]  eta: 0:00:33    time: 0.0236  data: 0.0222  max mem: 13749
Epoch: [2]  [3120/4572]  eta: 0:00:33    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [2]  [3140/4572]  eta: 0:00:32    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3160/4572]  eta: 0:00:32    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [3180/4572]  eta: 0:00:31    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3200/4572]  eta: 0:00:31    time: 0.0236  data: 0.0219  max mem: 13749
Epoch: [2]  [3220/4572]  eta: 0:00:30    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [2]  [3240/4572]  eta: 0:00:30    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [2]  [3260/4572]  eta: 0:00:30    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [3280/4572]  eta: 0:00:29    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [3300/4572]  eta: 0:00:29    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [2]  [3320/4572]  eta: 0:00:28    time: 0.0237  data: 0.0223  max mem: 13749
Epoch: [2]  [3340/4572]  eta: 0:00:28    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [3360/4572]  eta: 0:00:27    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [2]  [3380/4572]  eta: 0:00:27    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [2]  [3400/4572]  eta: 0:00:26    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [3420/4572]  eta: 0:00:26    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [2]  [3440/4572]  eta: 0:00:25    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3460/4572]  eta: 0:00:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [3480/4572]  eta: 0:00:25    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [3500/4572]  eta: 0:00:24    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3520/4572]  eta: 0:00:24    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3540/4572]  eta: 0:00:23    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [2]  [3560/4572]  eta: 0:00:23    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [3580/4572]  eta: 0:00:22    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [3600/4572]  eta: 0:00:22    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3620/4572]  eta: 0:00:21    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3640/4572]  eta: 0:00:21    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3660/4572]  eta: 0:00:20    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [3680/4572]  eta: 0:00:20    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [3700/4572]  eta: 0:00:20    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [3720/4572]  eta: 0:00:19    time: 0.0229  data: 0.0212  max mem: 13749
Epoch: [2]  [3740/4572]  eta: 0:00:19    time: 0.0227  data: 0.0203  max mem: 13749
Epoch: [2]  [3760/4572]  eta: 0:00:18    time: 0.0228  data: 0.0209  max mem: 13749
Epoch: [2]  [3780/4572]  eta: 0:00:18    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3800/4572]  eta: 0:00:17    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [2]  [3820/4572]  eta: 0:00:17    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [3840/4572]  eta: 0:00:16    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [2]  [3860/4572]  eta: 0:00:16    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [3880/4572]  eta: 0:00:15    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [3900/4572]  eta: 0:00:15    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [3920/4572]  eta: 0:00:14    time: 0.0227  data: 0.0209  max mem: 13749
Epoch: [2]  [3940/4572]  eta: 0:00:14    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3960/4572]  eta: 0:00:14    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [3980/4572]  eta: 0:00:13    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [4000/4572]  eta: 0:00:13    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [2]  [4020/4572]  eta: 0:00:12    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [4040/4572]  eta: 0:00:12    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [2]  [4060/4572]  eta: 0:00:11    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [4080/4572]  eta: 0:00:11    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [4100/4572]  eta: 0:00:10    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [4120/4572]  eta: 0:00:10    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4140/4572]  eta: 0:00:09    time: 0.0228  data: 0.0204  max mem: 13749
Epoch: [2]  [4160/4572]  eta: 0:00:09    time: 0.0256  data: 0.0240  max mem: 13749
Epoch: [2]  [4180/4572]  eta: 0:00:09    time: 0.0267  data: 0.0251  max mem: 13749
Epoch: [2]  [4200/4572]  eta: 0:00:08    time: 0.0236  data: 0.0209  max mem: 13749
Epoch: [2]  [4220/4572]  eta: 0:00:08    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [4240/4572]  eta: 0:00:07    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0198  max mem: 13749
Epoch: [2]  [4280/4572]  eta: 0:00:06    time: 0.0225  data: 0.0200  max mem: 13749
Epoch: [2]  [4300/4572]  eta: 0:00:06    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [4320/4572]  eta: 0:00:05    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [4340/4572]  eta: 0:00:05    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [4360/4572]  eta: 0:00:04    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4380/4572]  eta: 0:00:04    time: 0.0239  data: 0.0218  max mem: 13749
Epoch: [2]  [4400/4572]  eta: 0:00:03    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [4420/4572]  eta: 0:00:03    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [2]  [4440/4572]  eta: 0:00:03    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [2]  [4460/4572]  eta: 0:00:02    time: 0.0251  data: 0.0223  max mem: 13749
Epoch: [2]  [4480/4572]  eta: 0:00:02    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [2]  [4500/4572]  eta: 0:00:01    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [2]  [4520/4572]  eta: 0:00:01    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [4540/4572]  eta: 0:00:00    time: 0.0223  data: 0.0202  max mem: 13749
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746042029376, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746042029376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.02883895629287}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042029377, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2775 (0.2775)  evaluator_time: 0.0031 (0.0031)  time: 0.2816  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2770 (0.2586)  evaluator_time: 0.0035 (0.0098)  time: 0.2693  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2694 s / it)
Averaged stats: model_time: 0.2770 (0.2650)  evaluator_time: 0.0035 (0.0081)
:::MLLOG {"namespace": "", "time_ms": 1746042033332, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:01:36    time: 0.0211  data: 0.0009  max mem: 13749
Epoch: [3]  [  20/4571]  eta: 0:01:40    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [  40/4571]  eta: 0:01:43    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [3]  [  60/4571]  eta: 0:01:41    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [  80/4571]  eta: 0:01:43    time: 0.0244  data: 0.0228  max mem: 13749
Epoch: [3]  [ 100/4571]  eta: 0:01:43    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [ 120/4571]  eta: 0:01:43    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [ 140/4571]  eta: 0:01:42    time: 0.0232  data: 0.0215  max mem: 13749
Epoch: [3]  [ 160/4571]  eta: 0:01:42    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [3]  [ 180/4571]  eta: 0:01:41    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [ 200/4571]  eta: 0:01:41    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [ 220/4571]  eta: 0:01:40    time: 0.0221  data: 0.0206  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746042038470, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3048277251369941, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042038470, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 240/4571]  eta: 0:01:39    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [ 260/4571]  eta: 0:01:39    time: 0.0235  data: 0.0217  max mem: 13749
Epoch: [3]  [ 280/4571]  eta: 0:01:38    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [3]  [ 300/4571]  eta: 0:01:38    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 320/4571]  eta: 0:01:38    time: 0.0262  data: 0.0247  max mem: 13749
Epoch: [3]  [ 340/4571]  eta: 0:01:38    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [ 360/4571]  eta: 0:01:37    time: 0.0238  data: 0.0220  max mem: 13749
Epoch: [3]  [ 380/4571]  eta: 0:01:37    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [ 400/4571]  eta: 0:01:36    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [3]  [ 420/4571]  eta: 0:01:36    time: 0.0248  data: 0.0232  max mem: 13749
Epoch: [3]  [ 440/4571]  eta: 0:01:36    time: 0.0260  data: 0.0236  max mem: 13749
Epoch: [3]  [ 460/4571]  eta: 0:01:36    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 480/4571]  eta: 0:01:35    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [ 500/4571]  eta: 0:01:35    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [ 520/4571]  eta: 0:01:34    time: 0.0238  data: 0.0216  max mem: 13749
Epoch: [3]  [ 540/4571]  eta: 0:01:34    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [ 560/4571]  eta: 0:01:33    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [3]  [ 580/4571]  eta: 0:01:33    time: 0.0232  data: 0.0211  max mem: 13749
Epoch: [3]  [ 600/4571]  eta: 0:01:32    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [ 620/4571]  eta: 0:01:32    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [ 640/4571]  eta: 0:01:31    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [ 660/4571]  eta: 0:01:31    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [ 680/4571]  eta: 0:01:30    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [ 700/4571]  eta: 0:01:30    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [3]  [ 720/4571]  eta: 0:01:29    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [ 740/4571]  eta: 0:01:29    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [3]  [ 760/4571]  eta: 0:01:28    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [3]  [ 780/4571]  eta: 0:01:28    time: 0.0258  data: 0.0243  max mem: 13749
Epoch: [3]  [ 800/4571]  eta: 0:01:28    time: 0.0250  data: 0.0235  max mem: 13749
Epoch: [3]  [ 820/4571]  eta: 0:01:27    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [3]  [ 840/4571]  eta: 0:01:27    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [ 860/4571]  eta: 0:01:26    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [3]  [ 880/4571]  eta: 0:01:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [ 900/4571]  eta: 0:01:25    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [ 920/4571]  eta: 0:01:24    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [ 940/4571]  eta: 0:01:24    time: 0.0263  data: 0.0248  max mem: 13749
Epoch: [3]  [ 960/4571]  eta: 0:01:24    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [ 980/4571]  eta: 0:01:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1000/4571]  eta: 0:01:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1020/4571]  eta: 0:01:22    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [1040/4571]  eta: 0:01:22    time: 0.0247  data: 0.0227  max mem: 13749
Epoch: [3]  [1060/4571]  eta: 0:01:21    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [1080/4571]  eta: 0:01:21    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [3]  [1100/4571]  eta: 0:01:20    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [1120/4571]  eta: 0:01:20    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [1140/4571]  eta: 0:01:19    time: 0.0243  data: 0.0220  max mem: 13749
Epoch: [3]  [1160/4571]  eta: 0:01:19    time: 0.0259  data: 0.0244  max mem: 13749
Epoch: [3]  [1180/4571]  eta: 0:01:19    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [1200/4571]  eta: 0:01:18    time: 0.0277  data: 0.0262  max mem: 13749
Epoch: [3]  [1220/4571]  eta: 0:01:18    time: 0.0262  data: 0.0247  max mem: 13749
Epoch: [3]  [1240/4571]  eta: 0:01:18    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1260/4571]  eta: 0:01:17    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [1280/4571]  eta: 0:01:17    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [1300/4571]  eta: 0:01:16    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [3]  [1320/4571]  eta: 0:01:16    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [3]  [1340/4571]  eta: 0:01:15    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [1360/4571]  eta: 0:01:15    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1380/4571]  eta: 0:01:14    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1400/4571]  eta: 0:01:13    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [3]  [1420/4571]  eta: 0:01:13    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [1440/4571]  eta: 0:01:13    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [1460/4571]  eta: 0:01:12    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1480/4571]  eta: 0:01:12    time: 0.0245  data: 0.0231  max mem: 13749
Epoch: [3]  [1500/4571]  eta: 0:01:11    time: 0.0217  data: 0.0203  max mem: 13749
Epoch: [3]  [1520/4571]  eta: 0:01:11    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [1540/4571]  eta: 0:01:10    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [1560/4571]  eta: 0:01:10    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [1580/4571]  eta: 0:01:09    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [1600/4571]  eta: 0:01:09    time: 0.0261  data: 0.0246  max mem: 13749
Epoch: [3]  [1620/4571]  eta: 0:01:08    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [1640/4571]  eta: 0:01:08    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1660/4571]  eta: 0:01:07    time: 0.0240  data: 0.0218  max mem: 13749
Epoch: [3]  [1680/4571]  eta: 0:01:07    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [1700/4571]  eta: 0:01:06    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [1720/4571]  eta: 0:01:06    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [1740/4571]  eta: 0:01:05    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [1760/4571]  eta: 0:01:05    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [1780/4571]  eta: 0:01:05    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [1800/4571]  eta: 0:01:04    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [1820/4571]  eta: 0:01:04    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1840/4571]  eta: 0:01:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1860/4571]  eta: 0:01:03    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [3]  [1880/4571]  eta: 0:01:02    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [3]  [1900/4571]  eta: 0:01:02    time: 0.0244  data: 0.0225  max mem: 13749
Epoch: [3]  [1920/4571]  eta: 0:01:01    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1940/4571]  eta: 0:01:01    time: 0.0233  data: 0.0209  max mem: 13749
Epoch: [3]  [1960/4571]  eta: 0:01:00    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [1980/4571]  eta: 0:01:00    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2000/4571]  eta: 0:00:59    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [2020/4571]  eta: 0:00:59    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2060/4571]  eta: 0:00:58    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [2080/4571]  eta: 0:00:58    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [2100/4571]  eta: 0:00:57    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [2120/4571]  eta: 0:00:57    time: 0.0223  data: 0.0199  max mem: 13749
Epoch: [3]  [2140/4571]  eta: 0:00:56    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [2160/4571]  eta: 0:00:56    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2180/4571]  eta: 0:00:55    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2200/4571]  eta: 0:00:55    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2220/4571]  eta: 0:00:54    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [2240/4571]  eta: 0:00:54    time: 0.0241  data: 0.0227  max mem: 13749
Epoch: [3]  [2260/4571]  eta: 0:00:53    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2280/4571]  eta: 0:00:53    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [2300/4571]  eta: 0:00:52    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [2320/4571]  eta: 0:00:52    time: 0.0239  data: 0.0221  max mem: 13749
Epoch: [3]  [2340/4571]  eta: 0:00:51    time: 0.0275  data: 0.0260  max mem: 13749
Epoch: [3]  [2360/4571]  eta: 0:00:51    time: 0.0232  data: 0.0207  max mem: 13749
Epoch: [3]  [2380/4571]  eta: 0:00:50    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2400/4571]  eta: 0:00:50    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [2420/4571]  eta: 0:00:50    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [2440/4571]  eta: 0:00:49    time: 0.0228  data: 0.0206  max mem: 13749
Epoch: [3]  [2460/4571]  eta: 0:00:49    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [2480/4571]  eta: 0:00:48    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2500/4571]  eta: 0:00:48    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2520/4571]  eta: 0:00:47    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2540/4571]  eta: 0:00:47    time: 0.0227  data: 0.0207  max mem: 13749
Epoch: [3]  [2560/4571]  eta: 0:00:46    time: 0.0240  data: 0.0226  max mem: 13749
Epoch: [3]  [2580/4571]  eta: 0:00:46    time: 0.0244  data: 0.0227  max mem: 13749
Epoch: [3]  [2600/4571]  eta: 0:00:45    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [2620/4571]  eta: 0:00:45    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2640/4571]  eta: 0:00:44    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [3]  [2660/4571]  eta: 0:00:44    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2680/4571]  eta: 0:00:43    time: 0.0226  data: 0.0207  max mem: 13749
Epoch: [3]  [2700/4571]  eta: 0:00:43    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2720/4571]  eta: 0:00:42    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2740/4571]  eta: 0:00:42    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [3]  [2760/4571]  eta: 0:00:42    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [3]  [2780/4571]  eta: 0:00:41    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [2800/4571]  eta: 0:00:41    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [2820/4571]  eta: 0:00:40    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2840/4571]  eta: 0:00:40    time: 0.0263  data: 0.0248  max mem: 13749
Epoch: [3]  [2860/4571]  eta: 0:00:39    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2880/4571]  eta: 0:00:39    time: 0.0226  data: 0.0205  max mem: 13749
Epoch: [3]  [2900/4571]  eta: 0:00:38    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [2920/4571]  eta: 0:00:38    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [2940/4571]  eta: 0:00:37    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [2960/4571]  eta: 0:00:37    time: 0.0236  data: 0.0222  max mem: 13749
Epoch: [3]  [2980/4571]  eta: 0:00:36    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [3000/4571]  eta: 0:00:36    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3020/4571]  eta: 0:00:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3040/4571]  eta: 0:00:35    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3060/4571]  eta: 0:00:35    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3080/4571]  eta: 0:00:34    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [3100/4571]  eta: 0:00:34    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [3120/4571]  eta: 0:00:33    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3140/4571]  eta: 0:00:33    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [3160/4571]  eta: 0:00:32    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3180/4571]  eta: 0:00:32    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3200/4571]  eta: 0:00:31    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [3220/4571]  eta: 0:00:31    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3240/4571]  eta: 0:00:30    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [3260/4571]  eta: 0:00:30    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [3280/4571]  eta: 0:00:29    time: 0.0265  data: 0.0249  max mem: 13749
Epoch: [3]  [3300/4571]  eta: 0:00:29    time: 0.0234  data: 0.0202  max mem: 13749
Epoch: [3]  [3320/4571]  eta: 0:00:29    time: 0.0230  data: 0.0204  max mem: 13749
Epoch: [3]  [3340/4571]  eta: 0:00:28    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [3360/4571]  eta: 0:00:28    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [3380/4571]  eta: 0:00:27    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3400/4571]  eta: 0:00:27    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [3420/4571]  eta: 0:00:26    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [3]  [3440/4571]  eta: 0:00:26    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [3460/4571]  eta: 0:00:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [3480/4571]  eta: 0:00:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3500/4571]  eta: 0:00:24    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [3520/4571]  eta: 0:00:24    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [3]  [3540/4571]  eta: 0:00:23    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3560/4571]  eta: 0:00:23    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [3580/4571]  eta: 0:00:22    time: 0.0235  data: 0.0210  max mem: 13749
Epoch: [3]  [3600/4571]  eta: 0:00:22    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [3]  [3620/4571]  eta: 0:00:22    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3640/4571]  eta: 0:00:21    time: 0.0239  data: 0.0214  max mem: 13749
Epoch: [3]  [3660/4571]  eta: 0:00:21    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [3680/4571]  eta: 0:00:20    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [3]  [3700/4571]  eta: 0:00:20    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3720/4571]  eta: 0:00:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3740/4571]  eta: 0:00:19    time: 0.0239  data: 0.0221  max mem: 13749
Epoch: [3]  [3760/4571]  eta: 0:00:18    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [3780/4571]  eta: 0:00:18    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3800/4571]  eta: 0:00:17    time: 0.0217  data: 0.0203  max mem: 13749
Epoch: [3]  [3820/4571]  eta: 0:00:17    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3840/4571]  eta: 0:00:16    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [3860/4571]  eta: 0:00:16    time: 0.0255  data: 0.0240  max mem: 13749
Epoch: [3]  [3880/4571]  eta: 0:00:16    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [3900/4571]  eta: 0:00:15    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [3]  [3920/4571]  eta: 0:00:15    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3940/4571]  eta: 0:00:14    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [3960/4571]  eta: 0:00:14    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [3980/4571]  eta: 0:00:13    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [4000/4571]  eta: 0:00:13    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [4020/4571]  eta: 0:00:12    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [4040/4571]  eta: 0:00:12    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [4060/4571]  eta: 0:00:11    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [4080/4571]  eta: 0:00:11    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [4100/4571]  eta: 0:00:10    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [4120/4571]  eta: 0:00:10    time: 0.0229  data: 0.0205  max mem: 13749
Epoch: [3]  [4140/4571]  eta: 0:00:09    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [4160/4571]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [4180/4571]  eta: 0:00:09    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4200/4571]  eta: 0:00:08    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [3]  [4220/4571]  eta: 0:00:08    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [4240/4571]  eta: 0:00:07    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4260/4571]  eta: 0:00:07    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [4280/4571]  eta: 0:00:06    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [3]  [4300/4571]  eta: 0:00:06    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [4320/4571]  eta: 0:00:05    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [4340/4571]  eta: 0:00:05    time: 0.0241  data: 0.0227  max mem: 13749
Epoch: [3]  [4360/4571]  eta: 0:00:04    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [4400/4571]  eta: 0:00:03    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [3]  [4420/4571]  eta: 0:00:03    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [3]  [4440/4571]  eta: 0:00:03    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [4460/4571]  eta: 0:00:02    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [4480/4571]  eta: 0:00:02    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4500/4571]  eta: 0:00:01    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [4520/4571]  eta: 0:00:01    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [4540/4571]  eta: 0:00:00    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3] Total time: 0:01:45 (0.0231 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746042139145, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042139146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 172.85484652990434}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746042139148, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2713 (0.2713)  evaluator_time: 0.0029 (0.0029)  time: 0.2753  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2745 (0.2559)  evaluator_time: 0.0035 (0.0032)  time: 0.2601  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2602 s / it)
Averaged stats: model_time: 0.2745 (0.2604)  evaluator_time: 0.0035 (0.0039)
:::MLLOG {"namespace": "", "time_ms": 1746042142972, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:01:39    time: 0.0217  data: 0.0007  max mem: 13749
Epoch: [4]  [  20/4572]  eta: 0:01:46    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [4]  [  40/4572]  eta: 0:01:47    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [4]  [  60/4572]  eta: 0:01:44    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [4]  [  80/4572]  eta: 0:01:44    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [4]  [ 100/4572]  eta: 0:01:43    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [4]  [ 120/4572]  eta: 0:01:42    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [4]  [ 140/4572]  eta: 0:01:41    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [4]  [ 160/4572]  eta: 0:01:40    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [4]  [ 180/4572]  eta: 0:01:40    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [4]  [ 200/4572]  eta: 0:01:39    time: 0.0220  data: 0.0205  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746042147815, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3436837196740527, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746042147816, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746042147997, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1746042147998, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746042147998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 176.97500506089813}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:07:23
:::MLLOG {"namespace": "", "time_ms": 1746042147998, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 783}}
Loading annotations into memory...
Done (t=1.07s)
Creating index...
Done (t=1.29s)
Loading and preparing results...
DONE (t=3.90s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.20s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.19221
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31370
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.20029
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.05153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.21240
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.47720
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.49839
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01976
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17807
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.54421
Loading and preparing results...
DONE (t=2.69s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.53s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28040
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42584
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.29841
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00662
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08114
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31030
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.56060
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.60914
Loading and preparing results...
DONE (t=2.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.44s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.30483
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.44422
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.32908
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00737
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08567
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.33691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.38216
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.54873
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.57322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23881
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.62136
Loading and preparing results...
DONE (t=2.35s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.31s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34368
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.48651
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.36939
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00888
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08793
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38040
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57745
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65551

GPU-419:1893590:1893974 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3
[rank32]:[W430 19:42:29.461917544 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-498:1892639:1893105 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 34, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1892641:1893102 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3
[rank24]:[W430 19:42:29.715666247 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-892:2471846:2472305 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3
[rank16]:[W430 19:42:29.700521739 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-726:2754561:2754962 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3

GPU-753:3649019:3649461 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471926:2472299 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 25, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3

GPU-790:2842254:2842696 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2842218:2842695 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2842218:2842695 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2842218:2842695 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 2, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3649025:3649459 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2754509:2754970 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2471895:2472302 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3

GPU-753:3649026:3649460 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649026:3649460 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3649026:3649460 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3649025:3649459 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3649006:3649462 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649026:3649460 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3649026:3649460 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3649006:3649462 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3649006:3649462 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3649025:3649459 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 58, retcode 3

GPU-498:1892626:1893099 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 37, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 37, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-498:1892641:1893102 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 37, retcode 3

GPU-498:1892626:1893099 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-498:1892626:1893099 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3

GPU-726:2754574:2754963 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 31, retcode 3

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 17, retcode 3

GPU-726:2754574:2754963 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-892:2471908:2472298 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754574:2754963 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 31, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 17, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2471895:2472302 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 31, retcode 3

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 36, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2754509:2754970 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 17, retcode 3

GPU-892:2471908:2472298 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2471908:2472298 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3

GPU-498:1892638:1893101 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1892641:1893102 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1892638:1893101 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1892638:1893101 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1892626:1893099 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1892626:1893099 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 36, retcode 3

GPU-892:2471924:2472304 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2471895:2472302 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2471924:2472304 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2471924:2472304 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2471918:2472301 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2471918:2472301 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2471908:2472298 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2471908:2472298 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2471918:2472301 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2471895:2472302 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2471924:2472304 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2471924:2472304 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2471918:2472301 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2471918:2472301 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2471908:2472298 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2471908:2472298 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 30, retcode 3

GPU-790:2842248:2842690 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2842218:2842695 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2842218:2842695 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2842248:2842690 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2842248:2842690 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3

GPU-419:1893501:1893976 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 41, retcode 3

GPU-726:2754563:2754969 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754559:2754971 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2754574:2754963 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2754574:2754963 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2754574:2754963 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2754574:2754963 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2754509:2754970 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2754509:2754970 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2754563:2754969 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2754563:2754969 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2754563:2754969 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2754563:2754969 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2754559:2754971 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2754559:2754971 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2754559:2754971 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2754559:2754971 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2754568:2754972 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2754574:2754963 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754574:2754963 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2754568:2754972 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754568:2754972 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754509:2754970 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 20, retcode 3

GPU-47:4153804:4154251 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754563:2754969 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754563:2754969 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2754559:2754971 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2754559:2754971 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 20, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 50, retcode 3

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 50, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 49, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 46, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 46, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-419:1893592:1893967 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3

GPU-47:4153826:4154250 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4153782:4154253 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4153782:4154253 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4153762:4154249 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153826:4154250 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4153826:4154250 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4153762:4154249 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4153762:4154249 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4153782:4154253 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4153782:4154253 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4153782:4154253 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 52, retcode 3

GPU-47:4153826:4154250 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4153826:4154250 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 52, retcode 3

GPU-47:4153762:4154249 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4153762:4154249 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 52, retcode 3

GPU-47:4153782:4154253 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4153782:4154253 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3

GPU-47:4153826:4154250 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4153826:4154250 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 52, retcode 3

GPU-47:4153762:4154249 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4153762:4154249 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 52, retcode 3

GPU-47:4153821:4154248 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 55, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 55, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 55, retcode 3

GPU-47:4153782:4154253 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153782:4154253 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 55, retcode 3

GPU-47:4153826:4154250 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153826:4154250 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 55, retcode 3

GPU-47:4153762:4154249 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153762:4154249 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 55, retcode 3

GPU-47:4153821:4154248 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4153821:4154248 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3

GPU-419:1893593:1893968 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1893593:1893968 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1893593:1893968 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1893592:1893967 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1893551:1893969 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1893551:1893969 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1893551:1893969 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1893593:1893968 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1893593:1893968 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1893592:1893967 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 44, retcode 3

GPU-790:2842231:2842693 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2842218:2842695 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2842218:2842695 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2842231:2842693 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2842231:2842693 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2842248:2842690 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2842248:2842690 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2842268:2842691 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2842218:2842695 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842218:2842695 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2842231:2842693 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842231:2842693 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2842268:2842691 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842268:2842691 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2842248:2842690 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2842248:2842690 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 6, retcode 3

GPU-419:1893591:1893966 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1893551:1893969 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1893551:1893969 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1893593:1893968 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1893593:1893968 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1893592:1893967 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 47, retcode 3

GPU-498:1892585:1893104 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1892585:1893104 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1892585:1893104 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1892641:1893102 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1892638:1893101 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1892638:1893101 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1892626:1893099 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1892626:1893099 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3649032:3649465 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649026:3649460 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3649026:3649460 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3649006:3649462 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3649006:3649462 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3649032:3649465 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3649032:3649465 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3649025:3649459 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 59, retcode 3

GPU-498:1892568:1893098 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892585:1893104 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892585:1893104 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892641:1893102 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892638:1893101 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892638:1893101 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892626:1893099 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892626:1893099 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892568:1893098 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1892568:1893098 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1892642:1893100 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1892639:1893105 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892639:1893105 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892585:1893104 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892585:1893104 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892640:1893103 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892640:1893103 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892641:1893102 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892641:1893102 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892638:1893101 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892638:1893101 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892626:1893099 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892626:1893099 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892642:1893100 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892642:1893100 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1892568:1893098 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1892568:1893098 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 38, retcode 3

GPU-892:2471904:2472300 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2471904:2472300 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471904:2472300 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471895:2472302 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2471924:2472304 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471924:2472304 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2471918:2472301 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471918:2472301 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2471908:2472298 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2471908:2472298 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 26, retcode 3

GPU-419:1893591:1893966 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1893591:1893966 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3

GPU-892:2471910:2472303 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2471846:2472305 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471846:2472305 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471926:2472299 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471926:2472299 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471904:2472300 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471904:2472300 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471895:2472302 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471895:2472302 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471910:2472303 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471910:2472303 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471924:2472304 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471924:2472304 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471918:2472301 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471918:2472301 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 28, retcode 3

GPU-892:2471908:2472298 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2471908:2472298 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 28, retcode 3

GPU-726:2754561:2754962 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754561:2754962 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754571:2754964 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2754571:2754964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754571:2754964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754574:2754963 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754574:2754963 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754543:2754968 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754543:2754968 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754568:2754972 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754568:2754972 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754509:2754970 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754509:2754970 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754563:2754969 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754563:2754969 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2754559:2754971 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2754559:2754971 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 18, retcode 3

GPU-419:1893575:1893975 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1893575:1893975 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893575:1893975 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1893551:1893969 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893551:1893969 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1893593:1893968 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893593:1893968 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893592:1893967 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1893591:1893966 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1893591:1893966 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 42, retcode 3
[rank56]:[W430 19:42:29.270123638 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-753:3649029:3649464 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649029:3649464 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3649029:3649464 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3649026:3649460 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3649026:3649460 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3649006:3649462 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3649006:3649462 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3649032:3649465 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3649032:3649465 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3649025:3649459 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 56, retcode 3
[rank48]:[W430 19:42:29.866600331 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-47:4153802:4154246 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4153802:4154246 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153802:4154246 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153804:4154251 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153804:4154251 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153828:4154247 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153828:4154247 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153830:4154252 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153830:4154252 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153782:4154253 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153782:4154253 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153826:4154250 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153826:4154250 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153762:4154249 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153762:4154249 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4153821:4154248 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4153821:4154248 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 48, retcode 3
[rank40]:[W430 19:42:29.820230074 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-419:1893595:1893977 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1893595:1893977 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893595:1893977 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893501:1893976 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893501:1893976 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893575:1893975 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893575:1893975 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893590:1893974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893590:1893974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893551:1893969 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893551:1893969 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893593:1893968 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893593:1893968 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893592:1893967 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893592:1893967 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1893591:1893966 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1893591:1893966 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 40, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 14, retcode 3
[rank8]:[W430 19:42:29.754972369 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-1006:2794253:2794637 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794253:2794637 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2794253:2794637 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2794234:2794631 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794253:2794637 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2794253:2794637 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2794234:2794631 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2794234:2794631 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2794231:2794635 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794253:2794637 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2794253:2794637 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2794234:2794631 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2794234:2794631 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2794231:2794635 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2794231:2794635 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2794250:2794630 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794253:2794637 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2794253:2794637 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2794234:2794631 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2794234:2794631 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2794250:2794630 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2794250:2794630 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2794231:2794635 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2794231:2794635 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2794247:2794634 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794253:2794637 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794253:2794637 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2794234:2794631 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794234:2794631 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2794250:2794630 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794250:2794630 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2794247:2794634 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794247:2794634 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2794231:2794635 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794231:2794635 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 12, retcode 3

GPU-753:3649011:3649463 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3649029:3649464 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649029:3649464 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 60, retcode 3

GPU-753:3649026:3649460 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649026:3649460 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 60, retcode 3

GPU-753:3649006:3649462 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649006:3649462 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 60, retcode 3

GPU-753:3649032:3649465 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649032:3649465 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 60, retcode 3

GPU-753:3649011:3649463 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649011:3649463 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3

GPU-753:3649019:3649461 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649019:3649461 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 60, retcode 3

GPU-753:3648937:3649458 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3648937:3649458 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 60, retcode 3

GPU-1006:2794238:2794632 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2794253:2794637 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794253:2794637 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794234:2794631 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794234:2794631 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794250:2794630 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794250:2794630 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794238:2794632 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794238:2794632 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794247:2794634 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794247:2794634 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794231:2794635 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794231:2794635 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794249:2794636 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794249:2794636 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2794159:2794633 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2794159:2794633 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 11, retcode 3

GPU-753:3649025:3649459 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3649025:3649459 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 60, retcode 3
[rank0]:[W430 19:42:30.610109841 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-790:2842250:2842697 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2842250:2842697 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842250:2842697 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842254:2842696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842254:2842696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842218:2842695 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842218:2842695 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842195:2842692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842195:2842692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842231:2842693 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842231:2842693 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842221:2842694 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842221:2842694 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842268:2842691 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842268:2842691 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2842248:2842690 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2842248:2842690 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 0, retcode 3
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:33 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:34 PM
RESULT,SINGLE_STAGE_DETECTOR,,540,nvidia,2025-04-30 07:33:34 PM
ENDING TIMING RUN AT 2025-04-30 07:42:35 PM
RESULT,SINGLE_STAGE_DETECTOR,,541,nvidia,2025-04-30 07:33:34 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746042155'
RUNANDTIME_STOP 1746042155
+ set -e
