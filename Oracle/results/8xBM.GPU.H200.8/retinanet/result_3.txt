+ echo 'Beginning trial 3 of 3'
Beginning trial 3 of 3
+ echo ':::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 381 8 GPU-[790,1006,726,892,498,419,47,753] '\''unknown'\'' DGXH100_008x08x004'
:::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 381 8 GPU-[790,1006,726,892,498,419,47,753] 'unknown' DGXH100_008x08x004
++ srun --ntasks=1 --container-name=single_stage_detector_381 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=single_stage_detector_381 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
:::GITCOMMITID  
+ srun -N1 -n1 --container-name=single_stage_detector_381 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on GPU-790
Clearing cache on GPU-419
Clearing cache on GPU-47
Clearing cache on GPU-1006
Clearing cache on GPU-892
Clearing cache on GPU-726
Clearing cache on GPU-498
Clearing cache on GPU-753
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector_381 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746042877036, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877066, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877094, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877130, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877132, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877139, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877142, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746042877159, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746042907'
RUNANDTIME_START 1746042907
+ srun --ntasks=64 --ntasks-per-node=8 --time=20 --container-name=single_stage_detector_381 --container-mounts=/mnt/localdisk5/mlperf/ssd/data/open-images-v6:/datasets/open-images-v6,/home/ubuntu/sd/ssd/log:/results,/mnt/localdisk5/mlperf/ssd/data/torch-home/hub/checkpoints:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 56: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 56, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 59: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 59, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 61: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 61, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 60: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 60, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
RANK 62: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 62, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 58: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 58, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 63: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 63, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 57: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 57, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 52: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 52, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 50: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 50, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 48: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 48, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 55: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 55, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 54: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 54, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 51: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 51, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 49: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 49, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 53: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 53, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 25: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 29: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 18: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 21: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 22: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 16: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 1: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 40: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 40, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 43: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 43, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 41: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 41, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 42: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 42, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 45: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 45, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 46: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 46, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 47: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 47, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 44: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 44, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
RANK 37: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 37, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 34: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 34, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 35: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 35, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 38: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 38, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 36: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 36, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 33: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 33, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 39: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 39, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 07:55:13 PM
RANK 32: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 381, SLURM_NTASKS 64, SLURM_PROCID 32, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
| distributed init (rank 56): env://
| distributed init (rank 62): env://
| distributed init (rank 59): env://
| distributed init (rank 40): env://
| distributed init (rank 4): env://
[W430 19:55:18.605948109 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.606358119 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.606736957 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.607119511 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.607489323 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.607867628 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.608244555 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.608625191 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.608981345 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
[W430 19:55:18.609363315 socket.cpp:752] [c10d] The client socket has failed to connect to [GPU-790]:29500 (errno: 22 - Invalid argument).
| distributed init (rank 0): env://
| distributed init (rank 8): env://
[W430 19:55:18.037441189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 58): env://
| distributed init (rank 61): env://
[W430 19:55:18.611308123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.612610961 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 57): env://
| distributed init (rank 60): env://
[W430 19:55:18.629056762 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.629389397 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 44): env://
[W430 19:55:18.157173788 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 63): env://
[W430 19:55:18.644791553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 2): env://
[W430 19:55:18.689330177 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 42): env://
[W430 19:55:18.196770650 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 6): env://
[W430 19:55:18.730796167 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 5): env://
[W430 19:55:18.733862701 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 1): env://
| distributed init (rank 3): env://
[W430 19:55:18.751441763 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 7): env://
[W430 19:55:18.752353459 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.752831238 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 43): env://
| distributed init (rank 45): env://
| distributed init (rank 46): env://
[W430 19:55:18.250010564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.250194894 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 41): env://
| distributed init (rank 47): env://
[W430 19:55:18.250776443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.251605235 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.251991590 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 31): env://
[W430 19:55:18.319700515 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 24): env://
| distributed init (rank 29): env://
[W430 19:55:18.321342598 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.322480999 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 27): env://
[W430 19:55:18.330751832 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 9): env://
[W430 19:55:18.237728555 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 15): env://
[W430 19:55:18.265895111 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 13): env://
[W430 19:55:18.272785318 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 10): env://
| distributed init (rank 14): env://
[W430 19:55:18.275840264 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.275849237 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.839038291 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 12): env://
[W430 19:55:18.286448960 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 11): env://
[W430 19:55:18.292680069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 28): env://
[W430 19:55:18.438301714 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 30): env://
[W430 19:55:18.462817701 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:18.927191037 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 25): env://
[W430 19:55:18.537596332 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 26): env://
[W430 19:55:18.540761868 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 32): env://
[W430 19:55:19.522789810 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.282382081 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.773908744 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.260356187 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 38): env://
| distributed init (rank 33): env://
| distributed init (rank 36): env://
[W430 19:55:19.644869837 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.644900105 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.645034080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 34): env://
[W430 19:55:19.682662825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 39): env://
[W430 19:55:19.695597521 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 37): env://
[W430 19:55:19.726560819 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 35): env://
[W430 19:55:19.729267443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 16): env://
[W430 19:55:19.948941651 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 48): env://
[W430 19:55:19.049842745 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 18): env://
[W430 19:55:19.027918120 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 19): env://
[W430 19:55:19.033950865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 17): env://
[W430 19:55:19.093427953 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 21): env://
[W430 19:55:19.102346301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 22): env://
[W430 19:55:19.114584822 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 23): env://
[W430 19:55:19.124313040 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 20): env://
[W430 19:55:19.132933855 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 54): env://
[W430 19:55:19.278093719 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 53): env://
[W430 19:55:19.282344991 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 50): env://
[W430 19:55:19.306947503 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 55): env://
| distributed init (rank 52): env://
| distributed init (rank 49): env://
[W430 19:55:19.308414633 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.309145918 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.309233280 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 51): env://
[W430 19:55:19.323875630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 19:55:19.779648949 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
NCCL version 2.22.3+cuda12.6
:::MLLOG {"namespace": "", "time_ms": 1746042922605, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "retinanet", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746042922605, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746042922605, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746042922605, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746042922605, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746042922606, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1746042922638, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3093644180, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1746042922638, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 4, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1746042922638, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1746042922638, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1746042922638, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=64, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=4, eval_batch_size=32, lr=0.0001, warmup_epochs=1, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=3093644180, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=64, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=False, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=0, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], num_train_ranks=64, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1746042922647, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922666, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922667, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922669, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922806, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922806, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922807, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922807, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922807, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922807, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922807, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922807, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922808, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922808, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922808, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922808, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922809, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922809, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922809, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922810, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922811, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922811, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922811, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922812, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922812, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922813, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922814, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922816, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922816, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922818, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922821, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922824, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922826, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922829, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922829, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922831, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922834, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922834, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922837, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922839, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922842, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922844, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922845, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922847, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922852, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922853, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922862, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922871, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922881, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922882, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922891, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922900, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042922902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923084, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923087, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923087, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923092, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923092, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923095, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923117, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923117, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923120, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923122, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923144, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923167, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923178, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923178, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923179, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923181, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923181, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923184, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923184, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923187, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923187, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746042923189, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
:::MLLOG {"namespace": "", "time_ms": 1746042923292, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1746042923292, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1746042923292, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1746042923292, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1746042923292, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1746042923292, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Time: 53.34422063827515 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1746043001612, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1746043001614, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 579}}
:::MLLOG {"namespace": "", "time_ms": 1746043001614, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1746043001614, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 13, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 636}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1746043001615, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:01:20    time: 0.0176  data: 0.0002  max mem: 13749
Epoch: [0]  [  20/4572]  eta: 0:01:38    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [  40/4572]  eta: 0:01:38    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [0]  [  60/4572]  eta: 0:01:39    time: 0.0226  data: 0.0207  max mem: 13749
Epoch: [0]  [  80/4572]  eta: 0:01:42    time: 0.0246  data: 0.0230  max mem: 13749
Epoch: [0]  [ 100/4572]  eta: 0:01:42    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [0]  [ 120/4572]  eta: 0:01:43    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [0]  [ 140/4572]  eta: 0:01:43    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [0]  [ 160/4572]  eta: 0:01:42    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [ 180/4572]  eta: 0:01:42    time: 0.0233  data: 0.0208  max mem: 13749
Epoch: [0]  [ 200/4572]  eta: 0:01:41    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [0]  [ 220/4572]  eta: 0:01:40    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [ 240/4572]  eta: 0:01:39    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [0]  [ 260/4572]  eta: 0:01:39    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [ 280/4572]  eta: 0:01:38    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [ 300/4572]  eta: 0:01:38    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [ 320/4572]  eta: 0:01:37    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [ 340/4572]  eta: 0:01:37    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [ 360/4572]  eta: 0:01:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 380/4572]  eta: 0:01:36    time: 0.0250  data: 0.0226  max mem: 13749
Epoch: [0]  [ 400/4572]  eta: 0:01:36    time: 0.0253  data: 0.0229  max mem: 13749
Epoch: [0]  [ 420/4572]  eta: 0:01:36    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [0]  [ 440/4572]  eta: 0:01:35    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [ 460/4572]  eta: 0:01:35    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [ 480/4572]  eta: 0:01:34    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [ 500/4572]  eta: 0:01:34    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 520/4572]  eta: 0:01:34    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [ 540/4572]  eta: 0:01:33    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [ 560/4572]  eta: 0:01:33    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [0]  [ 580/4572]  eta: 0:01:32    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [0]  [ 600/4572]  eta: 0:01:32    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [0]  [ 620/4572]  eta: 0:01:31    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [ 640/4572]  eta: 0:01:30    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [ 660/4572]  eta: 0:01:30    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [0]  [ 680/4572]  eta: 0:01:30    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 700/4572]  eta: 0:01:29    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 720/4572]  eta: 0:01:29    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [0]  [ 740/4572]  eta: 0:01:28    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [0]  [ 760/4572]  eta: 0:01:28    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [ 780/4572]  eta: 0:01:27    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [ 800/4572]  eta: 0:01:27    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [0]  [ 820/4572]  eta: 0:01:26    time: 0.0230  data: 0.0211  max mem: 13749
Epoch: [0]  [ 840/4572]  eta: 0:01:26    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [ 860/4572]  eta: 0:01:25    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [ 880/4572]  eta: 0:01:25    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [ 900/4572]  eta: 0:01:24    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [ 920/4572]  eta: 0:01:24    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [ 940/4572]  eta: 0:01:23    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [ 960/4572]  eta: 0:01:23    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 980/4572]  eta: 0:01:22    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1000/4572]  eta: 0:01:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1020/4572]  eta: 0:01:21    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [0]  [1040/4572]  eta: 0:01:21    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1060/4572]  eta: 0:01:21    time: 0.0244  data: 0.0228  max mem: 13749
Epoch: [0]  [1080/4572]  eta: 0:01:20    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [1100/4572]  eta: 0:01:20    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [1120/4572]  eta: 0:01:19    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [0]  [1140/4572]  eta: 0:01:19    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1160/4572]  eta: 0:01:18    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1180/4572]  eta: 0:01:18    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1200/4572]  eta: 0:01:17    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1220/4572]  eta: 0:01:17    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [1240/4572]  eta: 0:01:16    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [1260/4572]  eta: 0:01:16    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [0]  [1280/4572]  eta: 0:01:16    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [1300/4572]  eta: 0:01:15    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [0]  [1320/4572]  eta: 0:01:14    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [0]  [1340/4572]  eta: 0:01:14    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [1360/4572]  eta: 0:01:14    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1380/4572]  eta: 0:01:13    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [1400/4572]  eta: 0:01:13    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1420/4572]  eta: 0:01:12    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [1440/4572]  eta: 0:01:12    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0]  [1460/4572]  eta: 0:01:11    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [0]  [1480/4572]  eta: 0:01:11    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1500/4572]  eta: 0:01:10    time: 0.0249  data: 0.0234  max mem: 13749
Epoch: [0]  [1520/4572]  eta: 0:01:10    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1540/4572]  eta: 0:01:09    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [0]  [1560/4572]  eta: 0:01:09    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1580/4572]  eta: 0:01:08    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [1600/4572]  eta: 0:01:08    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [0]  [1620/4572]  eta: 0:01:08    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [1640/4572]  eta: 0:01:07    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1660/4572]  eta: 0:01:07    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [0]  [1680/4572]  eta: 0:01:06    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1700/4572]  eta: 0:01:06    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1720/4572]  eta: 0:01:05    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [1740/4572]  eta: 0:01:05    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1760/4572]  eta: 0:01:04    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [1780/4572]  eta: 0:01:04    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [1800/4572]  eta: 0:01:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [1820/4572]  eta: 0:01:03    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [1840/4572]  eta: 0:01:03    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0]  [1860/4572]  eta: 0:01:02    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [0]  [1880/4572]  eta: 0:01:02    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1900/4572]  eta: 0:01:01    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [1920/4572]  eta: 0:01:01    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [1940/4572]  eta: 0:01:00    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [1960/4572]  eta: 0:01:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [1980/4572]  eta: 0:00:59    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2000/4572]  eta: 0:00:59    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [2020/4572]  eta: 0:00:58    time: 0.0222  data: 0.0203  max mem: 13749
Epoch: [0]  [2040/4572]  eta: 0:00:58    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [2060/4572]  eta: 0:00:57    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [2080/4572]  eta: 0:00:57    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2100/4572]  eta: 0:00:57    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [0]  [2120/4572]  eta: 0:00:56    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2140/4572]  eta: 0:00:56    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [2160/4572]  eta: 0:00:55    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [2180/4572]  eta: 0:00:55    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [0]  [2200/4572]  eta: 0:00:54    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2220/4572]  eta: 0:00:54    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2240/4572]  eta: 0:00:53    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [2260/4572]  eta: 0:00:53    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [2280/4572]  eta: 0:00:52    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [0]  [2300/4572]  eta: 0:00:52    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [0]  [2320/4572]  eta: 0:00:51    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2340/4572]  eta: 0:00:51    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [2360/4572]  eta: 0:00:51    time: 0.0244  data: 0.0219  max mem: 13749
Epoch: [0]  [2380/4572]  eta: 0:00:50    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [2400/4572]  eta: 0:00:50    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [2420/4572]  eta: 0:00:49    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [2440/4572]  eta: 0:00:49    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [2460/4572]  eta: 0:00:48    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [2480/4572]  eta: 0:00:48    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2500/4572]  eta: 0:00:47    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2520/4572]  eta: 0:00:47    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2540/4572]  eta: 0:00:46    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2560/4572]  eta: 0:00:46    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [0]  [2580/4572]  eta: 0:00:45    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2600/4572]  eta: 0:00:45    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2620/4572]  eta: 0:00:44    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [2640/4572]  eta: 0:00:44    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2660/4572]  eta: 0:00:44    time: 0.0254  data: 0.0239  max mem: 13749
Epoch: [0]  [2680/4572]  eta: 0:00:43    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2700/4572]  eta: 0:00:43    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2720/4572]  eta: 0:00:42    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2740/4572]  eta: 0:00:42    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [2760/4572]  eta: 0:00:41    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2780/4572]  eta: 0:00:41    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [2800/4572]  eta: 0:00:40    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [2820/4572]  eta: 0:00:40    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [2840/4572]  eta: 0:00:39    time: 0.0243  data: 0.0229  max mem: 13749
Epoch: [0]  [2860/4572]  eta: 0:00:39    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2880/4572]  eta: 0:00:39    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2900/4572]  eta: 0:00:38    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [2920/4572]  eta: 0:00:38    time: 0.0238  data: 0.0221  max mem: 13749
Epoch: [0]  [2940/4572]  eta: 0:00:37    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [2960/4572]  eta: 0:00:37    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [2980/4572]  eta: 0:00:36    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [0]  [3000/4572]  eta: 0:00:36    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3020/4572]  eta: 0:00:35    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3040/4572]  eta: 0:00:35    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [0]  [3060/4572]  eta: 0:00:34    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3080/4572]  eta: 0:00:34    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [3100/4572]  eta: 0:00:33    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3120/4572]  eta: 0:00:33    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [3140/4572]  eta: 0:00:33    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [0]  [3160/4572]  eta: 0:00:32    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [3180/4572]  eta: 0:00:32    time: 0.0234  data: 0.0220  max mem: 13749
Epoch: [0]  [3200/4572]  eta: 0:00:31    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [3220/4572]  eta: 0:00:31    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [0]  [3240/4572]  eta: 0:00:30    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [3260/4572]  eta: 0:00:30    time: 0.0239  data: 0.0217  max mem: 13749
Epoch: [0]  [3280/4572]  eta: 0:00:29    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [3300/4572]  eta: 0:00:29    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [3320/4572]  eta: 0:00:28    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [3340/4572]  eta: 0:00:28    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [0]  [3360/4572]  eta: 0:00:27    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3380/4572]  eta: 0:00:27    time: 0.0236  data: 0.0217  max mem: 13749
Epoch: [0]  [3400/4572]  eta: 0:00:27    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [3420/4572]  eta: 0:00:26    time: 0.0231  data: 0.0210  max mem: 13749
Epoch: [0]  [3440/4572]  eta: 0:00:26    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [0]  [3460/4572]  eta: 0:00:25    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [3480/4572]  eta: 0:00:25    time: 0.0235  data: 0.0213  max mem: 13749
Epoch: [0]  [3500/4572]  eta: 0:00:24    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [3520/4572]  eta: 0:00:24    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [0]  [3540/4572]  eta: 0:00:23    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3560/4572]  eta: 0:00:23    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3580/4572]  eta: 0:00:22    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [0]  [3600/4572]  eta: 0:00:22    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [3620/4572]  eta: 0:00:21    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [3640/4572]  eta: 0:00:21    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3660/4572]  eta: 0:00:21    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3680/4572]  eta: 0:00:20    time: 0.0245  data: 0.0220  max mem: 13749
Epoch: [0]  [3700/4572]  eta: 0:00:20    time: 0.0241  data: 0.0227  max mem: 13749
Epoch: [0]  [3720/4572]  eta: 0:00:19    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [0]  [3740/4572]  eta: 0:00:19    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [3760/4572]  eta: 0:00:18    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3780/4572]  eta: 0:00:18    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3800/4572]  eta: 0:00:17    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3820/4572]  eta: 0:00:17    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [3840/4572]  eta: 0:00:16    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [3860/4572]  eta: 0:00:16    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3880/4572]  eta: 0:00:15    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3900/4572]  eta: 0:00:15    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [0]  [3920/4572]  eta: 0:00:15    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [3940/4572]  eta: 0:00:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3960/4572]  eta: 0:00:14    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [3980/4572]  eta: 0:00:13    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [4000/4572]  eta: 0:00:13    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [0]  [4020/4572]  eta: 0:00:12    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [0]  [4040/4572]  eta: 0:00:12    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [0]  [4060/4572]  eta: 0:00:11    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [4080/4572]  eta: 0:00:11    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [4100/4572]  eta: 0:00:10    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [4120/4572]  eta: 0:00:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [4140/4572]  eta: 0:00:09    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [4160/4572]  eta: 0:00:09    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [4180/4572]  eta: 0:00:09    time: 0.0229  data: 0.0206  max mem: 13749
Epoch: [0]  [4200/4572]  eta: 0:00:08    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [4220/4572]  eta: 0:00:08    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [4240/4572]  eta: 0:00:07    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4280/4572]  eta: 0:00:06    time: 0.0238  data: 0.0218  max mem: 13749
Epoch: [0]  [4300/4572]  eta: 0:00:06    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [4320/4572]  eta: 0:00:05    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [4340/4572]  eta: 0:00:05    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4360/4572]  eta: 0:00:04    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4380/4572]  eta: 0:00:04    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [4400/4572]  eta: 0:00:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [4420/4572]  eta: 0:00:03    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [4440/4572]  eta: 0:00:03    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4460/4572]  eta: 0:00:02    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [4480/4572]  eta: 0:00:02    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [0]  [4500/4572]  eta: 0:00:01    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [4520/4572]  eta: 0:00:01    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4540/4572]  eta: 0:00:00    time: 0.0237  data: 0.0223  max mem: 13749
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0247  data: 0.0231  max mem: 13749
Epoch: [0] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746043106912, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1746043106912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 173.72916511852176}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746043106915, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/13]  eta: 0:00:06  model_time: 0.5110 (0.5110)  evaluator_time: 0.0055 (0.0055)  time: 0.5232  data: 0.0005  max mem: 13749
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [12/13]  eta: 0:00:00  model_time: 0.3528 (0.3386)  evaluator_time: 0.0053 (0.0049)  time: 0.3450  data: 0.0008  max mem: 13749
Test: Total time: 0:00:04 (0.3450 s / it)
Averaged stats: model_time: 0.3528 (0.3455)  evaluator_time: 0.0053 (0.0049)
:::MLLOG {"namespace": "", "time_ms": 1746043112048, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:01:38    time: 0.0215  data: 0.0008  max mem: 13749
Epoch: [1]  [  20/4571]  eta: 0:01:41    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [  40/4571]  eta: 0:01:45    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [1]  [  60/4571]  eta: 0:01:43    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [  80/4571]  eta: 0:01:41    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [ 100/4571]  eta: 0:01:41    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 120/4571]  eta: 0:01:42    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [ 140/4571]  eta: 0:01:43    time: 0.0252  data: 0.0225  max mem: 13749
Epoch: [1]  [ 160/4571]  eta: 0:01:43    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [1]  [ 180/4571]  eta: 0:01:43    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [ 200/4571]  eta: 0:01:41    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [ 220/4571]  eta: 0:01:41    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [ 240/4571]  eta: 0:01:41    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [1]  [ 260/4571]  eta: 0:01:40    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [ 280/4571]  eta: 0:01:40    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [1]  [ 300/4571]  eta: 0:01:39    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [1]  [ 320/4571]  eta: 0:01:38    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [ 340/4571]  eta: 0:01:38    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [1]  [ 360/4571]  eta: 0:01:38    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [1]  [ 380/4571]  eta: 0:01:37    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [ 400/4571]  eta: 0:01:36    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [ 420/4571]  eta: 0:01:36    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 440/4571]  eta: 0:01:35    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [ 460/4571]  eta: 0:01:35    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [ 480/4571]  eta: 0:01:34    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [ 500/4571]  eta: 0:01:34    time: 0.0225  data: 0.0208  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746043123898, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.19577096049931944, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746043123899, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 520/4571]  eta: 0:01:33    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [ 540/4571]  eta: 0:01:33    time: 0.0239  data: 0.0220  max mem: 13749
Epoch: [1]  [ 560/4571]  eta: 0:01:32    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 580/4571]  eta: 0:01:32    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 600/4571]  eta: 0:01:31    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [ 620/4571]  eta: 0:01:31    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [ 640/4571]  eta: 0:01:30    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 660/4571]  eta: 0:01:30    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [ 680/4571]  eta: 0:01:29    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [ 700/4571]  eta: 0:01:29    time: 0.0231  data: 0.0211  max mem: 13749
Epoch: [1]  [ 720/4571]  eta: 0:01:28    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [ 740/4571]  eta: 0:01:28    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [ 760/4571]  eta: 0:01:27    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [ 780/4571]  eta: 0:01:27    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [ 800/4571]  eta: 0:01:26    time: 0.0223  data: 0.0204  max mem: 13749
Epoch: [1]  [ 820/4571]  eta: 0:01:26    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [ 840/4571]  eta: 0:01:26    time: 0.0247  data: 0.0228  max mem: 13749
Epoch: [1]  [ 860/4571]  eta: 0:01:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [ 880/4571]  eta: 0:01:25    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [ 900/4571]  eta: 0:01:24    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [ 920/4571]  eta: 0:01:24    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [1]  [ 940/4571]  eta: 0:01:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [ 960/4571]  eta: 0:01:23    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [ 980/4571]  eta: 0:01:22    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [1000/4571]  eta: 0:01:22    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1020/4571]  eta: 0:01:21    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [1040/4571]  eta: 0:01:21    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1060/4571]  eta: 0:01:20    time: 0.0224  data: 0.0200  max mem: 13749
Epoch: [1]  [1080/4571]  eta: 0:01:20    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1100/4571]  eta: 0:01:20    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [1120/4571]  eta: 0:01:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1140/4571]  eta: 0:01:18    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1160/4571]  eta: 0:01:18    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1180/4571]  eta: 0:01:18    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [1200/4571]  eta: 0:01:17    time: 0.0234  data: 0.0212  max mem: 13749
Epoch: [1]  [1220/4571]  eta: 0:01:17    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [1240/4571]  eta: 0:01:16    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1260/4571]  eta: 0:01:16    time: 0.0243  data: 0.0219  max mem: 13749
Epoch: [1]  [1280/4571]  eta: 0:01:15    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1300/4571]  eta: 0:01:15    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1320/4571]  eta: 0:01:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1340/4571]  eta: 0:01:14    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1360/4571]  eta: 0:01:13    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [1380/4571]  eta: 0:01:13    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [1]  [1400/4571]  eta: 0:01:12    time: 0.0227  data: 0.0207  max mem: 13749
Epoch: [1]  [1420/4571]  eta: 0:01:12    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1440/4571]  eta: 0:01:12    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1460/4571]  eta: 0:01:11    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [1]  [1480/4571]  eta: 0:01:11    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1500/4571]  eta: 0:01:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [1520/4571]  eta: 0:01:10    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [1540/4571]  eta: 0:01:09    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [1560/4571]  eta: 0:01:09    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [1580/4571]  eta: 0:01:08    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [1600/4571]  eta: 0:01:08    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [1]  [1620/4571]  eta: 0:01:07    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [1640/4571]  eta: 0:01:07    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [1]  [1660/4571]  eta: 0:01:06    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [1680/4571]  eta: 0:01:06    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1700/4571]  eta: 0:01:05    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [1]  [1720/4571]  eta: 0:01:05    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [1]  [1740/4571]  eta: 0:01:05    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [1]  [1760/4571]  eta: 0:01:04    time: 0.0221  data: 0.0203  max mem: 13749
Epoch: [1]  [1780/4571]  eta: 0:01:04    time: 0.0219  data: 0.0195  max mem: 13749
Epoch: [1]  [1800/4571]  eta: 0:01:03    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [1820/4571]  eta: 0:01:03    time: 0.0237  data: 0.0217  max mem: 13749
Epoch: [1]  [1840/4571]  eta: 0:01:02    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1860/4571]  eta: 0:01:02    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1880/4571]  eta: 0:01:01    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1900/4571]  eta: 0:01:01    time: 0.0252  data: 0.0231  max mem: 13749
Epoch: [1]  [1920/4571]  eta: 0:01:00    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [1940/4571]  eta: 0:01:00    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [1960/4571]  eta: 0:01:00    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [1980/4571]  eta: 0:00:59    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [2000/4571]  eta: 0:00:59    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2020/4571]  eta: 0:00:58    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2060/4571]  eta: 0:00:57    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2080/4571]  eta: 0:00:57    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2100/4571]  eta: 0:00:56    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [2120/4571]  eta: 0:00:56    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2140/4571]  eta: 0:00:55    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2160/4571]  eta: 0:00:55    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2180/4571]  eta: 0:00:54    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [2200/4571]  eta: 0:00:54    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [2220/4571]  eta: 0:00:54    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [1]  [2240/4571]  eta: 0:00:53    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2260/4571]  eta: 0:00:53    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [1]  [2280/4571]  eta: 0:00:52    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [2300/4571]  eta: 0:00:52    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [2320/4571]  eta: 0:00:51    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2340/4571]  eta: 0:00:51    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [2360/4571]  eta: 0:00:50    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [2380/4571]  eta: 0:00:50    time: 0.0234  data: 0.0214  max mem: 13749
Epoch: [1]  [2400/4571]  eta: 0:00:49    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2420/4571]  eta: 0:00:49    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [2440/4571]  eta: 0:00:48    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [2460/4571]  eta: 0:00:48    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [1]  [2480/4571]  eta: 0:00:48    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2500/4571]  eta: 0:00:47    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2520/4571]  eta: 0:00:47    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [2540/4571]  eta: 0:00:46    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [2560/4571]  eta: 0:00:46    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [1]  [2580/4571]  eta: 0:00:45    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2600/4571]  eta: 0:00:45    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [2620/4571]  eta: 0:00:44    time: 0.0224  data: 0.0205  max mem: 13749
Epoch: [1]  [2640/4571]  eta: 0:00:44    time: 0.0241  data: 0.0224  max mem: 13749
Epoch: [1]  [2660/4571]  eta: 0:00:43    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2680/4571]  eta: 0:00:43    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2700/4571]  eta: 0:00:42    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [2720/4571]  eta: 0:00:42    time: 0.0221  data: 0.0201  max mem: 13749
Epoch: [1]  [2740/4571]  eta: 0:00:42    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2760/4571]  eta: 0:00:41    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2780/4571]  eta: 0:00:41    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [2800/4571]  eta: 0:00:40    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [2820/4571]  eta: 0:00:40    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [1]  [2840/4571]  eta: 0:00:39    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2860/4571]  eta: 0:00:39    time: 0.0257  data: 0.0242  max mem: 13749
Epoch: [1]  [2880/4571]  eta: 0:00:38    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2900/4571]  eta: 0:00:38    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2920/4571]  eta: 0:00:37    time: 0.0225  data: 0.0206  max mem: 13749
Epoch: [1]  [2940/4571]  eta: 0:00:37    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2960/4571]  eta: 0:00:37    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [2980/4571]  eta: 0:00:36    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [3000/4571]  eta: 0:00:36    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [3020/4571]  eta: 0:00:35    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [1]  [3040/4571]  eta: 0:00:35    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [3060/4571]  eta: 0:00:34    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [3080/4571]  eta: 0:00:34    time: 0.0220  data: 0.0194  max mem: 13749
Epoch: [1]  [3100/4571]  eta: 0:00:33    time: 0.0231  data: 0.0213  max mem: 13749
Epoch: [1]  [3120/4571]  eta: 0:00:33    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [1]  [3140/4571]  eta: 0:00:32    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3160/4571]  eta: 0:00:32    time: 0.0253  data: 0.0238  max mem: 13749
Epoch: [1]  [3180/4571]  eta: 0:00:31    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [3200/4571]  eta: 0:00:31    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [1]  [3220/4571]  eta: 0:00:31    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [3240/4571]  eta: 0:00:30    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [3260/4571]  eta: 0:00:30    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3280/4571]  eta: 0:00:29    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [3300/4571]  eta: 0:00:29    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3320/4571]  eta: 0:00:28    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3340/4571]  eta: 0:00:28    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [3360/4571]  eta: 0:00:27    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [1]  [3380/4571]  eta: 0:00:27    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [3400/4571]  eta: 0:00:26    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3420/4571]  eta: 0:00:26    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [1]  [3440/4571]  eta: 0:00:26    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3460/4571]  eta: 0:00:25    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [1]  [3480/4571]  eta: 0:00:25    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [3500/4571]  eta: 0:00:24    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [3520/4571]  eta: 0:00:24    time: 0.0232  data: 0.0211  max mem: 13749
Epoch: [1]  [3540/4571]  eta: 0:00:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [3560/4571]  eta: 0:00:23    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [3580/4571]  eta: 0:00:22    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [3600/4571]  eta: 0:00:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3620/4571]  eta: 0:00:21    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [1]  [3640/4571]  eta: 0:00:21    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [3660/4571]  eta: 0:00:20    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3680/4571]  eta: 0:00:20    time: 0.0228  data: 0.0204  max mem: 13749
Epoch: [1]  [3700/4571]  eta: 0:00:20    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [3720/4571]  eta: 0:00:19    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [1]  [3740/4571]  eta: 0:00:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3760/4571]  eta: 0:00:18    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3780/4571]  eta: 0:00:18    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [3800/4571]  eta: 0:00:17    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3820/4571]  eta: 0:00:17    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3840/4571]  eta: 0:00:16    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [1]  [3860/4571]  eta: 0:00:16    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [3880/4571]  eta: 0:00:15    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [3900/4571]  eta: 0:00:15    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3920/4571]  eta: 0:00:14    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [1]  [3940/4571]  eta: 0:00:14    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3960/4571]  eta: 0:00:14    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [1]  [3980/4571]  eta: 0:00:13    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [4000/4571]  eta: 0:00:13    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [4020/4571]  eta: 0:00:12    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [4040/4571]  eta: 0:00:12    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [4060/4571]  eta: 0:00:11    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [4080/4571]  eta: 0:00:11    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [4100/4571]  eta: 0:00:10    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [4120/4571]  eta: 0:00:10    time: 0.0226  data: 0.0205  max mem: 13749
Epoch: [1]  [4140/4571]  eta: 0:00:09    time: 0.0242  data: 0.0216  max mem: 13749
Epoch: [1]  [4160/4571]  eta: 0:00:09    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [4180/4571]  eta: 0:00:08    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [4200/4571]  eta: 0:00:08    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [4220/4571]  eta: 0:00:08    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [4240/4571]  eta: 0:00:07    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [4260/4571]  eta: 0:00:07    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [1]  [4280/4571]  eta: 0:00:06    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [4300/4571]  eta: 0:00:06    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [4320/4571]  eta: 0:00:05    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [4340/4571]  eta: 0:00:05    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [4360/4571]  eta: 0:00:04    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [4400/4571]  eta: 0:00:03    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [1]  [4420/4571]  eta: 0:00:03    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [4440/4571]  eta: 0:00:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [4460/4571]  eta: 0:00:02    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [4480/4571]  eta: 0:00:02    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [4500/4571]  eta: 0:00:01    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [4520/4571]  eta: 0:00:01    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [4540/4571]  eta: 0:00:00    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0249  data: 0.0235  max mem: 13749
Epoch: [1] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746043217150, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746043217150, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.01729425516308}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746043217153, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2824 (0.2824)  evaluator_time: 0.0033 (0.0033)  time: 0.2867  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2790 (0.2622)  evaluator_time: 0.0035 (0.0034)  time: 0.2666  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2667 s / it)
Averaged stats: model_time: 0.2790 (0.2690)  evaluator_time: 0.0035 (0.0035)
:::MLLOG {"namespace": "", "time_ms": 1746043221110, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:01:34    time: 0.0208  data: 0.0007  max mem: 13749
Epoch: [2]  [  20/4572]  eta: 0:01:42    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [  40/4572]  eta: 0:01:40    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [  60/4572]  eta: 0:01:40    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [  80/4572]  eta: 0:01:40    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [ 100/4572]  eta: 0:01:40    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [ 120/4572]  eta: 0:01:40    time: 0.0229  data: 0.0212  max mem: 13749
Epoch: [2]  [ 140/4572]  eta: 0:01:39    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [ 160/4572]  eta: 0:01:39    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [ 180/4572]  eta: 0:01:38    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [ 200/4572]  eta: 0:01:37    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [ 220/4572]  eta: 0:01:37    time: 0.0224  data: 0.0208  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746043226401, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2814146291725968, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746043226402, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 240/4572]  eta: 0:01:36    time: 0.0221  data: 0.0204  max mem: 13749
Epoch: [2]  [ 260/4572]  eta: 0:01:36    time: 0.0227  data: 0.0208  max mem: 13749
Epoch: [2]  [ 280/4572]  eta: 0:01:36    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [ 300/4572]  eta: 0:01:36    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [2]  [ 320/4572]  eta: 0:01:35    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [ 340/4572]  eta: 0:01:35    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [ 360/4572]  eta: 0:01:34    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 380/4572]  eta: 0:01:34    time: 0.0226  data: 0.0209  max mem: 13749
Epoch: [2]  [ 400/4572]  eta: 0:01:34    time: 0.0237  data: 0.0218  max mem: 13749
Epoch: [2]  [ 420/4572]  eta: 0:01:33    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [2]  [ 440/4572]  eta: 0:01:33    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [ 460/4572]  eta: 0:01:33    time: 0.0240  data: 0.0221  max mem: 13749
Epoch: [2]  [ 480/4572]  eta: 0:01:32    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [ 500/4572]  eta: 0:01:32    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [ 520/4572]  eta: 0:01:31    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [ 540/4572]  eta: 0:01:31    time: 0.0237  data: 0.0217  max mem: 13749
Epoch: [2]  [ 560/4572]  eta: 0:01:30    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [2]  [ 580/4572]  eta: 0:01:30    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [ 600/4572]  eta: 0:01:30    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 620/4572]  eta: 0:01:29    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [2]  [ 640/4572]  eta: 0:01:29    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [ 660/4572]  eta: 0:01:28    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 680/4572]  eta: 0:01:28    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [ 700/4572]  eta: 0:01:27    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [ 720/4572]  eta: 0:01:27    time: 0.0226  data: 0.0203  max mem: 13749
Epoch: [2]  [ 740/4572]  eta: 0:01:26    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [ 760/4572]  eta: 0:01:26    time: 0.0252  data: 0.0237  max mem: 13749
Epoch: [2]  [ 780/4572]  eta: 0:01:26    time: 0.0250  data: 0.0235  max mem: 13749
Epoch: [2]  [ 800/4572]  eta: 0:01:25    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [ 820/4572]  eta: 0:01:25    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [ 840/4572]  eta: 0:01:25    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [ 860/4572]  eta: 0:01:24    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [ 880/4572]  eta: 0:01:24    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 900/4572]  eta: 0:01:23    time: 0.0250  data: 0.0234  max mem: 13749
Epoch: [2]  [ 920/4572]  eta: 0:01:23    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 940/4572]  eta: 0:01:22    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [ 960/4572]  eta: 0:01:22    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [2]  [ 980/4572]  eta: 0:01:21    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1000/4572]  eta: 0:01:21    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [1020/4572]  eta: 0:01:21    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1040/4572]  eta: 0:01:20    time: 0.0247  data: 0.0228  max mem: 13749
Epoch: [2]  [1060/4572]  eta: 0:01:20    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1080/4572]  eta: 0:01:20    time: 0.0236  data: 0.0218  max mem: 13749
Epoch: [2]  [1100/4572]  eta: 0:01:19    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1120/4572]  eta: 0:01:19    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1140/4572]  eta: 0:01:18    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [2]  [1160/4572]  eta: 0:01:18    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [2]  [1180/4572]  eta: 0:01:17    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [1200/4572]  eta: 0:01:17    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1220/4572]  eta: 0:01:16    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1240/4572]  eta: 0:01:16    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [2]  [1260/4572]  eta: 0:01:15    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1280/4572]  eta: 0:01:15    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [1300/4572]  eta: 0:01:14    time: 0.0234  data: 0.0214  max mem: 13749
Epoch: [2]  [1320/4572]  eta: 0:01:14    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [2]  [1340/4572]  eta: 0:01:14    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [1360/4572]  eta: 0:01:13    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [1380/4572]  eta: 0:01:13    time: 0.0220  data: 0.0202  max mem: 13749
Epoch: [2]  [1400/4572]  eta: 0:01:12    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1420/4572]  eta: 0:01:12    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1440/4572]  eta: 0:01:11    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1460/4572]  eta: 0:01:11    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1480/4572]  eta: 0:01:10    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1500/4572]  eta: 0:01:10    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1520/4572]  eta: 0:01:09    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [1540/4572]  eta: 0:01:09    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [1560/4572]  eta: 0:01:08    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [1580/4572]  eta: 0:01:08    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [2]  [1600/4572]  eta: 0:01:08    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1620/4572]  eta: 0:01:07    time: 0.0245  data: 0.0231  max mem: 13749
Epoch: [2]  [1640/4572]  eta: 0:01:07    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [2]  [1660/4572]  eta: 0:01:06    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1680/4572]  eta: 0:01:06    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [1700/4572]  eta: 0:01:05    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [1720/4572]  eta: 0:01:05    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1740/4572]  eta: 0:01:04    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1760/4572]  eta: 0:01:04    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1780/4572]  eta: 0:01:03    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [1800/4572]  eta: 0:01:03    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1820/4572]  eta: 0:01:02    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [1840/4572]  eta: 0:01:02    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [1860/4572]  eta: 0:01:02    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1880/4572]  eta: 0:01:01    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1900/4572]  eta: 0:01:01    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1920/4572]  eta: 0:01:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1940/4572]  eta: 0:01:00    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1960/4572]  eta: 0:00:59    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [2]  [1980/4572]  eta: 0:00:59    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [2000/4572]  eta: 0:00:58    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [2020/4572]  eta: 0:00:58    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [2040/4572]  eta: 0:00:57    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2060/4572]  eta: 0:00:57    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [2080/4572]  eta: 0:00:57    time: 0.0238  data: 0.0219  max mem: 13749
Epoch: [2]  [2100/4572]  eta: 0:00:56    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [2120/4572]  eta: 0:00:56    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [2140/4572]  eta: 0:00:55    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [2160/4572]  eta: 0:00:55    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [2]  [2180/4572]  eta: 0:00:54    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [2200/4572]  eta: 0:00:54    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [2]  [2220/4572]  eta: 0:00:53    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2240/4572]  eta: 0:00:53    time: 0.0236  data: 0.0211  max mem: 13749
Epoch: [2]  [2260/4572]  eta: 0:00:52    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [2280/4572]  eta: 0:00:52    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2300/4572]  eta: 0:00:51    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [2320/4572]  eta: 0:00:51    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [2340/4572]  eta: 0:00:51    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2360/4572]  eta: 0:00:50    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [2380/4572]  eta: 0:00:50    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [2400/4572]  eta: 0:00:49    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2420/4572]  eta: 0:00:49    time: 0.0234  data: 0.0220  max mem: 13749
Epoch: [2]  [2440/4572]  eta: 0:00:48    time: 0.0242  data: 0.0228  max mem: 13749
Epoch: [2]  [2460/4572]  eta: 0:00:48    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [2480/4572]  eta: 0:00:47    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [2]  [2500/4572]  eta: 0:00:47    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [2520/4572]  eta: 0:00:46    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [2540/4572]  eta: 0:00:46    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [2560/4572]  eta: 0:00:46    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [2580/4572]  eta: 0:00:45    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2600/4572]  eta: 0:00:45    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2620/4572]  eta: 0:00:44    time: 0.0237  data: 0.0218  max mem: 13749
Epoch: [2]  [2640/4572]  eta: 0:00:44    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [2660/4572]  eta: 0:00:43    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2680/4572]  eta: 0:00:43    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [2700/4572]  eta: 0:00:42    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2720/4572]  eta: 0:00:42    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2740/4572]  eta: 0:00:41    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2760/4572]  eta: 0:00:41    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [2]  [2780/4572]  eta: 0:00:41    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [2800/4572]  eta: 0:00:40    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [2820/4572]  eta: 0:00:40    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [2840/4572]  eta: 0:00:39    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [2860/4572]  eta: 0:00:39    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [2]  [2880/4572]  eta: 0:00:38    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2900/4572]  eta: 0:00:38    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2920/4572]  eta: 0:00:37    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [2940/4572]  eta: 0:00:37    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [2960/4572]  eta: 0:00:36    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2980/4572]  eta: 0:00:36    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3000/4572]  eta: 0:00:35    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3020/4572]  eta: 0:00:35    time: 0.0237  data: 0.0212  max mem: 13749
Epoch: [2]  [3040/4572]  eta: 0:00:35    time: 0.0226  data: 0.0206  max mem: 13749
Epoch: [2]  [3060/4572]  eta: 0:00:34    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [2]  [3080/4572]  eta: 0:00:34    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [3100/4572]  eta: 0:00:33    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [3120/4572]  eta: 0:00:33    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3140/4572]  eta: 0:00:32    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [3160/4572]  eta: 0:00:32    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [3180/4572]  eta: 0:00:31    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3200/4572]  eta: 0:00:31    time: 0.0236  data: 0.0219  max mem: 13749
Epoch: [2]  [3220/4572]  eta: 0:00:30    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [2]  [3240/4572]  eta: 0:00:30    time: 0.0234  data: 0.0214  max mem: 13749
Epoch: [2]  [3260/4572]  eta: 0:00:30    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [3280/4572]  eta: 0:00:29    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3300/4572]  eta: 0:00:29    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [2]  [3320/4572]  eta: 0:00:28    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [2]  [3340/4572]  eta: 0:00:28    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [3360/4572]  eta: 0:00:27    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [2]  [3380/4572]  eta: 0:00:27    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [3400/4572]  eta: 0:00:26    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [3420/4572]  eta: 0:00:26    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [2]  [3440/4572]  eta: 0:00:25    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3460/4572]  eta: 0:00:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [3480/4572]  eta: 0:00:25    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [3500/4572]  eta: 0:00:24    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3520/4572]  eta: 0:00:24    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3540/4572]  eta: 0:00:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3560/4572]  eta: 0:00:23    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [3580/4572]  eta: 0:00:22    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [2]  [3600/4572]  eta: 0:00:22    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [3620/4572]  eta: 0:00:21    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3640/4572]  eta: 0:00:21    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3660/4572]  eta: 0:00:20    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3680/4572]  eta: 0:00:20    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [3700/4572]  eta: 0:00:19    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3720/4572]  eta: 0:00:19    time: 0.0229  data: 0.0211  max mem: 13749
Epoch: [2]  [3740/4572]  eta: 0:00:19    time: 0.0227  data: 0.0202  max mem: 13749
Epoch: [2]  [3760/4572]  eta: 0:00:18    time: 0.0227  data: 0.0208  max mem: 13749
Epoch: [2]  [3780/4572]  eta: 0:00:18    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3800/4572]  eta: 0:00:17    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [2]  [3820/4572]  eta: 0:00:17    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [3840/4572]  eta: 0:00:16    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [2]  [3860/4572]  eta: 0:00:16    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [2]  [3880/4572]  eta: 0:00:15    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [3900/4572]  eta: 0:00:15    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3920/4572]  eta: 0:00:14    time: 0.0225  data: 0.0207  max mem: 13749
Epoch: [2]  [3940/4572]  eta: 0:00:14    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3960/4572]  eta: 0:00:14    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [2]  [3980/4572]  eta: 0:00:13    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [4000/4572]  eta: 0:00:13    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [2]  [4020/4572]  eta: 0:00:12    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [4040/4572]  eta: 0:00:12    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [2]  [4060/4572]  eta: 0:00:11    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [2]  [4080/4572]  eta: 0:00:11    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [4100/4572]  eta: 0:00:10    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4120/4572]  eta: 0:00:10    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [4140/4572]  eta: 0:00:09    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [4160/4572]  eta: 0:00:09    time: 0.0255  data: 0.0241  max mem: 13749
Epoch: [2]  [4180/4572]  eta: 0:00:08    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [4200/4572]  eta: 0:00:08    time: 0.0236  data: 0.0211  max mem: 13749
Epoch: [2]  [4220/4572]  eta: 0:00:08    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [4240/4572]  eta: 0:00:07    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0199  max mem: 13749
Epoch: [2]  [4280/4572]  eta: 0:00:06    time: 0.0225  data: 0.0200  max mem: 13749
Epoch: [2]  [4300/4572]  eta: 0:00:06    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [4320/4572]  eta: 0:00:05    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [4340/4572]  eta: 0:00:05    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [4360/4572]  eta: 0:00:04    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4380/4572]  eta: 0:00:04    time: 0.0239  data: 0.0218  max mem: 13749
Epoch: [2]  [4400/4572]  eta: 0:00:03    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [4420/4572]  eta: 0:00:03    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [2]  [4440/4572]  eta: 0:00:03    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [4460/4572]  eta: 0:00:02    time: 0.0250  data: 0.0223  max mem: 13749
Epoch: [2]  [4480/4572]  eta: 0:00:02    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [2]  [4500/4572]  eta: 0:00:01    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4520/4572]  eta: 0:00:01    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [4540/4572]  eta: 0:00:00    time: 0.0223  data: 0.0203  max mem: 13749
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0240  data: 0.0226  max mem: 13749
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2] Total time: 0:01:44 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746043326090, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746043326090, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.26524966048171}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746043326093, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2640 (0.2640)  evaluator_time: 0.0030 (0.0030)  time: 0.2681  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2721 (0.2537)  evaluator_time: 0.0035 (0.0094)  time: 0.2641  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2642 s / it)
Averaged stats: model_time: 0.2721 (0.2596)  evaluator_time: 0.0035 (0.0069)
:::MLLOG {"namespace": "", "time_ms": 1746043329968, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:01:36    time: 0.0211  data: 0.0008  max mem: 13749
Epoch: [3]  [  20/4571]  eta: 0:01:40    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [  40/4571]  eta: 0:01:43    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [3]  [  60/4571]  eta: 0:01:41    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [  80/4571]  eta: 0:01:43    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [ 100/4571]  eta: 0:01:43    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [ 120/4571]  eta: 0:01:42    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [ 140/4571]  eta: 0:01:42    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 160/4571]  eta: 0:01:42    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [ 180/4571]  eta: 0:01:41    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [ 200/4571]  eta: 0:01:40    time: 0.0224  data: 0.0208  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746043334761, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3148755415728455, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746043334761, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 220/4571]  eta: 0:01:39    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [ 240/4571]  eta: 0:01:39    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 260/4571]  eta: 0:01:39    time: 0.0235  data: 0.0216  max mem: 13749
Epoch: [3]  [ 280/4571]  eta: 0:01:38    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [3]  [ 300/4571]  eta: 0:01:38    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 320/4571]  eta: 0:01:37    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [ 340/4571]  eta: 0:01:37    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 360/4571]  eta: 0:01:36    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [3]  [ 380/4571]  eta: 0:01:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [ 400/4571]  eta: 0:01:35    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 420/4571]  eta: 0:01:35    time: 0.0247  data: 0.0231  max mem: 13749
Epoch: [3]  [ 440/4571]  eta: 0:01:35    time: 0.0260  data: 0.0236  max mem: 13749
Epoch: [3]  [ 460/4571]  eta: 0:01:35    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [ 480/4571]  eta: 0:01:34    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [ 500/4571]  eta: 0:01:34    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [ 520/4571]  eta: 0:01:34    time: 0.0238  data: 0.0217  max mem: 13749
Epoch: [3]  [ 540/4571]  eta: 0:01:33    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [ 560/4571]  eta: 0:01:32    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [ 580/4571]  eta: 0:01:32    time: 0.0268  data: 0.0248  max mem: 13749
Epoch: [3]  [ 600/4571]  eta: 0:01:32    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [ 620/4571]  eta: 0:01:31    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [3]  [ 640/4571]  eta: 0:01:31    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [3]  [ 660/4571]  eta: 0:01:31    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [ 680/4571]  eta: 0:01:30    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [ 700/4571]  eta: 0:01:30    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [ 720/4571]  eta: 0:01:29    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [ 740/4571]  eta: 0:01:28    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [ 760/4571]  eta: 0:01:28    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [ 780/4571]  eta: 0:01:28    time: 0.0229  data: 0.0212  max mem: 13749
Epoch: [3]  [ 800/4571]  eta: 0:01:27    time: 0.0248  data: 0.0232  max mem: 13749
Epoch: [3]  [ 820/4571]  eta: 0:01:27    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [ 840/4571]  eta: 0:01:26    time: 0.0234  data: 0.0217  max mem: 13749
Epoch: [3]  [ 860/4571]  eta: 0:01:26    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [3]  [ 880/4571]  eta: 0:01:25    time: 0.0220  data: 0.0194  max mem: 13749
Epoch: [3]  [ 900/4571]  eta: 0:01:25    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [ 920/4571]  eta: 0:01:24    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [3]  [ 940/4571]  eta: 0:01:24    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 960/4571]  eta: 0:01:23    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [ 980/4571]  eta: 0:01:23    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1000/4571]  eta: 0:01:22    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1020/4571]  eta: 0:01:22    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [1040/4571]  eta: 0:01:21    time: 0.0247  data: 0.0226  max mem: 13749
Epoch: [3]  [1060/4571]  eta: 0:01:21    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [3]  [1080/4571]  eta: 0:01:20    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [1100/4571]  eta: 0:01:20    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1120/4571]  eta: 0:01:20    time: 0.0271  data: 0.0255  max mem: 13749
Epoch: [3]  [1140/4571]  eta: 0:01:19    time: 0.0243  data: 0.0218  max mem: 13749
Epoch: [3]  [1160/4571]  eta: 0:01:19    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [1180/4571]  eta: 0:01:18    time: 0.0231  data: 0.0214  max mem: 13749
Epoch: [3]  [1200/4571]  eta: 0:01:18    time: 0.0273  data: 0.0257  max mem: 13749
Epoch: [3]  [1220/4571]  eta: 0:01:17    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [1240/4571]  eta: 0:01:17    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1260/4571]  eta: 0:01:16    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [1280/4571]  eta: 0:01:16    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [1300/4571]  eta: 0:01:15    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1320/4571]  eta: 0:01:15    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [3]  [1340/4571]  eta: 0:01:14    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [1360/4571]  eta: 0:01:14    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [1380/4571]  eta: 0:01:14    time: 0.0261  data: 0.0246  max mem: 13749
Epoch: [3]  [1400/4571]  eta: 0:01:13    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1420/4571]  eta: 0:01:13    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1440/4571]  eta: 0:01:12    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [1460/4571]  eta: 0:01:12    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1480/4571]  eta: 0:01:11    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [3]  [1500/4571]  eta: 0:01:11    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [3]  [1520/4571]  eta: 0:01:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [1540/4571]  eta: 0:01:10    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [1560/4571]  eta: 0:01:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [1580/4571]  eta: 0:01:09    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [3]  [1600/4571]  eta: 0:01:08    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [1620/4571]  eta: 0:01:08    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [1640/4571]  eta: 0:01:07    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [1660/4571]  eta: 0:01:07    time: 0.0239  data: 0.0217  max mem: 13749
Epoch: [3]  [1680/4571]  eta: 0:01:06    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [1700/4571]  eta: 0:01:06    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [1720/4571]  eta: 0:01:06    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [1740/4571]  eta: 0:01:05    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [1760/4571]  eta: 0:01:05    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [1780/4571]  eta: 0:01:04    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [1800/4571]  eta: 0:01:04    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [3]  [1820/4571]  eta: 0:01:03    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1840/4571]  eta: 0:01:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1860/4571]  eta: 0:01:02    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [3]  [1880/4571]  eta: 0:01:02    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1900/4571]  eta: 0:01:01    time: 0.0245  data: 0.0226  max mem: 13749
Epoch: [3]  [1920/4571]  eta: 0:01:01    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1940/4571]  eta: 0:01:00    time: 0.0234  data: 0.0210  max mem: 13749
Epoch: [3]  [1960/4571]  eta: 0:01:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [1980/4571]  eta: 0:00:59    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2000/4571]  eta: 0:00:59    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [2020/4571]  eta: 0:00:59    time: 0.0267  data: 0.0252  max mem: 13749
Epoch: [3]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2060/4571]  eta: 0:00:58    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [2080/4571]  eta: 0:00:57    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [2100/4571]  eta: 0:00:57    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2120/4571]  eta: 0:00:56    time: 0.0223  data: 0.0199  max mem: 13749
Epoch: [3]  [2140/4571]  eta: 0:00:56    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [2160/4571]  eta: 0:00:55    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [2180/4571]  eta: 0:00:55    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [2200/4571]  eta: 0:00:54    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2220/4571]  eta: 0:00:54    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2240/4571]  eta: 0:00:53    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [2260/4571]  eta: 0:00:53    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [3]  [2280/4571]  eta: 0:00:52    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2300/4571]  eta: 0:00:52    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [2320/4571]  eta: 0:00:52    time: 0.0240  data: 0.0221  max mem: 13749
Epoch: [3]  [2340/4571]  eta: 0:00:51    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [2360/4571]  eta: 0:00:51    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [2380/4571]  eta: 0:00:50    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2400/4571]  eta: 0:00:50    time: 0.0239  data: 0.0221  max mem: 13749
Epoch: [3]  [2420/4571]  eta: 0:00:49    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [2440/4571]  eta: 0:00:49    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [3]  [2460/4571]  eta: 0:00:48    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [2480/4571]  eta: 0:00:48    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2500/4571]  eta: 0:00:47    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2520/4571]  eta: 0:00:47    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2540/4571]  eta: 0:00:46    time: 0.0227  data: 0.0207  max mem: 13749
Epoch: [3]  [2560/4571]  eta: 0:00:46    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [2580/4571]  eta: 0:00:46    time: 0.0244  data: 0.0227  max mem: 13749
Epoch: [3]  [2600/4571]  eta: 0:00:45    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [2620/4571]  eta: 0:00:45    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2640/4571]  eta: 0:00:44    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [2660/4571]  eta: 0:00:44    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2680/4571]  eta: 0:00:43    time: 0.0226  data: 0.0207  max mem: 13749
Epoch: [3]  [2700/4571]  eta: 0:00:43    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [2720/4571]  eta: 0:00:42    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2740/4571]  eta: 0:00:42    time: 0.0227  data: 0.0205  max mem: 13749
Epoch: [3]  [2760/4571]  eta: 0:00:41    time: 0.0238  data: 0.0221  max mem: 13749
Epoch: [3]  [2780/4571]  eta: 0:00:41    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [2800/4571]  eta: 0:00:40    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [2820/4571]  eta: 0:00:40    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2840/4571]  eta: 0:00:40    time: 0.0263  data: 0.0248  max mem: 13749
Epoch: [3]  [2860/4571]  eta: 0:00:39    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [2880/4571]  eta: 0:00:39    time: 0.0226  data: 0.0205  max mem: 13749
Epoch: [3]  [2900/4571]  eta: 0:00:38    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [2920/4571]  eta: 0:00:38    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [2940/4571]  eta: 0:00:37    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2960/4571]  eta: 0:00:37    time: 0.0271  data: 0.0256  max mem: 13749
Epoch: [3]  [2980/4571]  eta: 0:00:36    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [3000/4571]  eta: 0:00:36    time: 0.0234  data: 0.0220  max mem: 13749
Epoch: [3]  [3020/4571]  eta: 0:00:35    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3040/4571]  eta: 0:00:35    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3060/4571]  eta: 0:00:34    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [3080/4571]  eta: 0:00:34    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3100/4571]  eta: 0:00:34    time: 0.0282  data: 0.0267  max mem: 13749
Epoch: [3]  [3120/4571]  eta: 0:00:33    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3140/4571]  eta: 0:00:33    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [3160/4571]  eta: 0:00:32    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [3180/4571]  eta: 0:00:32    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3200/4571]  eta: 0:00:31    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [3220/4571]  eta: 0:00:31    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [3]  [3240/4571]  eta: 0:00:30    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3260/4571]  eta: 0:00:30    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3280/4571]  eta: 0:00:29    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3300/4571]  eta: 0:00:29    time: 0.0272  data: 0.0250  max mem: 13749
Epoch: [3]  [3320/4571]  eta: 0:00:28    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [3340/4571]  eta: 0:00:28    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [3360/4571]  eta: 0:00:28    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [3380/4571]  eta: 0:00:27    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3400/4571]  eta: 0:00:27    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3420/4571]  eta: 0:00:26    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [3440/4571]  eta: 0:00:26    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [3460/4571]  eta: 0:00:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [3480/4571]  eta: 0:00:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3500/4571]  eta: 0:00:24    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [3520/4571]  eta: 0:00:24    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3540/4571]  eta: 0:00:23    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [3560/4571]  eta: 0:00:23    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [3580/4571]  eta: 0:00:22    time: 0.0235  data: 0.0211  max mem: 13749
Epoch: [3]  [3600/4571]  eta: 0:00:22    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [3620/4571]  eta: 0:00:21    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3640/4571]  eta: 0:00:21    time: 0.0238  data: 0.0213  max mem: 13749
Epoch: [3]  [3660/4571]  eta: 0:00:21    time: 0.0237  data: 0.0223  max mem: 13749
Epoch: [3]  [3680/4571]  eta: 0:00:20    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [3700/4571]  eta: 0:00:20    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3720/4571]  eta: 0:00:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3740/4571]  eta: 0:00:19    time: 0.0238  data: 0.0220  max mem: 13749
Epoch: [3]  [3760/4571]  eta: 0:00:18    time: 0.0264  data: 0.0249  max mem: 13749
Epoch: [3]  [3780/4571]  eta: 0:00:18    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3800/4571]  eta: 0:00:17    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [3]  [3820/4571]  eta: 0:00:17    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3840/4571]  eta: 0:00:16    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3860/4571]  eta: 0:00:16    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [3]  [3880/4571]  eta: 0:00:16    time: 0.0264  data: 0.0249  max mem: 13749
Epoch: [3]  [3900/4571]  eta: 0:00:15    time: 0.0232  data: 0.0210  max mem: 13749
Epoch: [3]  [3920/4571]  eta: 0:00:15    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [3]  [3940/4571]  eta: 0:00:14    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [3960/4571]  eta: 0:00:14    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [3980/4571]  eta: 0:00:13    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [4000/4571]  eta: 0:00:13    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [4020/4571]  eta: 0:00:12    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [3]  [4040/4571]  eta: 0:00:12    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [4060/4571]  eta: 0:00:11    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [4080/4571]  eta: 0:00:11    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [4100/4571]  eta: 0:00:10    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [4120/4571]  eta: 0:00:10    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [3]  [4140/4571]  eta: 0:00:09    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [4160/4571]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [4180/4571]  eta: 0:00:09    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4200/4571]  eta: 0:00:08    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [3]  [4220/4571]  eta: 0:00:08    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [4240/4571]  eta: 0:00:07    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4260/4571]  eta: 0:00:07    time: 0.0274  data: 0.0259  max mem: 13749
Epoch: [3]  [4280/4571]  eta: 0:00:06    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4300/4571]  eta: 0:00:06    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [4320/4571]  eta: 0:00:05    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [3]  [4340/4571]  eta: 0:00:05    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [4360/4571]  eta: 0:00:04    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [4400/4571]  eta: 0:00:03    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [3]  [4420/4571]  eta: 0:00:03    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [4440/4571]  eta: 0:00:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [4460/4571]  eta: 0:00:02    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [4480/4571]  eta: 0:00:02    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [4500/4571]  eta: 0:00:01    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [4520/4571]  eta: 0:00:01    time: 0.0262  data: 0.0247  max mem: 13749
Epoch: [3]  [4540/4571]  eta: 0:00:00    time: 0.0260  data: 0.0246  max mem: 13749
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3] Total time: 0:01:45 (0.0232 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746043435918, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746043435918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 172.6271686373146}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746043435921, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2617 (0.2617)  evaluator_time: 0.0032 (0.0032)  time: 0.2659  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2650 (0.2536)  evaluator_time: 0.0033 (0.0033)  time: 0.2579  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2580 s / it)
Averaged stats: model_time: 0.2650 (0.2598)  evaluator_time: 0.0033 (0.0049)
:::MLLOG {"namespace": "", "time_ms": 1746043439779, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:01:39    time: 0.0217  data: 0.0007  max mem: 13749
Epoch: [4]  [  20/4572]  eta: 0:01:46    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [4]  [  40/4572]  eta: 0:01:47    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [4]  [  60/4572]  eta: 0:01:44    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [4]  [  80/4572]  eta: 0:01:44    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [4]  [ 100/4572]  eta: 0:01:42    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [4]  [ 120/4572]  eta: 0:01:42    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [4]  [ 140/4572]  eta: 0:01:41    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [4]  [ 160/4572]  eta: 0:01:40    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [4]  [ 180/4572]  eta: 0:01:40    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [4]  [ 200/4572]  eta: 0:01:39    time: 0.0219  data: 0.0204  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746043444594, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3427515300891548, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746043444595, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746043444802, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1746043444802, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746043444802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 177.04337428640392}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:07:23
:::MLLOG {"namespace": "", "time_ms": 1746043444802, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 783}}

GPU-790:2857490:2857904 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3
Loading annotations into memory...
Done (t=1.10s)
Creating index...
Done (t=1.29s)
Loading and preparing results...
DONE (t=3.83s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.12s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.19577
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32098
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.20137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00507
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.04987
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.21650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33230
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.48021
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01916
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18234
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.54818
Loading and preparing results...
DONE (t=2.61s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.46s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28141
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42554
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30258
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00574
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07667
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31076
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53268
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.55858
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03064
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.22638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.60772
Loading and preparing results...
DONE (t=2.29s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.32s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.31488
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.45719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.33922
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00656
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09421
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.34837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.55898
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.58436
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03049
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24796
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.63405
Loading and preparing results...
DONE (t=2.34s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.29s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34275
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.48973
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.36777
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00870
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37988
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60406
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24987
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65553

GPU-1006:2806293:2806673 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3

GPU-1006:2806294:2806670 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 9, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3

GPU-47:4165650:4166107 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 50, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 13, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2806281:2806677 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2806287:2806674 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806287:2806674 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2806287:2806674 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 14, retcode 3

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 55, retcode 3

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 14, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 55, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2806281:2806677 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 14, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4165715:4166101 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3

GPU-1006:2806287:2806674 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2806287:2806674 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2806289:2806675 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2806289:2806675 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2806289:2806675 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2806281:2806677 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2806287:2806674 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2806287:2806674 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2806289:2806675 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2806289:2806675 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3

GPU-47:4165720:4166103 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4165720:4166103 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4165720:4166103 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4165715:4166101 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 54, retcode 3

GPU-1006:2806275:2806676 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2806275:2806676 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2806275:2806676 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2806281:2806677 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2806287:2806674 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2806287:2806674 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2806289:2806675 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2806289:2806675 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 12, retcode 3

GPU-726:2766453:2766859 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 17, retcode 3

GPU-47:4165729:4166105 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4165729:4166105 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4165729:4166105 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4165720:4166103 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4165720:4166103 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4165715:4166101 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 53, retcode 3

GPU-47:4165728:4166110 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165728:4166110 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165728:4166110 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165722:4166108 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165722:4166108 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165729:4166105 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165729:4166105 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165722:4166108 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165720:4166103 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165720:4166103 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4165715:4166101 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 49, retcode 3

GPU-47:4165728:4166110 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165728:4166110 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4165722:4166108 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165722:4166108 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 51, retcode 3
[rank48]:[W430 20:04:05.556503653 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-47:4165729:4166105 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165729:4166105 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4165720:4166103 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165720:4166103 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4165715:4166101 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4165699:4166111 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4165699:4166111 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165699:4166111 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165728:4166110 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165728:4166110 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165650:4166107 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165650:4166107 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165722:4166108 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165722:4166108 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165632:4166109 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165632:4166109 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165729:4166105 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165729:4166105 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165720:4166103 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165720:4166103 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4165715:4166101 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4165715:4166101 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 48, retcode 3

GPU-498:1904507:1904914 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2766477:2766857 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 37, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 39, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-498:1904532:1904921 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2857524:2857908 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2857463:2857903 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857463:2857903 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2857463:2857903 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2857524:2857908 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2857517:2857909 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857463:2857903 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2857463:2857903 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2857524:2857908 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2857517:2857909 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2857517:2857909 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3

GPU-726:2766474:2766856 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2766477:2766857 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2766466:2766852 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2766474:2766856 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2766474:2766856 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2766466:2766852 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2766466:2766852 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2766477:2766857 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2766474:2766856 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2766474:2766856 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2766466:2766852 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2766466:2766852 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3
[rank56]:[W430 20:04:05.016467338 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-753:3660869:3661290 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 56, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3660901:3661280 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 58, retcode 3

GPU-753:3660874:3661284 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3660901:3661280 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3660874:3661284 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3660874:3661284 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 59, retcode 3
[rank16]:[W430 20:04:05.583449024 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-726:2766476:2766854 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766476:2766854 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2766476:2766854 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2766477:2766857 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2766474:2766856 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2766474:2766856 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2766466:2766852 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2766466:2766852 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 16, retcode 3

GPU-790:2857519:2857912 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857463:2857903 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2857463:2857903 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2857524:2857908 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2857519:2857912 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2857519:2857912 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2857517:2857909 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2857517:2857909 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2857551:2857910 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857463:2857903 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857463:2857903 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857524:2857908 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2857519:2857912 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857519:2857912 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2857551:2857910 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857551:2857910 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2857517:2857909 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2857517:2857909 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 6, retcode 3

GPU-753:3660899:3661281 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3660901:3661280 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3660874:3661284 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3660874:3661284 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3660899:3661281 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3660899:3661281 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3

GPU-753:3660875:3661283 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 61, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3660901:3661280 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 61, retcode 3

GPU-753:3660874:3661284 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3660874:3661284 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 61, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 61, retcode 3

GPU-753:3660875:3661283 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3660875:3661283 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3

GPU-753:3660899:3661281 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3660899:3661281 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 61, retcode 3

GPU-753:3660906:3661282 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660901:3661280 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3660874:3661284 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660874:3661284 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3660875:3661283 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660875:3661283 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3660899:3661281 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660899:3661281 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 63, retcode 3

GPU-753:3660906:3661282 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3660906:3661282 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3
[rank32]:[W430 20:04:06.431936979 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-498:1904536:1904912 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904536:1904912 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-498:1904536:1904912 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 32, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 32, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-498:1904532:1904921 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 32, retcode 3

GPU-498:1904531:1904913 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904536:1904912 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1904536:1904912 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1904531:1904913 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1904531:1904913 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-498:1904532:1904921 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 33, retcode 3

GPU-498:1904508:1904917 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904536:1904912 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1904536:1904912 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1904531:1904913 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1904531:1904913 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1904508:1904917 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1904508:1904917 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 35, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-498:1904532:1904921 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 35, retcode 3
[rank24]:[W430 20:04:06.661012644 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-892:2483583:2484144 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 24, retcode 3

GPU-753:3660915:3661287 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3660869:3661290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660869:3661290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660915:3661287 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660915:3661287 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660901:3661280 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660901:3661280 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660874:3661284 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660874:3661284 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660898:3661285 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660898:3661285 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660875:3661283 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660875:3661283 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660899:3661281 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660899:3661281 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 57, retcode 3

GPU-753:3660906:3661282 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3660906:3661282 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 57, retcode 3

GPU-726:2766475:2766860 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766476:2766854 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766476:2766854 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766477:2766857 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2766475:2766860 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766475:2766860 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2766474:2766856 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766474:2766856 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2766466:2766852 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2766466:2766852 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 21, retcode 3
[rank40]:[W430 20:04:06.620415929 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-419:1905395:1905871 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 46, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3

GPU-498:1904526:1904919 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904536:1904912 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904536:1904912 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904531:1904913 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904531:1904913 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904508:1904917 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904508:1904917 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904526:1904919 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904526:1904919 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-498:1904532:1904921 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 38, retcode 3

GPU-498:1904529:1904920 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-498:1904536:1904912 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904536:1904912 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904531:1904913 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904531:1904913 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904507:1904914 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904507:1904914 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904508:1904917 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904508:1904917 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904529:1904920 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904529:1904920 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904501:1904922 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904501:1904922 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904526:1904919 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904526:1904919 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 36, retcode 3

GPU-498:1904532:1904921 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-498:1904532:1904921 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 36, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 25, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-892:2483541:2484146 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 25, retcode 3

GPU-1006:2806296:2806671 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2806296:2806671 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806296:2806671 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2806275:2806676 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806275:2806676 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806281:2806677 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2806287:2806674 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806287:2806674 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2806289:2806675 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2806289:2806675 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 10, retcode 3

GPU-892:2483598:2484139 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 31, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2483541:2484146 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 31, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 31, retcode 3

GPU-892:2483598:2484139 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-892:2483598:2484139 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3

GPU-892:2483607:2484145 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2483541:2484146 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2483607:2484145 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2483607:2484145 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 26, retcode 3

GPU-892:2483598:2484139 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-892:2483598:2484139 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 26, retcode 3
[rank8]:[W430 20:04:06.579307625 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-892:2483592:2484141 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2483541:2484146 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2483607:2484145 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2483607:2484145 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2483592:2484141 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2483592:2484141 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3

GPU-1006:2806204:2806669 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2806204:2806669 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806204:2806669 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806294:2806670 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806294:2806670 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806296:2806671 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806296:2806671 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806293:2806673 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806293:2806673 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806275:2806676 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806275:2806676 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806281:2806677 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806281:2806677 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806287:2806674 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806287:2806674 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2806289:2806675 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2806289:2806675 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 8, retcode 3

GPU-726:2766472:2766858 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2766476:2766854 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766476:2766854 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766453:2766859 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766453:2766859 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766399:2766855 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766399:2766855 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766477:2766857 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766477:2766857 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766472:2766858 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766472:2766858 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766475:2766860 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766475:2766860 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766474:2766856 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766474:2766856 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2766466:2766852 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2766466:2766852 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 20, retcode 3

GPU-892:2483598:2484139 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-892:2483598:2484139 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 29, retcode 3

GPU-892:2483601:2484143 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483541:2484146 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483607:2484145 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483607:2484145 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483601:2484143 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483601:2484143 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483592:2484141 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483592:2484141 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483540:2484140 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-892:2483598:2484139 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483598:2484139 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483540:2484140 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-892:2483540:2484140 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 27, retcode 3

GPU-892:2483583:2484144 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483583:2484144 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483541:2484146 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483541:2484146 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483607:2484145 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483607:2484145 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483601:2484143 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483601:2484143 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483594:2484142 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483594:2484142 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483592:2484141 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483592:2484141 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483540:2484140 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483540:2484140 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3

GPU-892:2483598:2484139 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-892:2483598:2484139 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 30, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 43, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-419:1905413:1905874 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 43, retcode 3

GPU-419:1905461:1905878 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1905413:1905874 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1905461:1905878 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1905461:1905878 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 45, retcode 3

GPU-419:1905475:1905877 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1905413:1905874 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1905461:1905878 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1905461:1905878 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1905475:1905877 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-419:1905475:1905877 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3

GPU-419:1905480:1905876 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905452:1905873 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905452:1905873 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905452:1905873 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905413:1905874 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905452:1905873 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905452:1905873 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905480:1905876 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905480:1905876 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905413:1905874 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905461:1905878 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905461:1905878 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905480:1905876 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905480:1905876 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905461:1905878 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905461:1905878 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905475:1905877 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-419:1905475:1905877 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 44, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905475:1905877 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-419:1905475:1905877 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 42, retcode 3

GPU-419:1905434:1905872 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-419:1905395:1905871 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905395:1905871 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905434:1905872 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905434:1905872 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905452:1905873 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905452:1905873 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905413:1905874 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905413:1905874 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905480:1905876 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905480:1905876 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905461:1905878 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905461:1905878 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905467:1905875 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905467:1905875 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 41, retcode 3

GPU-419:1905475:1905877 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-419:1905475:1905877 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 41, retcode 3
[rank0]:[W430 20:04:07.456897178 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-790:2857531:2857902 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2857531:2857902 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857531:2857902 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857463:2857903 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857463:2857903 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857490:2857904 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857490:2857904 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857524:2857908 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857524:2857908 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857513:2857911 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857513:2857911 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857519:2857912 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857519:2857912 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857551:2857910 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857551:2857910 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2857517:2857909 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2857517:2857909 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 0, retcode 3
ENDING TIMING RUN AT 2025-04-30 08:04:09 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:10 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
ENDING TIMING RUN AT 2025-04-30 08:04:11 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 07:55:13 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746043451'
RUNANDTIME_STOP 1746043451
+ set -e
