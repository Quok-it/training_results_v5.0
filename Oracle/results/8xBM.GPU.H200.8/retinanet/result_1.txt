+ echo 'Beginning trial 3 of 8'
Beginning trial 3 of 8
+ echo ':::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 376 8 GPU-[790,1006,726,47,753,903,761,682] '\''unknown'\'' DGXH100_008x08x004'
:::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 376 8 GPU-[790,1006,726,47,753,903,761,682] 'unknown' DGXH100_008x08x004
++ srun --ntasks=1 --container-name=single_stage_detector_376 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=single_stage_detector_376 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
:::GITCOMMITID  
+ srun -N1 -n1 --container-name=single_stage_detector_376 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on GPU-790
Clearing cache on GPU-761
Clearing cache on GPU-753
Clearing cache on GPU-903
Clearing cache on GPU-1006
Clearing cache on GPU-726
Clearing cache on GPU-47
Clearing cache on GPU-682
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector_376 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746035117995, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118040, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118050, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118062, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118075, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118128, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118131, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035118150, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746035148'
RUNANDTIME_START 1746035148
+ srun --ntasks=64 --ntasks-per-node=8 --time=20 --container-name=single_stage_detector_376 --container-mounts=/mnt/localdisk5/mlperf/ssd/data/open-images-v6:/datasets/open-images-v6,/home/ubuntu/sd/ssd/log:/results,/mnt/localdisk5/mlperf/ssd/data/torch-home/hub/checkpoints:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 18: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 16: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 21: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 22: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 12: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 53: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 53, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 52: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 52, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 48: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 48, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 51: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 51, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 49: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 49, SLURM_LOCALID 1, OMP_NUM_THREADS 1
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
running benchmark
RANK 50: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 50, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 54: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 54, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 55: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 55, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 62: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 62, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 60: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 60, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
RANK 61: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 61, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 63: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 63, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 58: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 58, SLURM_LOCALID 2, OMP_NUM_THREADS 1
RANK 59: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 59, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 56: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 56, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 57: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 57, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 2: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 39: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 39, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 36: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 36, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 33: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 33, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 34: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 34, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 38: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 38, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 37: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 37, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 32: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 32, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 35: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 35, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 46: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 46, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 45: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 45, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 44: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 44, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 43: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 43, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 42: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 42, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 41: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 41, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 47: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 47, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 40: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 40, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 29: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 25: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:45:54 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
| distributed init (rank 0): env://
| distributed init (rank 48): env://
[W430 17:45:59.785741861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 5): env://
| distributed init (rank 6): env://
[W430 17:45:59.503944077 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.504367652 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 56): env://
[W430 17:45:59.854932196 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 8): env://
[W430 17:45:59.986132406 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 11): env://
[W430 17:45:59.994178392 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 24): env://
[W430 17:45:59.147645482 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 54): env://
| distributed init (rank 10): env://
[W430 17:45:59.933028816 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 13): env://
[W430 17:45:59.032555730 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.032689284 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 2): env://
[W430 17:45:59.633867573 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 7): env://
[W430 17:45:59.638419871 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 3): env://
[W430 17:45:59.641869639 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 32): env://
[W430 17:45:59.611844045 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 4): env://
| distributed init (rank 12): env://
[W430 17:45:59.648622658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.054597376 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 28): env://
[W430 17:45:59.203542079 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 35): env://
[W430 17:45:59.619976970 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 1): env://
| distributed init (rank 55): env://
[W430 17:45:59.661578337 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.968977908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 33): env://
[W430 17:45:59.630285641 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 61): env://
| distributed init (rank 63): env://
[W430 17:45:59.009603619 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.010475467 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 37): env://
[W430 17:45:59.647116360 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 31): env://
| distributed init (rank 38): env://
| distributed init (rank 39): env://
| distributed init (rank 15): env://
[W430 17:45:59.237227044 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.652500454 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.652527578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.092324698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 30): env://
[W430 17:45:59.245276677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 58): env://
| distributed init (rank 57): env://
[W430 17:45:59.040233117 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.040429071 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 60): env://
[W430 17:45:59.041922260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 14): env://
| distributed init (rank 62): env://
[W430 17:45:59.119635093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.048921663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 9): env://
[W430 17:45:59.127209262 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 34): env://
[W430 17:45:59.689232499 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 50): env://
[W430 17:45:59.032588677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 49): env://
[W430 17:45:59.034977756 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 59): env://
[W430 17:45:59.069770140 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 36): env://
[W430 17:45:59.709305729 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 51): env://
[W430 17:45:59.052161733 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 52): env://
[W430 17:45:59.060893422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 53): env://
[W430 17:45:59.068500242 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 26): env://
[W430 17:45:59.334275750 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 29): env://
[W430 17:45:59.340421609 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 25): env://
| distributed init (rank 27): env://
[W430 17:45:59.351174475 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:45:59.351413930 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 16): env://
[W430 17:45:59.541041023 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 18): env://
[W430 17:46:00.655860211 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 19): env://
[W430 17:46:00.703200692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 40): env://
[W430 17:46:00.069074884 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 21): env://
| distributed init (rank 22): env://
[W430 17:46:00.719085835 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:46:00.719642148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 20): env://
[W430 17:46:00.730157971 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 23): env://
[W430 17:46:00.735222644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 17): env://
[W430 17:46:00.738334453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 41): env://
[W430 17:46:00.309983492 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 46): env://
| distributed init (rank 42): env://
[W430 17:46:00.313303032 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:46:00.313742381 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 45): env://
| distributed init (rank 44): env://
[W430 17:46:00.315033171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:46:00.315520727 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 47): env://
[W430 17:46:00.324092247 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 43): env://
[W430 17:46:00.332241076 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:46:00.458571545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
NCCL version 2.22.3+cuda12.6
:::MLLOG {"namespace": "", "time_ms": 1746035163160, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "retinanet", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746035163160, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746035163160, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746035163160, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746035163160, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746035163161, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1746035163193, "event_type": "POINT_IN_TIME", "key": "seed", "value": 870512724, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1746035163193, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 4, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1746035163193, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1746035163193, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1746035163193, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=64, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=4, eval_batch_size=32, lr=0.0001, warmup_epochs=1, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=870512724, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=64, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=False, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=0, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], num_train_ranks=64, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1746035163203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163360, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163362, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163362, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163362, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163362, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163362, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163362, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163363, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163363, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163364, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163364, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163365, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163365, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163366, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163366, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163367, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163367, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163368, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163368, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163369, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163370, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163370, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163373, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163375, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163378, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163378, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163380, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163383, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163383, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163386, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163388, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163389, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163391, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163393, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163394, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163396, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163399, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163399, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163401, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163406, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163408, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163417, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163426, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163436, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163437, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163446, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163456, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163457, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163641, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163642, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163642, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163643, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163643, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163645, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163645, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163648, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163648, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163650, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163650, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163653, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163670, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163678, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163678, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163681, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746035163749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
:::MLLOG {"namespace": "", "time_ms": 1746035163840, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1746035163840, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1746035163840, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1746035163840, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1746035163841, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1746035163841, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Time: 53.75736880302429 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1746035241556, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1746035241558, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 579}}
:::MLLOG {"namespace": "", "time_ms": 1746035241558, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1746035241558, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 13, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 636}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1746035241559, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:01:21    time: 0.0178  data: 0.0001  max mem: 13749
Epoch: [0]  [  20/4572]  eta: 0:01:37    time: 0.0216  data: 0.0201  max mem: 13749
Epoch: [0]  [  40/4572]  eta: 0:01:38    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [0]  [  60/4572]  eta: 0:01:38    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [0]  [  80/4572]  eta: 0:01:41    time: 0.0244  data: 0.0227  max mem: 13749
Epoch: [0]  [ 100/4572]  eta: 0:01:42    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [0]  [ 120/4572]  eta: 0:01:41    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [ 140/4572]  eta: 0:01:41    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [ 160/4572]  eta: 0:01:41    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [ 180/4572]  eta: 0:01:41    time: 0.0233  data: 0.0209  max mem: 13749
Epoch: [0]  [ 200/4572]  eta: 0:01:40    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [ 220/4572]  eta: 0:01:39    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [ 240/4572]  eta: 0:01:38    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [0]  [ 260/4572]  eta: 0:01:38    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [ 280/4572]  eta: 0:01:37    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [ 300/4572]  eta: 0:01:37    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [ 320/4572]  eta: 0:01:37    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 340/4572]  eta: 0:01:36    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [ 360/4572]  eta: 0:01:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 380/4572]  eta: 0:01:36    time: 0.0251  data: 0.0227  max mem: 13749
Epoch: [0]  [ 400/4572]  eta: 0:01:36    time: 0.0254  data: 0.0230  max mem: 13749
Epoch: [0]  [ 420/4572]  eta: 0:01:35    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 440/4572]  eta: 0:01:35    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 460/4572]  eta: 0:01:34    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [ 480/4572]  eta: 0:01:34    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [ 500/4572]  eta: 0:01:33    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 520/4572]  eta: 0:01:33    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [ 540/4572]  eta: 0:01:33    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [ 560/4572]  eta: 0:01:32    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [ 580/4572]  eta: 0:01:32    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [ 600/4572]  eta: 0:01:31    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 620/4572]  eta: 0:01:31    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [ 640/4572]  eta: 0:01:30    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 660/4572]  eta: 0:01:30    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [0]  [ 680/4572]  eta: 0:01:29    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 700/4572]  eta: 0:01:29    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 720/4572]  eta: 0:01:28    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [ 740/4572]  eta: 0:01:28    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [ 760/4572]  eta: 0:01:27    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [ 780/4572]  eta: 0:01:27    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [ 800/4572]  eta: 0:01:27    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [ 820/4572]  eta: 0:01:26    time: 0.0230  data: 0.0211  max mem: 13749
Epoch: [0]  [ 840/4572]  eta: 0:01:26    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [ 860/4572]  eta: 0:01:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [ 880/4572]  eta: 0:01:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [ 900/4572]  eta: 0:01:24    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [ 920/4572]  eta: 0:01:24    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [ 940/4572]  eta: 0:01:23    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [ 960/4572]  eta: 0:01:23    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [ 980/4572]  eta: 0:01:22    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [1000/4572]  eta: 0:01:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1020/4572]  eta: 0:01:21    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [1040/4572]  eta: 0:01:21    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1060/4572]  eta: 0:01:20    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [0]  [1080/4572]  eta: 0:01:20    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [1100/4572]  eta: 0:01:19    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [1120/4572]  eta: 0:01:19    time: 0.0235  data: 0.0218  max mem: 13749
Epoch: [0]  [1140/4572]  eta: 0:01:19    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1160/4572]  eta: 0:01:18    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1180/4572]  eta: 0:01:18    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [1200/4572]  eta: 0:01:17    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [1220/4572]  eta: 0:01:17    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [1240/4572]  eta: 0:01:16    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [1260/4572]  eta: 0:01:16    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [0]  [1280/4572]  eta: 0:01:15    time: 0.0251  data: 0.0236  max mem: 13749
Epoch: [0]  [1300/4572]  eta: 0:01:15    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [1320/4572]  eta: 0:01:14    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [1340/4572]  eta: 0:01:14    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [1360/4572]  eta: 0:01:13    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1380/4572]  eta: 0:01:13    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [1400/4572]  eta: 0:01:13    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1420/4572]  eta: 0:01:12    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [1440/4572]  eta: 0:01:12    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0]  [1460/4572]  eta: 0:01:11    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [1480/4572]  eta: 0:01:11    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1500/4572]  eta: 0:01:10    time: 0.0243  data: 0.0229  max mem: 13749
Epoch: [0]  [1520/4572]  eta: 0:01:10    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1540/4572]  eta: 0:01:09    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [1560/4572]  eta: 0:01:09    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1580/4572]  eta: 0:01:08    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [1600/4572]  eta: 0:01:08    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [1620/4572]  eta: 0:01:07    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [1640/4572]  eta: 0:01:07    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [1660/4572]  eta: 0:01:07    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1680/4572]  eta: 0:01:06    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1700/4572]  eta: 0:01:06    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1720/4572]  eta: 0:01:05    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [1740/4572]  eta: 0:01:05    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [0]  [1760/4572]  eta: 0:01:04    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [1780/4572]  eta: 0:01:04    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [0]  [1800/4572]  eta: 0:01:03    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [0]  [1820/4572]  eta: 0:01:03    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [1840/4572]  eta: 0:01:02    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [1860/4572]  eta: 0:01:02    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [0]  [1880/4572]  eta: 0:01:01    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [1900/4572]  eta: 0:01:01    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [1920/4572]  eta: 0:01:01    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [1940/4572]  eta: 0:01:00    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [1960/4572]  eta: 0:01:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [1980/4572]  eta: 0:00:59    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2000/4572]  eta: 0:00:59    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [0]  [2020/4572]  eta: 0:00:58    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [0]  [2040/4572]  eta: 0:00:58    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [2060/4572]  eta: 0:00:57    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2080/4572]  eta: 0:00:57    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2100/4572]  eta: 0:00:56    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [0]  [2120/4572]  eta: 0:00:56    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2140/4572]  eta: 0:00:56    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [0]  [2160/4572]  eta: 0:00:55    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2180/4572]  eta: 0:00:55    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [0]  [2200/4572]  eta: 0:00:54    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [2220/4572]  eta: 0:00:54    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [2240/4572]  eta: 0:00:53    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [2260/4572]  eta: 0:00:53    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2280/4572]  eta: 0:00:52    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [2300/4572]  eta: 0:00:52    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [0]  [2320/4572]  eta: 0:00:51    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2340/4572]  eta: 0:00:51    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [0]  [2360/4572]  eta: 0:00:50    time: 0.0245  data: 0.0220  max mem: 13749
Epoch: [0]  [2380/4572]  eta: 0:00:50    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [2400/4572]  eta: 0:00:50    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [2420/4572]  eta: 0:00:49    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2440/4572]  eta: 0:00:49    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [2460/4572]  eta: 0:00:48    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2480/4572]  eta: 0:00:48    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2500/4572]  eta: 0:00:47    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2520/4572]  eta: 0:00:47    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2540/4572]  eta: 0:00:46    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2560/4572]  eta: 0:00:46    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [2580/4572]  eta: 0:00:45    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [2600/4572]  eta: 0:00:45    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2620/4572]  eta: 0:00:44    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [2640/4572]  eta: 0:00:44    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [0]  [2660/4572]  eta: 0:00:44    time: 0.0254  data: 0.0238  max mem: 13749
Epoch: [0]  [2680/4572]  eta: 0:00:43    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2700/4572]  eta: 0:00:43    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2720/4572]  eta: 0:00:42    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2740/4572]  eta: 0:00:42    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [2760/4572]  eta: 0:00:41    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [2780/4572]  eta: 0:00:41    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [2800/4572]  eta: 0:00:40    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [2820/4572]  eta: 0:00:40    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [0]  [2840/4572]  eta: 0:00:39    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0]  [2860/4572]  eta: 0:00:39    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [0]  [2880/4572]  eta: 0:00:38    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2900/4572]  eta: 0:00:38    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2920/4572]  eta: 0:00:38    time: 0.0238  data: 0.0221  max mem: 13749
Epoch: [0]  [2940/4572]  eta: 0:00:37    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [2960/4572]  eta: 0:00:37    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [2980/4572]  eta: 0:00:36    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [0]  [3000/4572]  eta: 0:00:36    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3020/4572]  eta: 0:00:35    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3040/4572]  eta: 0:00:35    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3060/4572]  eta: 0:00:34    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3080/4572]  eta: 0:00:34    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [3100/4572]  eta: 0:00:33    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [0]  [3120/4572]  eta: 0:00:33    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [3140/4572]  eta: 0:00:32    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3160/4572]  eta: 0:00:32    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [3180/4572]  eta: 0:00:32    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [3200/4572]  eta: 0:00:31    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [3220/4572]  eta: 0:00:31    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [0]  [3240/4572]  eta: 0:00:30    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [3260/4572]  eta: 0:00:30    time: 0.0239  data: 0.0217  max mem: 13749
Epoch: [0]  [3280/4572]  eta: 0:00:29    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [3300/4572]  eta: 0:00:29    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [0]  [3320/4572]  eta: 0:00:28    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [0]  [3340/4572]  eta: 0:00:28    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [3360/4572]  eta: 0:00:27    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [3380/4572]  eta: 0:00:27    time: 0.0236  data: 0.0217  max mem: 13749
Epoch: [0]  [3400/4572]  eta: 0:00:26    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [3420/4572]  eta: 0:00:26    time: 0.0231  data: 0.0211  max mem: 13749
Epoch: [0]  [3440/4572]  eta: 0:00:26    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3460/4572]  eta: 0:00:25    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [0]  [3480/4572]  eta: 0:00:25    time: 0.0235  data: 0.0214  max mem: 13749
Epoch: [0]  [3500/4572]  eta: 0:00:24    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [3520/4572]  eta: 0:00:24    time: 0.0219  data: 0.0205  max mem: 13749
Epoch: [0]  [3540/4572]  eta: 0:00:23    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3560/4572]  eta: 0:00:23    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [3580/4572]  eta: 0:00:22    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3600/4572]  eta: 0:00:22    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [3620/4572]  eta: 0:00:21    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3640/4572]  eta: 0:00:21    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [3660/4572]  eta: 0:00:20    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3680/4572]  eta: 0:00:20    time: 0.0244  data: 0.0219  max mem: 13749
Epoch: [0]  [3700/4572]  eta: 0:00:20    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [3720/4572]  eta: 0:00:19    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [3740/4572]  eta: 0:00:19    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [3760/4572]  eta: 0:00:18    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3780/4572]  eta: 0:00:18    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [0]  [3800/4572]  eta: 0:00:17    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [3820/4572]  eta: 0:00:17    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [3840/4572]  eta: 0:00:16    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3860/4572]  eta: 0:00:16    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3880/4572]  eta: 0:00:15    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3900/4572]  eta: 0:00:15    time: 0.0219  data: 0.0202  max mem: 13749
Epoch: [0]  [3920/4572]  eta: 0:00:14    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [3940/4572]  eta: 0:00:14    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3960/4572]  eta: 0:00:14    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [3980/4572]  eta: 0:00:13    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4000/4572]  eta: 0:00:13    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [4020/4572]  eta: 0:00:12    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [0]  [4040/4572]  eta: 0:00:12    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [4060/4572]  eta: 0:00:11    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [4080/4572]  eta: 0:00:11    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [4100/4572]  eta: 0:00:10    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [4120/4572]  eta: 0:00:10    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [4140/4572]  eta: 0:00:09    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [4160/4572]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4180/4572]  eta: 0:00:09    time: 0.0229  data: 0.0206  max mem: 13749
Epoch: [0]  [4200/4572]  eta: 0:00:08    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [4220/4572]  eta: 0:00:08    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [4240/4572]  eta: 0:00:07    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [4280/4572]  eta: 0:00:06    time: 0.0238  data: 0.0219  max mem: 13749
Epoch: [0]  [4300/4572]  eta: 0:00:06    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [4320/4572]  eta: 0:00:05    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [4340/4572]  eta: 0:00:05    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4360/4572]  eta: 0:00:04    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [4380/4572]  eta: 0:00:04    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [4400/4572]  eta: 0:00:03    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [4420/4572]  eta: 0:00:03    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [4440/4572]  eta: 0:00:03    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [4460/4572]  eta: 0:00:02    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [0]  [4480/4572]  eta: 0:00:02    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [4500/4572]  eta: 0:00:01    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [4520/4572]  eta: 0:00:01    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4540/4572]  eta: 0:00:00    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [0] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746035346691, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1746035346691, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.02948372525265}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746035346696, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/13]  eta: 0:00:07  model_time: 0.5516 (0.5516)  evaluator_time: 0.0055 (0.0055)  time: 0.5624  data: 0.0005  max mem: 13749
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [12/13]  eta: 0:00:00  model_time: 0.3664 (0.3575)  evaluator_time: 0.0052 (0.0049)  time: 0.3637  data: 0.0008  max mem: 13749
Test: Total time: 0:00:04 (0.3637 s / it)
Averaged stats: model_time: 0.3664 (0.3630)  evaluator_time: 0.0052 (0.0050)
:::MLLOG {"namespace": "", "time_ms": 1746035352093, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:01:37    time: 0.0214  data: 0.0009  max mem: 13749
Epoch: [1]  [  20/4571]  eta: 0:01:40    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [  40/4571]  eta: 0:01:45    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [1]  [  60/4571]  eta: 0:01:42    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [1]  [  80/4571]  eta: 0:01:41    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 100/4571]  eta: 0:01:41    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [ 120/4571]  eta: 0:01:42    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [1]  [ 140/4571]  eta: 0:01:42    time: 0.0251  data: 0.0223  max mem: 13749
Epoch: [1]  [ 160/4571]  eta: 0:01:42    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [1]  [ 180/4571]  eta: 0:01:42    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [1]  [ 200/4571]  eta: 0:01:41    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 220/4571]  eta: 0:01:41    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [ 240/4571]  eta: 0:01:40    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [ 260/4571]  eta: 0:01:40    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [ 280/4571]  eta: 0:01:39    time: 0.0238  data: 0.0220  max mem: 13749
Epoch: [1]  [ 300/4571]  eta: 0:01:39    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [ 320/4571]  eta: 0:01:38    time: 0.0221  data: 0.0204  max mem: 13749
Epoch: [1]  [ 340/4571]  eta: 0:01:38    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [1]  [ 360/4571]  eta: 0:01:37    time: 0.0232  data: 0.0215  max mem: 13749
Epoch: [1]  [ 380/4571]  eta: 0:01:36    time: 0.0216  data: 0.0201  max mem: 13749
Epoch: [1]  [ 400/4571]  eta: 0:01:36    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [1]  [ 420/4571]  eta: 0:01:35    time: 0.0220  data: 0.0203  max mem: 13749
Epoch: [1]  [ 440/4571]  eta: 0:01:35    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [ 460/4571]  eta: 0:01:34    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [ 480/4571]  eta: 0:01:34    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [1]  [ 500/4571]  eta: 0:01:33    time: 0.0224  data: 0.0205  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746035364096, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1966948541328198, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746035364097, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 520/4571]  eta: 0:01:33    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [ 540/4571]  eta: 0:01:33    time: 0.0239  data: 0.0219  max mem: 13749
Epoch: [1]  [ 560/4571]  eta: 0:01:32    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [ 580/4571]  eta: 0:01:32    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 600/4571]  eta: 0:01:31    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [ 620/4571]  eta: 0:01:31    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 640/4571]  eta: 0:01:30    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [1]  [ 660/4571]  eta: 0:01:30    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [ 680/4571]  eta: 0:01:29    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [ 700/4571]  eta: 0:01:29    time: 0.0231  data: 0.0210  max mem: 13749
Epoch: [1]  [ 720/4571]  eta: 0:01:28    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [ 740/4571]  eta: 0:01:28    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [1]  [ 760/4571]  eta: 0:01:27    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 780/4571]  eta: 0:01:27    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [ 800/4571]  eta: 0:01:26    time: 0.0223  data: 0.0203  max mem: 13749
Epoch: [1]  [ 820/4571]  eta: 0:01:26    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [ 840/4571]  eta: 0:01:25    time: 0.0250  data: 0.0230  max mem: 13749
Epoch: [1]  [ 860/4571]  eta: 0:01:25    time: 0.0224  data: 0.0204  max mem: 13749
Epoch: [1]  [ 880/4571]  eta: 0:01:24    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [ 900/4571]  eta: 0:01:24    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [ 920/4571]  eta: 0:01:23    time: 0.0227  data: 0.0205  max mem: 13749
Epoch: [1]  [ 940/4571]  eta: 0:01:23    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [ 960/4571]  eta: 0:01:22    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [ 980/4571]  eta: 0:01:22    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [1]  [1000/4571]  eta: 0:01:22    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1020/4571]  eta: 0:01:21    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [1]  [1040/4571]  eta: 0:01:21    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1060/4571]  eta: 0:01:20    time: 0.0223  data: 0.0198  max mem: 13749
Epoch: [1]  [1080/4571]  eta: 0:01:20    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [1100/4571]  eta: 0:01:19    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1120/4571]  eta: 0:01:19    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [1140/4571]  eta: 0:01:18    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1160/4571]  eta: 0:01:18    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [1180/4571]  eta: 0:01:17    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1200/4571]  eta: 0:01:17    time: 0.0234  data: 0.0211  max mem: 13749
Epoch: [1]  [1220/4571]  eta: 0:01:16    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [1240/4571]  eta: 0:01:16    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [1260/4571]  eta: 0:01:16    time: 0.0242  data: 0.0218  max mem: 13749
Epoch: [1]  [1280/4571]  eta: 0:01:15    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [1300/4571]  eta: 0:01:15    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [1320/4571]  eta: 0:01:14    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1340/4571]  eta: 0:01:14    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [1360/4571]  eta: 0:01:13    time: 0.0222  data: 0.0205  max mem: 13749
Epoch: [1]  [1380/4571]  eta: 0:01:13    time: 0.0229  data: 0.0208  max mem: 13749
Epoch: [1]  [1400/4571]  eta: 0:01:12    time: 0.0229  data: 0.0208  max mem: 13749
Epoch: [1]  [1420/4571]  eta: 0:01:12    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [1440/4571]  eta: 0:01:11    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [1460/4571]  eta: 0:01:11    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [1]  [1480/4571]  eta: 0:01:10    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1500/4571]  eta: 0:01:10    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [1520/4571]  eta: 0:01:10    time: 0.0228  data: 0.0211  max mem: 13749
Epoch: [1]  [1540/4571]  eta: 0:01:09    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [1560/4571]  eta: 0:01:09    time: 0.0221  data: 0.0204  max mem: 13749
Epoch: [1]  [1580/4571]  eta: 0:01:08    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [1]  [1600/4571]  eta: 0:01:08    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1620/4571]  eta: 0:01:07    time: 0.0221  data: 0.0204  max mem: 13749
Epoch: [1]  [1640/4571]  eta: 0:01:07    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1660/4571]  eta: 0:01:06    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1680/4571]  eta: 0:01:06    time: 0.0228  data: 0.0211  max mem: 13749
Epoch: [1]  [1700/4571]  eta: 0:01:05    time: 0.0237  data: 0.0219  max mem: 13749
Epoch: [1]  [1720/4571]  eta: 0:01:05    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [1]  [1740/4571]  eta: 0:01:04    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [1]  [1760/4571]  eta: 0:01:04    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [1780/4571]  eta: 0:01:03    time: 0.0223  data: 0.0198  max mem: 13749
Epoch: [1]  [1800/4571]  eta: 0:01:03    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [1820/4571]  eta: 0:01:03    time: 0.0237  data: 0.0216  max mem: 13749
Epoch: [1]  [1840/4571]  eta: 0:01:02    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [1860/4571]  eta: 0:01:02    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [1880/4571]  eta: 0:01:01    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [1900/4571]  eta: 0:01:01    time: 0.0252  data: 0.0230  max mem: 13749
Epoch: [1]  [1920/4571]  eta: 0:01:00    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [1940/4571]  eta: 0:01:00    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [1960/4571]  eta: 0:00:59    time: 0.0231  data: 0.0212  max mem: 13749
Epoch: [1]  [1980/4571]  eta: 0:00:59    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2000/4571]  eta: 0:00:58    time: 0.0226  data: 0.0209  max mem: 13749
Epoch: [1]  [2020/4571]  eta: 0:00:58    time: 0.0223  data: 0.0206  max mem: 13749
Epoch: [1]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0202  max mem: 13749
Epoch: [1]  [2060/4571]  eta: 0:00:57    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2080/4571]  eta: 0:00:57    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2100/4571]  eta: 0:00:56    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [2120/4571]  eta: 0:00:56    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [2140/4571]  eta: 0:00:55    time: 0.0233  data: 0.0194  max mem: 13749
Epoch: [1]  [2160/4571]  eta: 0:00:55    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2180/4571]  eta: 0:00:54    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [2200/4571]  eta: 0:00:54    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [1]  [2220/4571]  eta: 0:00:53    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [2240/4571]  eta: 0:00:53    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [2260/4571]  eta: 0:00:52    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [1]  [2280/4571]  eta: 0:00:52    time: 0.0227  data: 0.0210  max mem: 13749
Epoch: [1]  [2300/4571]  eta: 0:00:52    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2320/4571]  eta: 0:00:51    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2340/4571]  eta: 0:00:51    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [2360/4571]  eta: 0:00:50    time: 0.0251  data: 0.0233  max mem: 13749
Epoch: [1]  [2380/4571]  eta: 0:00:50    time: 0.0232  data: 0.0211  max mem: 13749
Epoch: [1]  [2400/4571]  eta: 0:00:49    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [1]  [2420/4571]  eta: 0:00:49    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [2440/4571]  eta: 0:00:48    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [2460/4571]  eta: 0:00:48    time: 0.0228  data: 0.0198  max mem: 13749
Epoch: [1]  [2480/4571]  eta: 0:00:47    time: 0.0235  data: 0.0218  max mem: 13749
Epoch: [1]  [2500/4571]  eta: 0:00:47    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [2520/4571]  eta: 0:00:47    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [2540/4571]  eta: 0:00:46    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2560/4571]  eta: 0:00:46    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2580/4571]  eta: 0:00:45    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [2600/4571]  eta: 0:00:45    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [2620/4571]  eta: 0:00:44    time: 0.0224  data: 0.0204  max mem: 13749
Epoch: [1]  [2640/4571]  eta: 0:00:44    time: 0.0240  data: 0.0222  max mem: 13749
Epoch: [1]  [2660/4571]  eta: 0:00:43    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2680/4571]  eta: 0:00:43    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [2700/4571]  eta: 0:00:42    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [1]  [2720/4571]  eta: 0:00:42    time: 0.0221  data: 0.0200  max mem: 13749
Epoch: [1]  [2740/4571]  eta: 0:00:41    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [2760/4571]  eta: 0:00:41    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [2780/4571]  eta: 0:00:41    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [2800/4571]  eta: 0:00:40    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [1]  [2820/4571]  eta: 0:00:40    time: 0.0255  data: 0.0239  max mem: 13749
Epoch: [1]  [2840/4571]  eta: 0:00:39    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [2860/4571]  eta: 0:00:39    time: 0.0256  data: 0.0240  max mem: 13749
Epoch: [1]  [2880/4571]  eta: 0:00:38    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2900/4571]  eta: 0:00:38    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [1]  [2920/4571]  eta: 0:00:37    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [1]  [2940/4571]  eta: 0:00:37    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [2960/4571]  eta: 0:00:36    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [1]  [2980/4571]  eta: 0:00:36    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [3000/4571]  eta: 0:00:36    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [1]  [3020/4571]  eta: 0:00:35    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [3040/4571]  eta: 0:00:35    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [1]  [3060/4571]  eta: 0:00:34    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3080/4571]  eta: 0:00:34    time: 0.0220  data: 0.0193  max mem: 13749
Epoch: [1]  [3100/4571]  eta: 0:00:33    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [3120/4571]  eta: 0:00:33    time: 0.0250  data: 0.0235  max mem: 13749
Epoch: [1]  [3140/4571]  eta: 0:00:32    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [1]  [3160/4571]  eta: 0:00:32    time: 0.0251  data: 0.0235  max mem: 13749
Epoch: [1]  [3180/4571]  eta: 0:00:31    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [3200/4571]  eta: 0:00:31    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3220/4571]  eta: 0:00:31    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [1]  [3240/4571]  eta: 0:00:30    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3260/4571]  eta: 0:00:30    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [3280/4571]  eta: 0:00:29    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [3300/4571]  eta: 0:00:29    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [3320/4571]  eta: 0:00:28    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [3340/4571]  eta: 0:00:28    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [1]  [3360/4571]  eta: 0:00:27    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [1]  [3380/4571]  eta: 0:00:27    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [1]  [3400/4571]  eta: 0:00:26    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [3420/4571]  eta: 0:00:26    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [1]  [3440/4571]  eta: 0:00:25    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [1]  [3460/4571]  eta: 0:00:25    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [3480/4571]  eta: 0:00:25    time: 0.0221  data: 0.0204  max mem: 13749
Epoch: [1]  [3500/4571]  eta: 0:00:24    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [3520/4571]  eta: 0:00:24    time: 0.0232  data: 0.0211  max mem: 13749
Epoch: [1]  [3540/4571]  eta: 0:00:23    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3560/4571]  eta: 0:00:23    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [3580/4571]  eta: 0:00:22    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [1]  [3600/4571]  eta: 0:00:22    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [3620/4571]  eta: 0:00:21    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3640/4571]  eta: 0:00:21    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [3660/4571]  eta: 0:00:20    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [1]  [3680/4571]  eta: 0:00:20    time: 0.0228  data: 0.0203  max mem: 13749
Epoch: [1]  [3700/4571]  eta: 0:00:19    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [3720/4571]  eta: 0:00:19    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [1]  [3740/4571]  eta: 0:00:19    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [3760/4571]  eta: 0:00:18    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3780/4571]  eta: 0:00:18    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [1]  [3800/4571]  eta: 0:00:17    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [3820/4571]  eta: 0:00:17    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3840/4571]  eta: 0:00:16    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [3860/4571]  eta: 0:00:16    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [3880/4571]  eta: 0:00:15    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [1]  [3900/4571]  eta: 0:00:15    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3920/4571]  eta: 0:00:14    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [1]  [3940/4571]  eta: 0:00:14    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [1]  [3960/4571]  eta: 0:00:14    time: 0.0232  data: 0.0211  max mem: 13749
Epoch: [1]  [3980/4571]  eta: 0:00:13    time: 0.0217  data: 0.0201  max mem: 13749
Epoch: [1]  [4000/4571]  eta: 0:00:13    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [4020/4571]  eta: 0:00:12    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [4040/4571]  eta: 0:00:12    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [4060/4571]  eta: 0:00:11    time: 0.0220  data: 0.0195  max mem: 13749
Epoch: [1]  [4080/4571]  eta: 0:00:11    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [4100/4571]  eta: 0:00:10    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [4120/4571]  eta: 0:00:10    time: 0.0226  data: 0.0204  max mem: 13749
Epoch: [1]  [4140/4571]  eta: 0:00:09    time: 0.0241  data: 0.0214  max mem: 13749
Epoch: [1]  [4160/4571]  eta: 0:00:09    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [1]  [4180/4571]  eta: 0:00:08    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [4200/4571]  eta: 0:00:08    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [4220/4571]  eta: 0:00:08    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [1]  [4240/4571]  eta: 0:00:07    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [1]  [4260/4571]  eta: 0:00:07    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [4280/4571]  eta: 0:00:06    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [4300/4571]  eta: 0:00:06    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [1]  [4320/4571]  eta: 0:00:05    time: 0.0217  data: 0.0201  max mem: 13749
Epoch: [1]  [4340/4571]  eta: 0:00:05    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [4360/4571]  eta: 0:00:04    time: 0.0220  data: 0.0203  max mem: 13749
Epoch: [1]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [4400/4571]  eta: 0:00:03    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [1]  [4420/4571]  eta: 0:00:03    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [4440/4571]  eta: 0:00:03    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [4460/4571]  eta: 0:00:02    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [1]  [4480/4571]  eta: 0:00:02    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [1]  [4500/4571]  eta: 0:00:01    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [1]  [4520/4571]  eta: 0:00:01    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [4540/4571]  eta: 0:00:00    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [1] Total time: 0:01:44 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746035457088, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746035457088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.2089916837656}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746035457090, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2758 (0.2758)  evaluator_time: 0.0031 (0.0031)  time: 0.2800  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2700 (0.2551)  evaluator_time: 0.0034 (0.0033)  time: 0.2593  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2593 s / it)
Averaged stats: model_time: 0.2700 (0.2615)  evaluator_time: 0.0034 (0.0034)
:::MLLOG {"namespace": "", "time_ms": 1746035460935, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:01:34    time: 0.0208  data: 0.0007  max mem: 13749
Epoch: [2]  [  20/4572]  eta: 0:01:41    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [  40/4572]  eta: 0:01:40    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [2]  [  60/4572]  eta: 0:01:39    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [  80/4572]  eta: 0:01:40    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [ 100/4572]  eta: 0:01:40    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [ 120/4572]  eta: 0:01:40    time: 0.0233  data: 0.0216  max mem: 13749
Epoch: [2]  [ 140/4572]  eta: 0:01:39    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [2]  [ 160/4572]  eta: 0:01:39    time: 0.0221  data: 0.0204  max mem: 13749
Epoch: [2]  [ 180/4572]  eta: 0:01:38    time: 0.0218  data: 0.0201  max mem: 13749
Epoch: [2]  [ 200/4572]  eta: 0:01:38    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [ 220/4572]  eta: 0:01:37    time: 0.0223  data: 0.0206  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746035465969, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.27965517755750235, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746035465969, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 240/4572]  eta: 0:01:36    time: 0.0220  data: 0.0202  max mem: 13749
Epoch: [2]  [ 260/4572]  eta: 0:01:36    time: 0.0225  data: 0.0206  max mem: 13749
Epoch: [2]  [ 280/4572]  eta: 0:01:36    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [ 300/4572]  eta: 0:01:36    time: 0.0228  data: 0.0210  max mem: 13749
Epoch: [2]  [ 320/4572]  eta: 0:01:35    time: 0.0233  data: 0.0216  max mem: 13749
Epoch: [2]  [ 340/4572]  eta: 0:01:35    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [ 360/4572]  eta: 0:01:34    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [ 380/4572]  eta: 0:01:34    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [2]  [ 400/4572]  eta: 0:01:34    time: 0.0237  data: 0.0217  max mem: 13749
Epoch: [2]  [ 420/4572]  eta: 0:01:33    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [ 440/4572]  eta: 0:01:33    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [ 460/4572]  eta: 0:01:33    time: 0.0240  data: 0.0219  max mem: 13749
Epoch: [2]  [ 480/4572]  eta: 0:01:32    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [ 500/4572]  eta: 0:01:32    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [ 520/4572]  eta: 0:01:31    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [ 540/4572]  eta: 0:01:31    time: 0.0237  data: 0.0216  max mem: 13749
Epoch: [2]  [ 560/4572]  eta: 0:01:30    time: 0.0230  data: 0.0212  max mem: 13749
Epoch: [2]  [ 580/4572]  eta: 0:01:30    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [2]  [ 600/4572]  eta: 0:01:30    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 620/4572]  eta: 0:01:29    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [2]  [ 640/4572]  eta: 0:01:29    time: 0.0227  data: 0.0210  max mem: 13749
Epoch: [2]  [ 660/4572]  eta: 0:01:28    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [ 680/4572]  eta: 0:01:28    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [ 700/4572]  eta: 0:01:27    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [ 720/4572]  eta: 0:01:27    time: 0.0226  data: 0.0202  max mem: 13749
Epoch: [2]  [ 740/4572]  eta: 0:01:26    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [ 760/4572]  eta: 0:01:26    time: 0.0251  data: 0.0236  max mem: 13749
Epoch: [2]  [ 780/4572]  eta: 0:01:26    time: 0.0250  data: 0.0235  max mem: 13749
Epoch: [2]  [ 800/4572]  eta: 0:01:25    time: 0.0222  data: 0.0205  max mem: 13749
Epoch: [2]  [ 820/4572]  eta: 0:01:25    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [ 840/4572]  eta: 0:01:25    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [ 860/4572]  eta: 0:01:24    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [ 880/4572]  eta: 0:01:24    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [ 900/4572]  eta: 0:01:23    time: 0.0249  data: 0.0233  max mem: 13749
Epoch: [2]  [ 920/4572]  eta: 0:01:23    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [ 940/4572]  eta: 0:01:22    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [2]  [ 960/4572]  eta: 0:01:22    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [ 980/4572]  eta: 0:01:21    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1000/4572]  eta: 0:01:21    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [2]  [1020/4572]  eta: 0:01:21    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1040/4572]  eta: 0:01:20    time: 0.0247  data: 0.0231  max mem: 13749
Epoch: [2]  [1060/4572]  eta: 0:01:20    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1080/4572]  eta: 0:01:19    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [1100/4572]  eta: 0:01:19    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [1120/4572]  eta: 0:01:19    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1140/4572]  eta: 0:01:18    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [1160/4572]  eta: 0:01:18    time: 0.0219  data: 0.0202  max mem: 13749
Epoch: [2]  [1180/4572]  eta: 0:01:17    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [1200/4572]  eta: 0:01:17    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [2]  [1220/4572]  eta: 0:01:16    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [1240/4572]  eta: 0:01:16    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [2]  [1260/4572]  eta: 0:01:15    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1280/4572]  eta: 0:01:15    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [1300/4572]  eta: 0:01:14    time: 0.0230  data: 0.0210  max mem: 13749
Epoch: [2]  [1320/4572]  eta: 0:01:14    time: 0.0228  data: 0.0208  max mem: 13749
Epoch: [2]  [1340/4572]  eta: 0:01:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1360/4572]  eta: 0:01:13    time: 0.0235  data: 0.0218  max mem: 13749
Epoch: [2]  [1380/4572]  eta: 0:01:13    time: 0.0218  data: 0.0200  max mem: 13749
Epoch: [2]  [1400/4572]  eta: 0:01:12    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1420/4572]  eta: 0:01:12    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [1440/4572]  eta: 0:01:11    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1460/4572]  eta: 0:01:11    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [1480/4572]  eta: 0:01:10    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1500/4572]  eta: 0:01:10    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [1520/4572]  eta: 0:01:09    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [1540/4572]  eta: 0:01:09    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [1560/4572]  eta: 0:01:08    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [1580/4572]  eta: 0:01:08    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [2]  [1600/4572]  eta: 0:01:08    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [1620/4572]  eta: 0:01:07    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [1640/4572]  eta: 0:01:07    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1660/4572]  eta: 0:01:06    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [2]  [1680/4572]  eta: 0:01:06    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [1700/4572]  eta: 0:01:05    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [1720/4572]  eta: 0:01:05    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [1740/4572]  eta: 0:01:04    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [1760/4572]  eta: 0:01:04    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1780/4572]  eta: 0:01:03    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [1800/4572]  eta: 0:01:03    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [1820/4572]  eta: 0:01:02    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [2]  [1840/4572]  eta: 0:01:02    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [1860/4572]  eta: 0:01:02    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [1880/4572]  eta: 0:01:01    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1900/4572]  eta: 0:01:01    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [2]  [1920/4572]  eta: 0:01:00    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1940/4572]  eta: 0:01:00    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1960/4572]  eta: 0:00:59    time: 0.0246  data: 0.0230  max mem: 13749
Epoch: [2]  [1980/4572]  eta: 0:00:59    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [2]  [2000/4572]  eta: 0:00:58    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2020/4572]  eta: 0:00:58    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [2040/4572]  eta: 0:00:57    time: 0.0222  data: 0.0205  max mem: 13749
Epoch: [2]  [2060/4572]  eta: 0:00:57    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [2080/4572]  eta: 0:00:57    time: 0.0238  data: 0.0219  max mem: 13749
Epoch: [2]  [2100/4572]  eta: 0:00:56    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [2]  [2120/4572]  eta: 0:00:56    time: 0.0223  data: 0.0197  max mem: 13749
Epoch: [2]  [2140/4572]  eta: 0:00:55    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [2]  [2160/4572]  eta: 0:00:55    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2180/4572]  eta: 0:00:54    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [2200/4572]  eta: 0:00:54    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [2220/4572]  eta: 0:00:53    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [2240/4572]  eta: 0:00:53    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [2]  [2260/4572]  eta: 0:00:52    time: 0.0233  data: 0.0216  max mem: 13749
Epoch: [2]  [2280/4572]  eta: 0:00:52    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [2300/4572]  eta: 0:00:51    time: 0.0231  data: 0.0211  max mem: 13749
Epoch: [2]  [2320/4572]  eta: 0:00:51    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [2]  [2340/4572]  eta: 0:00:51    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [2360/4572]  eta: 0:00:50    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [2380/4572]  eta: 0:00:50    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [2]  [2400/4572]  eta: 0:00:49    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [2420/4572]  eta: 0:00:49    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [2440/4572]  eta: 0:00:48    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [2]  [2460/4572]  eta: 0:00:48    time: 0.0228  data: 0.0211  max mem: 13749
Epoch: [2]  [2480/4572]  eta: 0:00:47    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [2500/4572]  eta: 0:00:47    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [2520/4572]  eta: 0:00:46    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2540/4572]  eta: 0:00:46    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [2560/4572]  eta: 0:00:46    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [2580/4572]  eta: 0:00:45    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2600/4572]  eta: 0:00:45    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [2620/4572]  eta: 0:00:44    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2640/4572]  eta: 0:00:44    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [2660/4572]  eta: 0:00:43    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [2680/4572]  eta: 0:00:43    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [2700/4572]  eta: 0:00:42    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2720/4572]  eta: 0:00:42    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [2740/4572]  eta: 0:00:41    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [2760/4572]  eta: 0:00:41    time: 0.0227  data: 0.0203  max mem: 13749
Epoch: [2]  [2780/4572]  eta: 0:00:41    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [2]  [2800/4572]  eta: 0:00:40    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [2820/4572]  eta: 0:00:40    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [2840/4572]  eta: 0:00:39    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [2860/4572]  eta: 0:00:39    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [2880/4572]  eta: 0:00:38    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [2900/4572]  eta: 0:00:38    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [2920/4572]  eta: 0:00:37    time: 0.0247  data: 0.0230  max mem: 13749
Epoch: [2]  [2940/4572]  eta: 0:00:37    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [2960/4572]  eta: 0:00:36    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [2980/4572]  eta: 0:00:36    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [3000/4572]  eta: 0:00:35    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [3020/4572]  eta: 0:00:35    time: 0.0237  data: 0.0211  max mem: 13749
Epoch: [2]  [3040/4572]  eta: 0:00:35    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [2]  [3060/4572]  eta: 0:00:34    time: 0.0246  data: 0.0230  max mem: 13749
Epoch: [2]  [3080/4572]  eta: 0:00:34    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [3100/4572]  eta: 0:00:33    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3120/4572]  eta: 0:00:33    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3140/4572]  eta: 0:00:32    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [3160/4572]  eta: 0:00:32    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3180/4572]  eta: 0:00:31    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [3200/4572]  eta: 0:00:31    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [3220/4572]  eta: 0:00:30    time: 0.0245  data: 0.0228  max mem: 13749
Epoch: [2]  [3240/4572]  eta: 0:00:30    time: 0.0231  data: 0.0210  max mem: 13749
Epoch: [2]  [3260/4572]  eta: 0:00:30    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [2]  [3280/4572]  eta: 0:00:29    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [2]  [3300/4572]  eta: 0:00:29    time: 0.0236  data: 0.0219  max mem: 13749
Epoch: [2]  [3320/4572]  eta: 0:00:28    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [3340/4572]  eta: 0:00:28    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [3360/4572]  eta: 0:00:27    time: 0.0246  data: 0.0230  max mem: 13749
Epoch: [2]  [3380/4572]  eta: 0:00:27    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [3400/4572]  eta: 0:00:26    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [3420/4572]  eta: 0:00:26    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [2]  [3440/4572]  eta: 0:00:25    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3460/4572]  eta: 0:00:25    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [3480/4572]  eta: 0:00:25    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [3500/4572]  eta: 0:00:24    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [3520/4572]  eta: 0:00:24    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [3540/4572]  eta: 0:00:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3560/4572]  eta: 0:00:23    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [2]  [3580/4572]  eta: 0:00:22    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3600/4572]  eta: 0:00:22    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [3620/4572]  eta: 0:00:21    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [3640/4572]  eta: 0:00:21    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [3660/4572]  eta: 0:00:20    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [3680/4572]  eta: 0:00:20    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [2]  [3700/4572]  eta: 0:00:19    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3720/4572]  eta: 0:00:19    time: 0.0229  data: 0.0211  max mem: 13749
Epoch: [2]  [3740/4572]  eta: 0:00:19    time: 0.0228  data: 0.0211  max mem: 13749
Epoch: [2]  [3760/4572]  eta: 0:00:18    time: 0.0227  data: 0.0207  max mem: 13749
Epoch: [2]  [3780/4572]  eta: 0:00:18    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3800/4572]  eta: 0:00:17    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [3820/4572]  eta: 0:00:17    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [3840/4572]  eta: 0:00:16    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3860/4572]  eta: 0:00:16    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [3880/4572]  eta: 0:00:15    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [2]  [3900/4572]  eta: 0:00:15    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [3920/4572]  eta: 0:00:14    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [3940/4572]  eta: 0:00:14    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [3960/4572]  eta: 0:00:14    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [3980/4572]  eta: 0:00:13    time: 0.0217  data: 0.0201  max mem: 13749
Epoch: [2]  [4000/4572]  eta: 0:00:13    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [4020/4572]  eta: 0:00:12    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [4040/4572]  eta: 0:00:12    time: 0.0232  data: 0.0211  max mem: 13749
Epoch: [2]  [4060/4572]  eta: 0:00:11    time: 0.0242  data: 0.0225  max mem: 13749
Epoch: [2]  [4080/4572]  eta: 0:00:11    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [4100/4572]  eta: 0:00:10    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4120/4572]  eta: 0:00:10    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [4140/4572]  eta: 0:00:09    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [4160/4572]  eta: 0:00:09    time: 0.0253  data: 0.0238  max mem: 13749
Epoch: [2]  [4180/4572]  eta: 0:00:08    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [2]  [4200/4572]  eta: 0:00:08    time: 0.0235  data: 0.0208  max mem: 13749
Epoch: [2]  [4220/4572]  eta: 0:00:08    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [4240/4572]  eta: 0:00:07    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0198  max mem: 13749
Epoch: [2]  [4280/4572]  eta: 0:00:06    time: 0.0225  data: 0.0200  max mem: 13749
Epoch: [2]  [4300/4572]  eta: 0:00:06    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [4320/4572]  eta: 0:00:05    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [4340/4572]  eta: 0:00:05    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [2]  [4360/4572]  eta: 0:00:04    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4380/4572]  eta: 0:00:04    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [2]  [4400/4572]  eta: 0:00:03    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [4420/4572]  eta: 0:00:03    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [2]  [4440/4572]  eta: 0:00:03    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [4460/4572]  eta: 0:00:02    time: 0.0253  data: 0.0226  max mem: 13749
Epoch: [2]  [4480/4572]  eta: 0:00:02    time: 0.0217  data: 0.0201  max mem: 13749
Epoch: [2]  [4500/4572]  eta: 0:00:01    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [4520/4572]  eta: 0:00:01    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [4540/4572]  eta: 0:00:00    time: 0.0222  data: 0.0202  max mem: 13749
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2] Total time: 0:01:44 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746035565932, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746035565932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.23877647082534}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035565933, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2811 (0.2811)  evaluator_time: 0.0031 (0.0031)  time: 0.2851  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2777 (0.2602)  evaluator_time: 0.0035 (0.0032)  time: 0.2644  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2644 s / it)
Averaged stats: model_time: 0.2777 (0.2624)  evaluator_time: 0.0035 (0.0076)
:::MLLOG {"namespace": "", "time_ms": 1746035569856, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:01:36    time: 0.0211  data: 0.0009  max mem: 13749
Epoch: [3]  [  20/4571]  eta: 0:01:59    time: 0.0266  data: 0.0250  max mem: 13749
Epoch: [3]  [  40/4571]  eta: 0:01:53    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [  60/4571]  eta: 0:01:48    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [  80/4571]  eta: 0:01:47    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [3]  [ 100/4571]  eta: 0:01:46    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [ 120/4571]  eta: 0:01:46    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [ 140/4571]  eta: 0:01:45    time: 0.0232  data: 0.0215  max mem: 13749
Epoch: [3]  [ 160/4571]  eta: 0:01:44    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [ 180/4571]  eta: 0:01:45    time: 0.0269  data: 0.0253  max mem: 13749
Epoch: [3]  [ 200/4571]  eta: 0:01:44    time: 0.0224  data: 0.0208  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746035574739, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.324196024447654, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035574739, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 220/4571]  eta: 0:01:44    time: 0.0259  data: 0.0244  max mem: 13749
Epoch: [3]  [ 240/4571]  eta: 0:01:43    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [ 260/4571]  eta: 0:01:43    time: 0.0234  data: 0.0216  max mem: 13749
Epoch: [3]  [ 280/4571]  eta: 0:01:42    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [ 300/4571]  eta: 0:01:41    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [ 320/4571]  eta: 0:01:40    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [ 340/4571]  eta: 0:01:40    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [ 360/4571]  eta: 0:01:39    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [3]  [ 380/4571]  eta: 0:01:38    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [ 400/4571]  eta: 0:01:38    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 420/4571]  eta: 0:01:38    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [3]  [ 440/4571]  eta: 0:01:38    time: 0.0257  data: 0.0233  max mem: 13749
Epoch: [3]  [ 460/4571]  eta: 0:01:37    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [ 480/4571]  eta: 0:01:36    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [ 500/4571]  eta: 0:01:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [ 520/4571]  eta: 0:01:35    time: 0.0239  data: 0.0217  max mem: 13749
Epoch: [3]  [ 540/4571]  eta: 0:01:35    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [ 560/4571]  eta: 0:01:34    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [ 580/4571]  eta: 0:01:34    time: 0.0231  data: 0.0210  max mem: 13749
Epoch: [3]  [ 600/4571]  eta: 0:01:33    time: 0.0263  data: 0.0247  max mem: 13749
Epoch: [3]  [ 620/4571]  eta: 0:01:33    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [ 640/4571]  eta: 0:01:32    time: 0.0231  data: 0.0213  max mem: 13749
Epoch: [3]  [ 660/4571]  eta: 0:01:32    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [ 680/4571]  eta: 0:01:31    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [ 700/4571]  eta: 0:01:31    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [ 720/4571]  eta: 0:01:30    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [ 740/4571]  eta: 0:01:30    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [3]  [ 760/4571]  eta: 0:01:29    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [ 780/4571]  eta: 0:01:29    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [ 800/4571]  eta: 0:01:28    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [3]  [ 820/4571]  eta: 0:01:28    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [ 840/4571]  eta: 0:01:27    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [ 860/4571]  eta: 0:01:27    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [ 880/4571]  eta: 0:01:26    time: 0.0258  data: 0.0232  max mem: 13749
Epoch: [3]  [ 900/4571]  eta: 0:01:26    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [ 920/4571]  eta: 0:01:25    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [3]  [ 940/4571]  eta: 0:01:25    time: 0.0262  data: 0.0247  max mem: 13749
Epoch: [3]  [ 960/4571]  eta: 0:01:25    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [ 980/4571]  eta: 0:01:24    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [1000/4571]  eta: 0:01:23    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1020/4571]  eta: 0:01:23    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1040/4571]  eta: 0:01:23    time: 0.0247  data: 0.0226  max mem: 13749
Epoch: [3]  [1060/4571]  eta: 0:01:22    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [3]  [1080/4571]  eta: 0:01:21    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [3]  [1100/4571]  eta: 0:01:21    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1120/4571]  eta: 0:01:21    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [3]  [1140/4571]  eta: 0:01:20    time: 0.0242  data: 0.0219  max mem: 13749
Epoch: [3]  [1160/4571]  eta: 0:01:20    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [1180/4571]  eta: 0:01:19    time: 0.0231  data: 0.0214  max mem: 13749
Epoch: [3]  [1200/4571]  eta: 0:01:19    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [1220/4571]  eta: 0:01:18    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [1240/4571]  eta: 0:01:18    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [1260/4571]  eta: 0:01:17    time: 0.0261  data: 0.0245  max mem: 13749
Epoch: [3]  [1280/4571]  eta: 0:01:17    time: 0.0233  data: 0.0216  max mem: 13749
Epoch: [3]  [1300/4571]  eta: 0:01:16    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [1320/4571]  eta: 0:01:16    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [3]  [1340/4571]  eta: 0:01:15    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [1360/4571]  eta: 0:01:15    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [1380/4571]  eta: 0:01:14    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1400/4571]  eta: 0:01:14    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [3]  [1420/4571]  eta: 0:01:13    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [1440/4571]  eta: 0:01:13    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [1460/4571]  eta: 0:01:12    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [3]  [1480/4571]  eta: 0:01:12    time: 0.0249  data: 0.0233  max mem: 13749
Epoch: [3]  [1500/4571]  eta: 0:01:11    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [1520/4571]  eta: 0:01:11    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [1540/4571]  eta: 0:01:10    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [1560/4571]  eta: 0:01:10    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [1580/4571]  eta: 0:01:09    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [1600/4571]  eta: 0:01:09    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [3]  [1620/4571]  eta: 0:01:08    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [1640/4571]  eta: 0:01:08    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [1660/4571]  eta: 0:01:07    time: 0.0240  data: 0.0218  max mem: 13749
Epoch: [3]  [1680/4571]  eta: 0:01:07    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [1700/4571]  eta: 0:01:06    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [1720/4571]  eta: 0:01:06    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [1740/4571]  eta: 0:01:05    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [1760/4571]  eta: 0:01:05    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [3]  [1780/4571]  eta: 0:01:05    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [3]  [1800/4571]  eta: 0:01:04    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [1820/4571]  eta: 0:01:04    time: 0.0233  data: 0.0208  max mem: 13749
Epoch: [3]  [1840/4571]  eta: 0:01:03    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [1860/4571]  eta: 0:01:03    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [1880/4571]  eta: 0:01:02    time: 0.0255  data: 0.0239  max mem: 13749
Epoch: [3]  [1900/4571]  eta: 0:01:02    time: 0.0244  data: 0.0224  max mem: 13749
Epoch: [3]  [1920/4571]  eta: 0:01:01    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [1940/4571]  eta: 0:01:01    time: 0.0234  data: 0.0208  max mem: 13749
Epoch: [3]  [1960/4571]  eta: 0:01:00    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [1980/4571]  eta: 0:01:00    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [2000/4571]  eta: 0:00:59    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [2020/4571]  eta: 0:00:59    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [2060/4571]  eta: 0:00:58    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [3]  [2080/4571]  eta: 0:00:58    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [3]  [2100/4571]  eta: 0:00:57    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [2120/4571]  eta: 0:00:57    time: 0.0222  data: 0.0197  max mem: 13749
Epoch: [3]  [2140/4571]  eta: 0:00:56    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [2160/4571]  eta: 0:00:56    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [2180/4571]  eta: 0:00:55    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [2200/4571]  eta: 0:00:55    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [3]  [2220/4571]  eta: 0:00:54    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [2240/4571]  eta: 0:00:54    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [3]  [2260/4571]  eta: 0:00:53    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [2280/4571]  eta: 0:00:53    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2300/4571]  eta: 0:00:52    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [2320/4571]  eta: 0:00:52    time: 0.0255  data: 0.0219  max mem: 13749
Epoch: [3]  [2340/4571]  eta: 0:00:51    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [2360/4571]  eta: 0:00:51    time: 0.0236  data: 0.0207  max mem: 13749
Epoch: [3]  [2380/4571]  eta: 0:00:50    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [2400/4571]  eta: 0:00:50    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [2420/4571]  eta: 0:00:50    time: 0.0276  data: 0.0261  max mem: 13749
Epoch: [3]  [2440/4571]  eta: 0:00:49    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [3]  [2460/4571]  eta: 0:00:49    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2480/4571]  eta: 0:00:48    time: 0.0253  data: 0.0238  max mem: 13749
Epoch: [3]  [2500/4571]  eta: 0:00:48    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2520/4571]  eta: 0:00:47    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2540/4571]  eta: 0:00:47    time: 0.0229  data: 0.0209  max mem: 13749
Epoch: [3]  [2560/4571]  eta: 0:00:46    time: 0.0278  data: 0.0263  max mem: 13749
Epoch: [3]  [2580/4571]  eta: 0:00:46    time: 0.0244  data: 0.0227  max mem: 13749
Epoch: [3]  [2600/4571]  eta: 0:00:45    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2620/4571]  eta: 0:00:45    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2640/4571]  eta: 0:00:45    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [2660/4571]  eta: 0:00:44    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2680/4571]  eta: 0:00:44    time: 0.0226  data: 0.0207  max mem: 13749
Epoch: [3]  [2700/4571]  eta: 0:00:43    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2720/4571]  eta: 0:00:43    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2740/4571]  eta: 0:00:42    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [3]  [2760/4571]  eta: 0:00:42    time: 0.0238  data: 0.0221  max mem: 13749
Epoch: [3]  [2780/4571]  eta: 0:00:41    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [2800/4571]  eta: 0:00:41    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [2820/4571]  eta: 0:00:40    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [2840/4571]  eta: 0:00:40    time: 0.0263  data: 0.0248  max mem: 13749
Epoch: [3]  [2860/4571]  eta: 0:00:39    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2880/4571]  eta: 0:00:39    time: 0.0233  data: 0.0212  max mem: 13749
Epoch: [3]  [2900/4571]  eta: 0:00:38    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [2920/4571]  eta: 0:00:38    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [2940/4571]  eta: 0:00:37    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2960/4571]  eta: 0:00:37    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [2980/4571]  eta: 0:00:37    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [3000/4571]  eta: 0:00:36    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3020/4571]  eta: 0:00:36    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [3040/4571]  eta: 0:00:35    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3060/4571]  eta: 0:00:35    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3080/4571]  eta: 0:00:34    time: 0.0228  data: 0.0210  max mem: 13749
Epoch: [3]  [3100/4571]  eta: 0:00:34    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [3120/4571]  eta: 0:00:33    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3140/4571]  eta: 0:00:33    time: 0.0241  data: 0.0227  max mem: 13749
Epoch: [3]  [3160/4571]  eta: 0:00:32    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3180/4571]  eta: 0:00:32    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [3]  [3200/4571]  eta: 0:00:31    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3220/4571]  eta: 0:00:31    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3240/4571]  eta: 0:00:30    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3260/4571]  eta: 0:00:30    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3280/4571]  eta: 0:00:29    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3300/4571]  eta: 0:00:29    time: 0.0233  data: 0.0211  max mem: 13749
Epoch: [3]  [3320/4571]  eta: 0:00:29    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [3340/4571]  eta: 0:00:28    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [3360/4571]  eta: 0:00:28    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [3380/4571]  eta: 0:00:27    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3400/4571]  eta: 0:00:27    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [3420/4571]  eta: 0:00:26    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [3]  [3440/4571]  eta: 0:00:26    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [3460/4571]  eta: 0:00:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [3480/4571]  eta: 0:00:25    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [3500/4571]  eta: 0:00:24    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [3520/4571]  eta: 0:00:24    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [3540/4571]  eta: 0:00:23    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [3560/4571]  eta: 0:00:23    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [3]  [3580/4571]  eta: 0:00:22    time: 0.0235  data: 0.0209  max mem: 13749
Epoch: [3]  [3600/4571]  eta: 0:00:22    time: 0.0246  data: 0.0230  max mem: 13749
Epoch: [3]  [3620/4571]  eta: 0:00:22    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [3640/4571]  eta: 0:00:21    time: 0.0241  data: 0.0216  max mem: 13749
Epoch: [3]  [3660/4571]  eta: 0:00:21    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [3680/4571]  eta: 0:00:20    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [3700/4571]  eta: 0:00:20    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [3720/4571]  eta: 0:00:19    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [3740/4571]  eta: 0:00:19    time: 0.0238  data: 0.0220  max mem: 13749
Epoch: [3]  [3760/4571]  eta: 0:00:18    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [3780/4571]  eta: 0:00:18    time: 0.0229  data: 0.0212  max mem: 13749
Epoch: [3]  [3800/4571]  eta: 0:00:17    time: 0.0217  data: 0.0201  max mem: 13749
Epoch: [3]  [3820/4571]  eta: 0:00:17    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [3840/4571]  eta: 0:00:16    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [3860/4571]  eta: 0:00:16    time: 0.0254  data: 0.0238  max mem: 13749
Epoch: [3]  [3880/4571]  eta: 0:00:16    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [3900/4571]  eta: 0:00:15    time: 0.0231  data: 0.0208  max mem: 13749
Epoch: [3]  [3920/4571]  eta: 0:00:15    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [3940/4571]  eta: 0:00:14    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [3960/4571]  eta: 0:00:14    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [3980/4571]  eta: 0:00:13    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [4000/4571]  eta: 0:00:13    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [4020/4571]  eta: 0:00:12    time: 0.0231  data: 0.0205  max mem: 13749
Epoch: [3]  [4040/4571]  eta: 0:00:12    time: 0.0258  data: 0.0242  max mem: 13749
Epoch: [3]  [4060/4571]  eta: 0:00:11    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [4080/4571]  eta: 0:00:11    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [3]  [4100/4571]  eta: 0:00:10    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [3]  [4120/4571]  eta: 0:00:10    time: 0.0228  data: 0.0203  max mem: 13749
Epoch: [3]  [4140/4571]  eta: 0:00:09    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [4160/4571]  eta: 0:00:09    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [4180/4571]  eta: 0:00:09    time: 0.0231  data: 0.0214  max mem: 13749
Epoch: [3]  [4200/4571]  eta: 0:00:08    time: 0.0231  data: 0.0212  max mem: 13749
Epoch: [3]  [4220/4571]  eta: 0:00:08    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [3]  [4240/4571]  eta: 0:00:07    time: 0.0229  data: 0.0212  max mem: 13749
Epoch: [3]  [4260/4571]  eta: 0:00:07    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [4280/4571]  eta: 0:00:06    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [4300/4571]  eta: 0:00:06    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [4320/4571]  eta: 0:00:05    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [4340/4571]  eta: 0:00:05    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [3]  [4360/4571]  eta: 0:00:04    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [4380/4571]  eta: 0:00:04    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [3]  [4400/4571]  eta: 0:00:03    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [3]  [4420/4571]  eta: 0:00:03    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [3]  [4440/4571]  eta: 0:00:03    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [3]  [4460/4571]  eta: 0:00:02    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [4480/4571]  eta: 0:00:02    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [4500/4571]  eta: 0:00:01    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [3]  [4520/4571]  eta: 0:00:01    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [4540/4571]  eta: 0:00:00    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3] Total time: 0:01:45 (0.0232 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746035675808, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746035675808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 172.63319970312241}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746035675810, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2562 (0.2562)  evaluator_time: 0.0031 (0.0031)  time: 0.2604  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2642 (0.2467)  evaluator_time: 0.0034 (0.0032)  time: 0.2509  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2509 s / it)
Averaged stats: model_time: 0.2642 (0.2486)  evaluator_time: 0.0034 (0.0039)
:::MLLOG {"namespace": "", "time_ms": 1746035679474, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:01:39    time: 0.0218  data: 0.0007  max mem: 13749
Epoch: [4]  [  20/4572]  eta: 0:01:46    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [4]  [  40/4572]  eta: 0:01:47    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [4]  [  60/4572]  eta: 0:01:44    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [4]  [  80/4572]  eta: 0:01:44    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [4]  [ 100/4572]  eta: 0:01:42    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [4]  [ 120/4572]  eta: 0:01:42    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [4]  [ 140/4572]  eta: 0:01:41    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [4]  [ 160/4572]  eta: 0:01:40    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [4]  [ 180/4572]  eta: 0:01:40    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [4]  [ 200/4572]  eta: 0:01:39    time: 0.0219  data: 0.0204  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746035684113, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3472803533495513, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746035684113, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746035684490, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1746035684491, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746035684491, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 177.29837765431483}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:07:22
:::MLLOG {"namespace": "", "time_ms": 1746035684491, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 783}}

GPU-1006:2741541:2741925 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 61, retcode 3

GPU-726:2702180:2702661 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2702174:2702668 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2702101:2702662 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2702101:2702662 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2702101:2702662 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2702174:2702668 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 18, retcode 3

GPU-682:4048771:4049167 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048771:4049167 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4048771:4049167 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 60, retcode 3
[rank16]:[W430 17:54:45.207532071 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-726:2702177:2702660 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702177:2702660 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2702177:2702660 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2702101:2702662 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2702101:2702662 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2702174:2702668 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 16, retcode 3

GPU-761:100448:100882 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Loading annotations into memory...
Done (t=1.08s)
Creating index...
Done (t=1.28s)
Loading and preparing results...
DONE (t=3.89s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.27s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.19669
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.31893
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.20583
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00621
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.04922
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.21718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.48136
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01877
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.54918
Loading and preparing results...
DONE (t=2.44s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.41s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27966
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42135
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.29997
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00571
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.30928
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53420
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.55846
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.22841
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.60754
Loading and preparing results...
DONE (t=2.41s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.26s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.46790
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.34737
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00761
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35890
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39721
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.58952
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03284
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23865
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64185
Loading and preparing results...
DONE (t=2.25s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.20s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34728
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49275
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37266
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00942
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09079
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38459
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57812
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60456
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03815
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65589

GPU-753:3596594:3597007 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 36, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3
[rank40]:[W430 17:54:45.641868674 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-903:3419969:3420345 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419987:3420344 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419976:3420346 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419976:3420346 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3419976:3420346 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3419964:3420347 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419987:3420344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3419976:3420346 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3419976:3420346 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3419964:3420347 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3419987:3420344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3419969:3420345 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3419976:3420346 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3419976:3420346 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3419987:3420344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 41, retcode 3

GPU-903:3419976:3420346 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3419976:3420346 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3419969:3420345 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 41, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3419964:3420347 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3419964:3420347 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 41, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 41, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 41, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 40, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3

GPU-903:3419979:3420349 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419987:3420344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3419976:3420346 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419976:3420346 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419969:3420345 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3419964:3420347 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3419979:3420349 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3419979:3420349 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3

GPU-753:3596618:3597002 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596618:3597002 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3596618:3597002 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 34, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 34, retcode 3
[rank32]:[W430 17:54:45.736327766 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-753:3596638:3597004 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596634:3597003 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596634:3597003 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3596634:3597003 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3596634:3597003 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3596634:3597003 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3596618:3597002 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3596618:3597002 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3596618:3597002 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3596618:3597002 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3596638:3597004 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3596638:3597004 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3596638:3597004 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3596638:3597004 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3596615:3597001 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596634:3597003 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3596634:3597003 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3596615:3597001 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3596615:3597001 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3596618:3597002 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3596618:3597002 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3596638:3597004 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3596638:3597004 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3596579:3597010 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596634:3597003 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596634:3597003 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596615:3597001 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596615:3597001 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596618:3597002 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596618:3597002 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596638:3597004 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596638:3597004 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596579:3597010 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3596579:3597010 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3596619:3597005 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3596634:3597003 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596634:3597003 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3596615:3597001 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596615:3597001 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3596618:3597002 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596618:3597002 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3596638:3597004 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596638:3597004 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3596594:3597007 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596594:3597007 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3596624:3597006 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596624:3597006 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3596619:3597005 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596619:3597005 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3

GPU-682:4048785:4049164 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048785:4049164 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4048785:4049164 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4048771:4049167 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4048771:4049167 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4048782:4049166 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048785:4049164 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4048785:4049164 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4048782:4049166 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4048782:4049166 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4048771:4049167 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4048771:4049167 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 59, retcode 3
[rank56]:[W430 17:54:45.134300065 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4048786:4049163 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048786:4049163 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4048786:4049163 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4048785:4049164 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4048785:4049164 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4048782:4049166 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4048782:4049166 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4048771:4049167 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4048771:4049167 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4048781:4049165 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048786:4049163 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048786:4049163 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4048785:4049164 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048785:4049164 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4048781:4049165 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048781:4049165 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4048782:4049166 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048782:4049166 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4048771:4049167 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048771:4049167 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 58, retcode 3

GPU-1006:2741531:2741933 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741531:2741933 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2741531:2741933 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 10, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 53, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 55, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 55, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:100497:100873 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3

GPU-761:100498:100872 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 54, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 54, retcode 3

GPU-761:100498:100872 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:100498:100872 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:100497:100873 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 54, retcode 3

GPU-1006:2741540:2741929 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741531:2741933 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2741531:2741933 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2741540:2741929 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2741540:2741929 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 12, retcode 3

GPU-753:3596579:3597010 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3596579:3597010 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 38, retcode 3

GPU-1006:2741543:2741927 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741531:2741933 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2741531:2741933 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2741540:2741929 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2741540:2741929 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2741543:2741927 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2741543:2741927 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 13, retcode 3

GPU-903:3419936:3420350 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3419987:3420344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419987:3420344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3419976:3420346 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419976:3420346 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3419969:3420345 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419969:3420345 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3419964:3420347 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419964:3420347 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3419944:3420351 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419944:3420351 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3419936:3420350 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419936:3420350 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3419914:3420348 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419914:3420348 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 45, retcode 3

GPU-682:4048776:4049160 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4048786:4049163 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048786:4049163 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048785:4049164 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048785:4049164 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048781:4049165 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048781:4049165 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048782:4049166 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048782:4049166 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048771:4049167 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048771:4049167 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048769:4049168 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048769:4049168 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048695:4049162 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048695:4049162 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4048776:4049160 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4048776:4049160 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 26, retcode 3

GPU-726:2702196:2702663 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702177:2702660 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2702177:2702660 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2702101:2702662 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2702101:2702662 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2702196:2702663 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2702196:2702663 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2702174:2702668 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 19, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 19, retcode 3

GPU-1006:2741526:2741937 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741526:2741937 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2741526:2741937 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2741531:2741933 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2741531:2741933 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2741540:2741929 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2741540:2741929 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2741543:2741927 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2741543:2741927 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 9, retcode 3
[rank8]:[W430 17:54:45.272298835 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-1006:2741446:2741936 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741446:2741936 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741446:2741936 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741526:2741937 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741526:2741937 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741531:2741933 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741531:2741933 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741540:2741929 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741540:2741929 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741543:2741927 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741543:2741927 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2741507:2741931 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2741446:2741936 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741446:2741936 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2741526:2741937 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741526:2741937 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2741531:2741933 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741531:2741933 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2741507:2741931 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741507:2741931 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2741540:2741929 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741540:2741929 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2741543:2741927 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741543:2741927 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 11, retcode 3

GPU-903:3419979:3420349 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3419979:3420349 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 45, retcode 3

GPU-47:4101405:4101780 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101405:4101780 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4101405:4101780 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 25, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 25, retcode 3

GPU-761:100476:100881 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100452:100880 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100476:100881 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:100476:100881 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 51, retcode 3

GPU-761:100476:100881 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:100476:100881 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3

GPU-761:100452:100880 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:100452:100880 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3

GPU-761:100452:100880 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:100452:100880 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 50, retcode 3

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 50, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 50, retcode 3

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 51, retcode 3

GPU-761:100498:100872 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:100498:100872 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 50, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 51, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:100497:100873 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 50, retcode 3

GPU-761:100498:100872 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:100498:100872 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 51, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:100497:100873 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 51, retcode 3

GPU-47:4101381:4101783 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101405:4101780 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4101405:4101780 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4101381:4101783 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4101381:4101783 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 27, retcode 3

GPU-761:100475:100878 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100475:100878 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100475:100878 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3

GPU-761:100476:100881 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100476:100881 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 49, retcode 3

GPU-761:100452:100880 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100452:100880 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 49, retcode 3

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 49, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 49, retcode 3

GPU-761:100498:100872 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100498:100872 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 49, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:100497:100873 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 49, retcode 3
[rank48]:[W430 17:54:45.191776910 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-761:100449:100879 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:100449:100879 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100449:100879 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3

GPU-761:100475:100878 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100475:100878 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 48, retcode 3

GPU-761:100476:100881 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100476:100881 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 48, retcode 3

GPU-761:100452:100880 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100452:100880 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 48, retcode 3

GPU-726:2702188:2702670 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702177:2702660 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702177:2702660 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702101:2702662 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702101:2702662 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702196:2702663 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702196:2702663 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702174:2702668 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702188:2702670 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2702188:2702670 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2702199:2702671 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2702177:2702660 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702177:2702660 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702180:2702661 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702180:2702661 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702101:2702662 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702101:2702662 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702196:2702663 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702196:2702663 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702174:2702668 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702174:2702668 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702184:2702669 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702184:2702669 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702199:2702671 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702199:2702671 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2702188:2702670 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2702188:2702670 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 22, retcode 3

GPU-47:4101317:4101782 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101405:4101780 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4101405:4101780 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4101381:4101783 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4101381:4101783 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4101317:4101782 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4101317:4101782 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3

GPU-1006:2741541:2741925 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741541:2741925 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2741527:2741924 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2741527:2741924 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 11, retcode 3

GPU-761:100448:100882 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100448:100882 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 48, retcode 3

GPU-761:100395:100874 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100395:100874 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 48, retcode 3

GPU-761:100498:100872 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100498:100872 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 48, retcode 3

GPU-761:100497:100873 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:100497:100873 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 48, retcode 3

GPU-47:4101411:4101781 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101405:4101780 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4101405:4101780 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 30, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 30, retcode 3

GPU-47:4101381:4101783 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4101381:4101783 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 30, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 30, retcode 3

GPU-47:4101317:4101782 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4101317:4101782 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 30, retcode 3

GPU-47:4101411:4101781 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4101411:4101781 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3
[rank24]:[W430 17:54:45.462182550 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-47:4101416:4101778 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101416:4101778 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101416:4101778 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101405:4101780 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101405:4101780 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101381:4101783 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101381:4101783 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101317:4101782 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101317:4101782 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101411:4101781 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4101411:4101781 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4101384:4101784 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4101416:4101778 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101416:4101778 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101405:4101780 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101405:4101780 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101398:4101779 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101398:4101779 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101381:4101783 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101381:4101783 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101395:4101785 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101395:4101785 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101317:4101782 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101317:4101782 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101411:4101781 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101411:4101781 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4101384:4101784 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4101384:4101784 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3

GPU-790:2780918:2781316 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2780923:2781313 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2780861:2781312 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2780923:2781313 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2780861:2781312 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2780861:2781312 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2780919:2781311 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2780923:2781313 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2780861:2781312 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2780861:2781312 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2780919:2781311 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2780919:2781311 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2780950:2781315 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2780950:2781315 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2780950:2781315 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2780923:2781313 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2780861:2781312 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2780861:2781312 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2780919:2781311 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2780919:2781311 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2780949:2781310 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2780950:2781315 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780950:2781315 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780923:2781313 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2780861:2781312 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780861:2781312 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2780919:2781311 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780919:2781311 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2780949:2781310 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2780949:2781310 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jrf1shtk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-vlccpbeo': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zmihrxza': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-mgagleor': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-1wh2ob_q': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-38s6f1d4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-s64imuou': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5kirho3f': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ur1ogc5k': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-0jlr4jl7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-hyz_djzi': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zu0um706': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-wyk32l2w': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-lcr7ik4j': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-0rn1bwj4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fkiowd3x': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ka868ago': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-waxrxy5l': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-deuqyhcl': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-bqf67jaf': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_i1pbf0t': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-szp4l18w': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-f2umsxi0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-qjjrrvhe': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-o1mp3l71': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_osods_l': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-v8l0sjr7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fxdblru7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-yqsndbz4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-at9ot8b1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-usk3i3ry': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-489lex4g': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-135pt20c': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5qiukh40': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-w12cecz2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-1y9uvu0o': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-kekwcgxh': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-xlr1cw9m': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-kso4oo43': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_hg5es9s': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-xlisbywm': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2laa4lif': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ecs0w1ze': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-f4b4ph_5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-hmh0hh95': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-i8vy5p3e': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-k6n0k_8c': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ybubuwox': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-i3o8sjqc': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jydqdyej': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-a0whmdd3': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-994mt3od': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-60q0rddt': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-8_6u_upk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-xf25oetw': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-i2fl20u3': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2r4kruq4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-usv5x49l': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-juzkw_bi': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-r43n2cdo': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6y01p_5u': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-s7yxb1or': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jaiy3u1c': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-b211gcv5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-bp_l2gtf': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ywaomo6b': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-akplsitw': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-y0qg_pf_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sywymkny': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-p20a2hf_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ek2j3lbj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-in45pua7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-nl8vw9sy': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-c6cp62q3': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-uzlctzz0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ggc2zjmv': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-v9fczfl3': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ekuak_ij': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-vsx7jx6u': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sf3vvu4i': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-08vk6kxt': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-4jhgqppo': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-k33lkn3x': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-83totsi9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-67k6he_6': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_ersimsm': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ohski46v': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jivglzdb': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7j84nbj2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sx7ab234': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-duwlqojj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-afu2p7iv': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-909etwa0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-omiijlts': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-k3z684f_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-80a5p9n9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7es0li7p': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-74rzwo00': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6zd8pwl4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-z2elpfaj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-88ydd0ea': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_riv22gb': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-yxlbhtk5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-pm_hxi_9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-he1eonu_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-apf86wuy': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_6h1eh8z': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-dekd7elr': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-a7vw7vyx': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sr2mki8m': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-icbocol_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7i5gdzl2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7uvxy31j': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ayix7k_q': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5xyf4403': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ins8z4p2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-hnc1tmbb': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5eeo7ts4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-rkhk709p': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-rlwjtgey': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7g4dbz4y': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-vgx03zvx': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-lgpbvp7r': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-wtsap_tt': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-l2byloli': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-w7cflrko': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-v3iizp7f': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zg3o5c77': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-s0hbwpuh': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jrv9ruyd': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jf3ecdyg': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-t1wroi37': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-w3b437y0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-9lc8anu0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-rw3nmcfu': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fqqag8nl': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-n9i4hx9x': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-msawb961': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-gcigl6yd': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-barlj1ah': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-8dycsv8z': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-thqrck0b': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2sz8dnn4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5vno3iz_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-uwa2ky_p': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-0tu47f33': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sbe7_3ci': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-8jckp_8n': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-w76d5yrx': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6b8a8kio': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-nhz6d0af': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-bo8eorc3': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-vrsis0ql': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-d2wgwhsj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ulnvtn8n': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-qxppnj7l': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-d9jdrwro': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-spajozrk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-gp4_9skk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6nfty33d': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5h22j00m': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-l4heum34': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zqorb0cv': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7ajtjucm': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-kvjhk4vc': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-c5jhb867': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-f5ydmjjz': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-p1ms2oov': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-l8tr15b0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ol2zd3se': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-42jqkpae': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-n1w2239d': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-au0o1zq2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-4q5q0_ln': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-lak5ght9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-co66ww3k': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-b6dkr664': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-01uvkpo8': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zy3jg9ae': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-x_q50wu9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-gnq3jojr': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-n602593c': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-los2qkg1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2vf5rb04': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ajpx9jjm': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6dy5g527': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-1yf6rber': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-3asptjba': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ra_3kkoh': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-yyvc4x6i': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-iub3hv6v': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fkcea0ut': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7i2g2jtg': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-g5ftxdmk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ssg7_0my': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/usr/lib/python3.10/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib/python3.10/multiprocessing/synchronize.py", line 87, in _cleanup
    sem_unlink(name)
FileNotFoundError: [Errno 2] No such file or directory
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-m_fy53b6': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-l63a8odt': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6orh7qfi': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-683e8wk5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-l1z51hzz': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fayp0vgj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-3m6k6e3j': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-9uq3n63q': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-b21clh42': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-1oq6babl': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_lgsdmdk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-o0cfvgy6': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sjs2g8xx': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-q77glqmz': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-c0355wdh': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-9yxt702e': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_67mmhmj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-rgtyul5a': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ubs2ecm8': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-xur16el0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-g98u7k07': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zbdqsz15': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-kf6hq_b5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-3822c7ni': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-g5mz_1mm': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-xf6mhwi1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2vt2m9dc': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-hpgoa88j': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ll4upou1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-686cmw0t': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-n4oy_seq': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zomipl8p': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-saiysykj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-rffqw6n9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_59deg0c': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2h5twc68': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-gdwmj2yp': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-d8r69l6l': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-47ay31wg': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-qqe68g29': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-3qxvlb59': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-l8671g_8': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-s0uo0xk7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-m3b1dihb': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-e3rlv8z_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-19fd051r': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-vl62kpp_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5bqwqmrk': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-0082cfbf': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-csswbti7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
[rank0]:[W430 17:54:47.400989620 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-790:2780903:2781324 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2780903:2781324 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780903:2781324 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780918:2781316 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780918:2781316 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780950:2781315 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780950:2781315 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780944:2781314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780944:2781314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780923:2781313 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780923:2781313 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780861:2781312 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780861:2781312 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780919:2781311 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780919:2781311 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2780949:2781310 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2780949:2781310 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 0, retcode 3
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-we1dl01q': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-qxzg21g2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_279vcac': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-hua7lxb9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_7ocujmz': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sfbe0axr': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-uapisbcq': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5v477djd': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-maamu_a8': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-kaz1qfui': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ik2ertyp': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-nwlxqyfo': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7n4ye1z5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-qkwvhlmo': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-3sg_99mu': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-43fm9w6i': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-suoluhbb': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-didjw2kc': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-w7p1fck8': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-b72_heq7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-1hjo3my7': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-foreg_0i': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-c88594qd': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-0_nh0w6r': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-gkiq2_5l': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-r2atny8d': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-uqxulca4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zffw_32d': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-uexwba6o': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-aco99a8z': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-5pa7uuac': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-x8mdpbco': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-wdz6csre': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-00a0tsdr': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-zkil_wit': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ar9_es3c': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-alj16kz1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-8jv7wd22': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-wtsruixg': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-86ay384t': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-bk4fhiec': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-mie_i6cv': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fbhfn_r0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_5vri5t5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-rhjx2ihx': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ve2xsesg': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7zbu1q94': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-sy6ov90k': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-c2jf56bm': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-g51tuk_y': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-mct0jidc': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-gwu87jnw': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-op0ne0v2': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-dy38q6st': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-bq9slwp1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ye2k0uep': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-2p4zaj0u': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-tr4uylcz': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-9pti5ci0': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-_zqg1rst': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-xiawsyzg': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-a2wla9r9': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-tpyknfu_': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-7ppqlum1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ckij441i': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 10 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-9a8t_3ao': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-nbm03m9n': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-urtq1223': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-knjyxo7k': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-j31emrlr': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-6l124qpj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-h9y_dkyf': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-tyjjol_d': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-jg3zgmrj': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-ov6_x647': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-pmdgjxvq': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-snfo1npq': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-numh3pg5': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-tdxzczi1': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
/usr/lib/python3.10/multiprocessing/resource_tracker.py:237: UserWarning: resource_tracker: '/mp-fipojui4': [Errno 2] No such file or directory
  warnings.warn('resource_tracker: %r: %s' % (name, e))
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:49 PM
RESULT,SINGLE_STAGE_DETECTOR,,535,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:50 PM
RESULT,SINGLE_STAGE_DETECTOR,,536,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
ENDING TIMING RUN AT 2025-04-30 05:54:51 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:45:54 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746035691'
RUNANDTIME_STOP 1746035691
+ set -e
