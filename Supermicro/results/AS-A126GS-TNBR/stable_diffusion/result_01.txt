+ echo 'Beginning trial 01 of 15'
Beginning trial 01 of 15
+ echo ':::DLPAL /mlptrn_50/sd_0423.sqsh 83 1 as-a126gs-tnbr '\''unknown'\'' AS-A126GS-TNBR_01x08x32'
:::DLPAL /mlptrn_50/sd_0423.sqsh 83 1 as-a126gs-tnbr 'unknown' AS-A126GS-TNBR_01x08x32
++ srun -N1 -n1 --container-name=stable_diffusion_83 --no-container-mount-home --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"Supermicro_77","division":"closed","status":"Available on-premise","system_name":"AS-A126GS-TNBR","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"AMD EPYC 9575F 64-Core Processor","host_processor_core_count":"64","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.8.0-58-generic","nvidia_kernel_driver":"570.133.20"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"Supermicro_77","division":"closed","status":"Available on-premise","system_name":"AS-A126GS-TNBR","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"AMD EPYC 9575F 64-Core Processor","host_processor_core_count":"64","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.8.0-58-generic","nvidia_kernel_driver":"570.133.20"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=stable_diffusion_83 --no-container-mount-home --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID 8c262b08b227bd43cefaeedd061fe71d67271031 
+ [[ 1 -eq 1 ]]
+ srun --ntasks-per-node=1 --mpi=pmix bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on as-a126gs-tnbr
vm.drop_caches = 3
+ srun --ntasks-per-node=1 --mpi=pmix --container-name=stable_diffusion_83 --no-container-mount-home --container-writable python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1745517731376, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=17287
+ RANDOM_SEED=17287
+ export EXP_NAME=stable-diffusion2-train-250424-180056-01
+ EXP_NAME=stable-diffusion2-train-250424-180056-01
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1745517731'
RUNANDTIME_START 1745517731
+ srun -l --mpi=pmix --ntasks-per-node=8 --time=110 --container-name=stable_diffusion_83 --no-container-mount-home --container-writable --container-mounts=./results:/results,/mlptrn_data/sd/datasets/laion-400m/webdataset-moments-filtered-encoded:/datasets,/mlptrn_data/sd/datasets/coco2014:/coco2014/,/mlptrn_data/sd/checkpoints/clip:/checkpoints/clip,/mlptrn_data/sd/checkpoints/inception:/checkpoints/inception,/mlptrn_data/sd/checkpoints/sd:/checkpoints/sd --container-workdir=/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
0: RANDOM_SEED=17287
0: :::MLLOG {"namespace": "", "time_ms": 1745517750799, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 86}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517752310, "event_type": "POINT_IN_TIME", "key": "seed", "value": 474539251, "metadata": {"file": "/workspace/sd/main.py", "lineno": 109}}
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: HPU available: False, using: 0 HPUs
0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8
3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8
7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8
2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8
5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8
1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8
6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8
4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8
0: ----------------------------------------------------------------------------------------------------
0: distributed_backend=nccl
0: All distributed processes registered. Starting with 8 processes
0: ----------------------------------------------------------------------------------------------------
0: 
4: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
6: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
7: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
5: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
0: :::MLLOG {"namespace": "", "time_ms": 1745517774161, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 271}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774175, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774175, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 279}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 280}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 281}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 282}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 283}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 7.168e-05, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 285}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 286}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 291}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 292}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Supermicro", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517774176, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xAS-A126GS-TNBR", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
0: 
0:   | Name  | Type            | Params | Mode 
0: --------------------------------------------------
0: 0 | model | LatentDiffusion | 865 M  | train
0: --------------------------------------------------
0: 865 M     Trainable params
0: 0         Non-trainable params
0: 865 M     Total params
0: 3,463.643 Total estimated model params size (MB)
0: 993       Modules in train mode
0: 482       Modules in eval mode
0: SLURM auto-requeueing enabled. Setting signal handlers.
2: SLURM auto-requeueing enabled. Setting signal handlers.
5: SLURM auto-requeueing enabled. Setting signal handlers.
3: SLURM auto-requeueing enabled. Setting signal handlers.
4: SLURM auto-requeueing enabled. Setting signal handlers.
7: SLURM auto-requeueing enabled. Setting signal handlers.
6: SLURM auto-requeueing enabled. Setting signal handlers.
1: SLURM auto-requeueing enabled. Setting signal handlers.
0: CUDAGraphCallback: disable autocast cache.
0: CUDAGraphCallback: disable autocast cache.
4: [1/3] c++ -MMD -MF geglu.o.d -DTORCH_EXTENSION_NAME=nemo_stable_diffusion_fast_geglu_ext -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /usr/local/lib/python3.12/dist-packages/torch/include -isystem /usr/local/lib/python3.12/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /usr/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /workspace/NeMo/nemo/collections/multimodal/modules/stable_diffusion/fast_geglu/geglu.cpp -o geglu.o 
4: [2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output geglu_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=nemo_stable_diffusion_fast_geglu_ext -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /usr/local/lib/python3.12/dist-packages/torch/include -isystem /usr/local/lib/python3.12/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /usr/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=compute_120 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' -O2 --use_fast_math --ftz=false -U__CU
4: DA_NO_HALF_CONVERSIONS__ -std=c++17 -c /workspace/NeMo/nemo/collections/multimodal/modules/stable_diffusion/fast_geglu/geglu_cuda.cu -o geglu_cuda.cuda.o 
4: [3/3] c++ geglu.o geglu_cuda.cuda.o -shared -L/usr/local/lib/python3.12/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o nemo_stable_diffusion_fast_geglu_ext.so
0: CUDAGraphCallback: set optimizer.zero_grad as nop during graph capturing.
0: :::MLLOG {"namespace": "", "time_ms": 1745517820799, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 426}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517820800, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 426}}
0: :::MLLOG {"namespace": "", "time_ms": 1745517820801, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 0}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518052220, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 0}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518052221, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1851.003333184919, "train_step_time": 0.13830337061550016, "max_memory_usage": 30.025}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 0}}
0: Epoch 0, global step 2000: 'timestamp' reached 1745518052219.00000 (best 1745518052219.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250424-180056-01/checkpoints/stable-diffusion2-train-250424-180056-01--timestamp=1745518052219.0-step=2000-consumed_samples=512000.0.ckpt' as top 1
0: :::MLLOG {"namespace": "", "time_ms": 1745518053577, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 512000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518287534, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 512000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518287535, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2175.8125200665827, "train_step_time": 0.11765719593899848, "max_memory_usage": 30.025}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 2000}}
0: Epoch 1, global step 4000: 'timestamp' reached 1745518287534.00000 (best 1745518052219.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250424-180056-01/checkpoints/stable-diffusion2-train-250424-180056-01--timestamp=1745518287534.0-step=4000-consumed_samples=1024000.0.ckpt' as top 2
0: :::MLLOG {"namespace": "", "time_ms": 1745518288870, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 1024000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518523060, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 1024000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518523060, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2173.8620252200394, "train_step_time": 0.11776276370350024, "max_memory_usage": 30.025}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 4000}}
0: Epoch 1, global step 6000: 'timestamp' reached 1745518523059.00000 (best 1745518052219.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250424-180056-01/checkpoints/stable-diffusion2-train-250424-180056-01--timestamp=1745518523059.0-step=6000-consumed_samples=1536000.0.ckpt' as top 3
0: :::MLLOG {"namespace": "", "time_ms": 1745518524386, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 1536000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518758710, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 1536000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518758711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2172.7063662833516, "train_step_time": 0.11782540152349975, "max_memory_usage": 30.025}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 6000}}
0: Epoch 2, global step 8000: 'timestamp' reached 1745518758710.00000 (best 1745518052219.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250424-180056-01/checkpoints/stable-diffusion2-train-250424-180056-01--timestamp=1745518758710.0-step=8000-consumed_samples=2048000.0.ckpt' as top 4
0: :::MLLOG {"namespace": "", "time_ms": 1745518760028, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 2048000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518994297, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 2048000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518994297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2173.302168296065, "train_step_time": 0.11779310016550153, "max_memory_usage": 30.025}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 8000}}
0: Epoch 3, global step 10000: 'timestamp' reached 1745518994296.00000 (best 1745518052219.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250424-180056-01/checkpoints/stable-diffusion2-train-250424-180056-01--timestamp=1745518994296.0-step=10000-consumed_samples=2560000.0.ckpt' as top 5
0: `Trainer.fit` stopped: `max_steps=10000` reached.
1: [rank1]:[W424 18:23:20.105326389 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
3: [rank3]:[W424 18:23:20.134361096 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
4: [rank4]:[W424 18:23:20.135691877 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
5: [rank5]:[W424 18:23:20.152642738 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
6: [rank6]:[W424 18:23:20.154422849 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
7: [rank7]:[W424 18:23:20.155657383 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
0: [rank0]:[W424 18:23:20.295522087 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
2: [rank2]:[W424 18:23:20.555386057 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
0: CKPT_PATH=/tmp/nemologs/stable-diffusion2-train-250424-180056-01/checkpoints/
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: HPU available: False, using: 0 HPUs
0: setting number of microbatches to constant 1
0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8
1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8
3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8
6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8
4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8
7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8
5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8
2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8
0: ----------------------------------------------------------------------------------------------------
0: distributed_backend=nccl
0: All distributed processes registered. Starting with 8 processes
0: ----------------------------------------------------------------------------------------------------
0: 
3: [rank3]:[W424 18:23:55.646877748 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: [rank0]:[W424 18:23:56.664090103 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
1: [rank1]:[W424 18:23:56.666736905 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
4: [rank4]:[W424 18:23:56.674893577 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
6: [rank6]:[W424 18:23:56.785981188 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
5: [rank5]:[W424 18:23:56.790144657 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
7: [rank7]:[W424 18:23:56.791505107 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
2: [rank2]:[W424 18:23:56.792372988 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1745519039408, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1024000}}
0: ninja: no work to do.
7: ninja: no work to do.
2: ninja: no work to do.
0: :::MLLOG {"namespace": "", "time_ms": 1745519699826, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 116.16146985173668, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 194, "samples_count": 1024000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745519733245, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1450488567352295, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 224, "samples_count": 1024000, "metric": "CLIP"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745519733246, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 235, "samples_count": 1024000}}
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: HPU available: False, using: 0 HPUs
0: :::MLLOG {"namespace": "", "time_ms": 1745519741748, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1536000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745520399079, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 81.469527963492, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 194, "samples_count": 1536000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745520432715, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1689419001340866, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 224, "samples_count": 1536000, "metric": "CLIP"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745520432715, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 235, "samples_count": 1536000}}
0: :::MLLOG {"namespace": "", "time_ms": 1745518523059, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 6000}}
++ date +%s
+ echo 'RUNANDTIME_STOP 1745520439'
RUNANDTIME_STOP 1745520439
+ set -e
