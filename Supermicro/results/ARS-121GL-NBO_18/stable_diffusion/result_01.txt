+ echo 'Beginning trial 01 of 10'
Beginning trial 01 of 10
+ echo ':::DLPAL /mlperf_data/nvdlfwea+mlperftv50+stable_diffusion-arm+20250423.sqsh 38 18 gb200node[01-18] '\''unknown'\'' GB200_18x04x08'
:::DLPAL /mlperf_data/nvdlfwea+mlperftv50+stable_diffusion-arm+20250423.sqsh 38 18 gb200node[01-18] 'unknown' GB200_18x04x08
++ srun -N1 -n1 --container-name=stable_diffusion_38 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"18","host_processors_per_node":"2","host_processor_model_name":"Neoverse-V2","host_processor_core_count":"72","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"4","accelerator_model_name":"HGX GB200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"189471 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.8.0-1026-nvidia-64k","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"18","host_processors_per_node":"2","host_processor_model_name":"Neoverse-V2","host_processor_core_count":"72","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"4","accelerator_model_name":"HGX GB200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"189471 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.8.0-1026-nvidia-64k","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=stable_diffusion_38 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID 8c262b08b227bd43cefaeedd061fe71d67271031 
+ [[ 1 -eq 1 ]]
+ srun --ntasks-per-node=1 --mpi=pmix bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on gb200node04
Clearing cache on gb200node16
Clearing cache on gb200node06
Clearing cache on gb200node08
Clearing cache on gb200node09
Clearing cache on gb200node12
Clearing cache on gb200node01
Clearing cache on gb200node17
Clearing cache on gb200node13
Clearing cache on gb200node02
Clearing cache on gb200node05
Clearing cache on gb200node14
Clearing cache on gb200node03
Clearing cache on gb200node07
Clearing cache on gb200node15
Clearing cache on gb200node18
Clearing cache on gb200node10
Clearing cache on gb200node11
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks-per-node=1 --mpi=pmix --container-name=stable_diffusion_38 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746144577892, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577898, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577893, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577902, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577902, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577903, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577908, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577909, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577917, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577927, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577934, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577935, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577940, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577946, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577962, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577966, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577969, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746144577995, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=15080
+ RANDOM_SEED=15080
+ export EXP_NAME=stable-diffusion2-train-250501170821306610851-01
+ EXP_NAME=stable-diffusion2-train-250501170821306610851-01
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746144578'
RUNANDTIME_START 1746144578
+ srun -l --mpi=pmix --ntasks-per-node=4 --time=50 --container-name=stable_diffusion_38 --no-container-mount-home --container-remap-root --container-writable --container-mounts=./results:/results,/mlperf_data/sd/datasets/laion-400m/webdataset-moments-filtered-encoded:/datasets,/mlperf_data/sd/datasets/coco2014:/coco2014/,/mlperf_data/sd/checkpoints/clip:/checkpoints/clip,/mlperf_data/sd/checkpoints/inception:/checkpoints/inception,/mlperf_data/sd/checkpoints/sd:/checkpoints/sd --container-workdir=/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: RANDOM_SEED=15080
 0: :::MLLOG {"namespace": "", "time_ms": 1746144592156, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144592846, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1865175748, "metadata": {"file": "/workspace/sd/main.py", "lineno": 109}}
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: [NeMo E 2025-05-01 17:09:52 nemo_logging:417] You are running multi-node training without SLURM handling the processes. Please note that this is not tested in NeMo and could result in errors.
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/72
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/72
52: Initializing distributed: GLOBAL_RANK: 52, MEMBER: 53/72
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/72
60: Initializing distributed: GLOBAL_RANK: 60, MEMBER: 61/72
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/72
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/72
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/72
44: Initializing distributed: GLOBAL_RANK: 44, MEMBER: 45/72
54: Initializing distributed: GLOBAL_RANK: 54, MEMBER: 55/72
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/72
55: Initializing distributed: GLOBAL_RANK: 55, MEMBER: 56/72
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/72
61: Initializing distributed: GLOBAL_RANK: 61, MEMBER: 62/72
36: Initializing distributed: GLOBAL_RANK: 36, MEMBER: 37/72
32: Initializing distributed: GLOBAL_RANK: 32, MEMBER: 33/72
56: Initializing distributed: GLOBAL_RANK: 56, MEMBER: 57/72
62: Initializing distributed: GLOBAL_RANK: 62, MEMBER: 63/72
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/72
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/72
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/72
53: Initializing distributed: GLOBAL_RANK: 53, MEMBER: 54/72
64: Initializing distributed: GLOBAL_RANK: 64, MEMBER: 65/72
63: Initializing distributed: GLOBAL_RANK: 63, MEMBER: 64/72
34: Initializing distributed: GLOBAL_RANK: 34, MEMBER: 35/72
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/72
59: Initializing distributed: GLOBAL_RANK: 59, MEMBER: 60/72
47: Initializing distributed: GLOBAL_RANK: 47, MEMBER: 48/72
37: Initializing distributed: GLOBAL_RANK: 37, MEMBER: 38/72
66: Initializing distributed: GLOBAL_RANK: 66, MEMBER: 67/72
46: Initializing distributed: GLOBAL_RANK: 46, MEMBER: 47/72
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/72
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/72
39: Initializing distributed: GLOBAL_RANK: 39, MEMBER: 40/72
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/72
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/72
35: Initializing distributed: GLOBAL_RANK: 35, MEMBER: 36/72
33: Initializing distributed: GLOBAL_RANK: 33, MEMBER: 34/72
68: Initializing distributed: GLOBAL_RANK: 68, MEMBER: 69/72
38: Initializing distributed: GLOBAL_RANK: 38, MEMBER: 39/72
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/72
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/72
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/72
71: Initializing distributed: GLOBAL_RANK: 71, MEMBER: 72/72
40: Initializing distributed: GLOBAL_RANK: 40, MEMBER: 41/72
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/72
69: Initializing distributed: GLOBAL_RANK: 69, MEMBER: 70/72
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/72
45: Initializing distributed: GLOBAL_RANK: 45, MEMBER: 46/72
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/72
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/72
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/72
70: Initializing distributed: GLOBAL_RANK: 70, MEMBER: 71/72
57: Initializing distributed: GLOBAL_RANK: 57, MEMBER: 58/72
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/72
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/72
42: Initializing distributed: GLOBAL_RANK: 42, MEMBER: 43/72
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/72
67: Initializing distributed: GLOBAL_RANK: 67, MEMBER: 68/72
65: Initializing distributed: GLOBAL_RANK: 65, MEMBER: 66/72
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/72
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/72
43: Initializing distributed: GLOBAL_RANK: 43, MEMBER: 44/72
48: Initializing distributed: GLOBAL_RANK: 48, MEMBER: 49/72
50: Initializing distributed: GLOBAL_RANK: 50, MEMBER: 51/72
51: Initializing distributed: GLOBAL_RANK: 51, MEMBER: 52/72
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/72
58: Initializing distributed: GLOBAL_RANK: 58, MEMBER: 59/72
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/72
41: Initializing distributed: GLOBAL_RANK: 41, MEMBER: 42/72
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/72
49: Initializing distributed: GLOBAL_RANK: 49, MEMBER: 50/72
 0: ----------------------------------------------------------------------------------------------------
 0: distributed_backend=nccl
 0: All distributed processes registered. Starting with 72 processes
 0: ----------------------------------------------------------------------------------------------------
 0: 
 0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
12: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
16: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
24: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
32: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
30: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
56: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
48: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
37: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 4: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
20: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
64: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
60: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
40: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
52: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
44: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 8: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
14: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
68: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
15: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
17: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
25: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
18: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
33: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
26: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
19: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
35: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
27: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
34: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
59: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
50: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
31: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
13: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
58: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
21: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
49: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
28: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 5: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
22: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
51: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
38: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 6: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
23: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
66: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
39: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
61: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 7: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
42: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
67: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
36: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
63: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
57: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
45: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
53: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
43: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
65: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 9: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
69: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
62: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
46: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
54: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
41: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
10: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
70: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
47: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
55: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
11: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
71: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
29: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618904, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 271}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618919, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 576, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 279}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 280}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 281}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 282}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 283}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.000117504, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 285}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 286}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 291}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618920, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 292}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618921, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618921, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618921, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618921, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144618921, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "18xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 294}}
 0: 
 0:   | Name  | Type            | Params | Mode 
 0: --------------------------------------------------
 0: 0 | model | LatentDiffusion | 865 M  | train
 0: --------------------------------------------------
 0: 865 M     Trainable params
 0: 0         Non-trainable params
 0: 865 M     Total params
 0: 3,463.643 Total estimated model params size (MB)
 0: 993       Modules in train mode
 0: 482       Modules in eval mode
 1: SLURM auto-requeueing enabled. Setting signal handlers.
 3: SLURM auto-requeueing enabled. Setting signal handlers.
 0: SLURM auto-requeueing enabled. Setting signal handlers.
21: SLURM auto-requeueing enabled. Setting signal handlers.
 2: SLURM auto-requeueing enabled. Setting signal handlers.
69: SLURM auto-requeueing enabled. Setting signal handlers.
25: SLURM auto-requeueing enabled. Setting signal handlers.
18: SLURM auto-requeueing enabled. Setting signal handlers.
39: SLURM auto-requeueing enabled. Setting signal handlers.
 4: SLURM auto-requeueing enabled. Setting signal handlers.
14: SLURM auto-requeueing enabled. Setting signal handlers.
58: SLURM auto-requeueing enabled. Setting signal handlers.
28: SLURM auto-requeueing enabled. Setting signal handlers.
22: SLURM auto-requeueing enabled. Setting signal handlers.
35: SLURM auto-requeueing enabled. Setting signal handlers.
23: SLURM auto-requeueing enabled. Setting signal handlers.
20: SLURM auto-requeueing enabled. Setting signal handlers.
44: SLURM auto-requeueing enabled. Setting signal handlers.
60: SLURM auto-requeueing enabled. Setting signal handlers.
53: SLURM auto-requeueing enabled. Setting signal handlers.
70: SLURM auto-requeueing enabled. Setting signal handlers.
50: SLURM auto-requeueing enabled. Setting signal handlers.
65: SLURM auto-requeueing enabled. Setting signal handlers.
 9: SLURM auto-requeueing enabled. Setting signal handlers.
71: SLURM auto-requeueing enabled. Setting signal handlers.
24: SLURM auto-requeueing enabled. Setting signal handlers.
40: SLURM auto-requeueing enabled. Setting signal handlers.
68: SLURM auto-requeueing enabled. Setting signal handlers.
26: SLURM auto-requeueing enabled. Setting signal handlers.
27: SLURM auto-requeueing enabled. Setting signal handlers.
19: SLURM auto-requeueing enabled. Setting signal handlers.
 5: SLURM auto-requeueing enabled. Setting signal handlers.
16: SLURM auto-requeueing enabled. Setting signal handlers.
36: SLURM auto-requeueing enabled. Setting signal handlers.
 7: SLURM auto-requeueing enabled. Setting signal handlers.
17: SLURM auto-requeueing enabled. Setting signal handlers.
37: SLURM auto-requeueing enabled. Setting signal handlers.
15: SLURM auto-requeueing enabled. Setting signal handlers.
59: SLURM auto-requeueing enabled. Setting signal handlers.
 6: SLURM auto-requeueing enabled. Setting signal handlers.
38: SLURM auto-requeueing enabled. Setting signal handlers.
31: SLURM auto-requeueing enabled. Setting signal handlers.
12: SLURM auto-requeueing enabled. Setting signal handlers.
56: SLURM auto-requeueing enabled. Setting signal handlers.
29: SLURM auto-requeueing enabled. Setting signal handlers.
13: SLURM auto-requeueing enabled. Setting signal handlers.
30: SLURM auto-requeueing enabled. Setting signal handlers.
32: SLURM auto-requeueing enabled. Setting signal handlers.
33: SLURM auto-requeueing enabled. Setting signal handlers.
46: SLURM auto-requeueing enabled. Setting signal handlers.
48: SLURM auto-requeueing enabled. Setting signal handlers.
61: SLURM auto-requeueing enabled. Setting signal handlers.
34: SLURM auto-requeueing enabled. Setting signal handlers.
45: SLURM auto-requeueing enabled. Setting signal handlers.
51: SLURM auto-requeueing enabled. Setting signal handlers.
41: SLURM auto-requeueing enabled. Setting signal handlers.
 8: SLURM auto-requeueing enabled. Setting signal handlers.
62: SLURM auto-requeueing enabled. Setting signal handlers.
47: SLURM auto-requeueing enabled. Setting signal handlers.
52: SLURM auto-requeueing enabled. Setting signal handlers.
42: SLURM auto-requeueing enabled. Setting signal handlers.
64: SLURM auto-requeueing enabled. Setting signal handlers.
10: SLURM auto-requeueing enabled. Setting signal handlers.
63: SLURM auto-requeueing enabled. Setting signal handlers.
54: SLURM auto-requeueing enabled. Setting signal handlers.
43: SLURM auto-requeueing enabled. Setting signal handlers.
67: SLURM auto-requeueing enabled. Setting signal handlers.
11: SLURM auto-requeueing enabled. Setting signal handlers.
55: SLURM auto-requeueing enabled. Setting signal handlers.
66: SLURM auto-requeueing enabled. Setting signal handlers.
57: SLURM auto-requeueing enabled. Setting signal handlers.
49: SLURM auto-requeueing enabled. Setting signal handlers.
 0: CUDAGraphCallback: disable autocast cache.
 0: CUDAGraphCallback: disable autocast cache.
60: ninja: no work to do.
36: ninja: no work to do.
61: ninja: no work to do.
57: ninja: no work to do.
32: ninja: no work to do.
37: ninja: no work to do.
12: ninja: no work to do.
44: ninja: no work to do.
38: ninja: no work to do.
54: ninja: no work to do.
33: ninja: no work to do.
45: ninja: no work to do.
28: ninja: no work to do.
 1: ninja: no work to do.
52: ninja: no work to do.
 3: ninja: no work to do.
63: ninja: no work to do.
14: ninja: no work to do.
20: ninja: no work to do.
 4: ninja: no work to do.
35: ninja: no work to do.
21: ninja: no work to do.
15: ninja: no work to do.
39: ninja: no work to do.
62: ninja: no work to do.
55: ninja: no work to do.
48: ninja: no work to do.
30: ninja: no work to do.
58: ninja: no work to do.
23: ninja: no work to do.
 6: ninja: no work to do.
40: ninja: no work to do.
59: ninja: no work to do.
13: ninja: no work to do.
47: ninja: no work to do.
22: ninja: no work to do.
 2: ninja: no work to do.
42: ninja: no work to do.
16: ninja: no work to do.
11: ninja: no work to do.
27: ninja: no work to do.
53: ninja: no work to do.
49: ninja: no work to do.
10: ninja: no work to do.
64: ninja: no work to do.
24: ninja: no work to do.
71: ninja: no work to do.
17: ninja: no work to do.
51: ninja: no work to do.
 0: ninja: no work to do.
68: ninja: no work to do.
 0: CUDAGraphCallback: set optimizer.zero_grad as nop during graph capturing.
 0: :::MLLOG {"namespace": "", "time_ms": 1746144682909, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 426}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144682909, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 426}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144682910, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144714818, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144714819, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.468158842038, "train_step_time": 0.10665741988626135, "max_memory_usage": 11.104}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 0}}
 0: Epoch 0, global step 888: 'timestamp' reached 1746144714818.00000 (best 1746144714818.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/stable-diffusion2-train-250501170821306610851-01--timestamp=1746144714818.0-step=888-consumed_samples=511488.0.ckpt' as top 1
 0: :::MLLOG {"namespace": "", "time_ms": 1746144715316, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 511488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144747384, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 511488}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144747384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 15706.547659645059, "train_step_time": 0.03667260383896588, "max_memory_usage": 11.104}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 888}}
 0: Epoch 1, global step 1776: 'timestamp' reached 1746144747383.00000 (best 1746144714818.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/stable-diffusion2-train-250501170821306610851-01--timestamp=1746144747383.0-step=1776-consumed_samples=1022976.0.ckpt' as top 2
 0: :::MLLOG {"namespace": "", "time_ms": 1746144747855, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 1022976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144780019, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 1022976}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144780019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 15672.933153864073, "train_step_time": 0.03675125736486603, "max_memory_usage": 11.104}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 1776}}
 0: Epoch 1, global step 2664: 'timestamp' reached 1746144780018.00000 (best 1746144714818.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/stable-diffusion2-train-250501170821306610851-01--timestamp=1746144780018.0-step=2664-consumed_samples=1534464.0.ckpt' as top 3
 0: :::MLLOG {"namespace": "", "time_ms": 1746144780498, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 1534464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144812727, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 1534464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144812727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 15637.904691574728, "train_step_time": 0.03683357913738488, "max_memory_usage": 11.104}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 2664}}
 0: Epoch 2, global step 3552: 'timestamp' reached 1746144812726.00000 (best 1746144714818.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/stable-diffusion2-train-250501170821306610851-01--timestamp=1746144812726.0-step=3552-consumed_samples=2045952.0.ckpt' as top 4
 0: :::MLLOG {"namespace": "", "time_ms": 1746144813267, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 2045952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144845550, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 2045952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144845551, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 15582.98394220612, "train_step_time": 0.036963395594595876, "max_memory_usage": 11.104}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 3552}}
 0: Epoch 3, global step 4440: 'timestamp' reached 1746144845550.00000 (best 1746144714818.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/stable-diffusion2-train-250501170821306610851-01--timestamp=1746144845550.0-step=4440-consumed_samples=2557440.0.ckpt' as top 5
 0: :::MLLOG {"namespace": "", "time_ms": 1746144846080, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 2557440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144878395, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 470, "samples_count": 2557440}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144878396, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 15572.840419192482, "train_step_time": 0.036987472066439375, "max_memory_usage": 11.104}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 494, "step_num": 4440}}
 0: Epoch 3, global step 5328: 'timestamp' reached 1746144878395.00000 (best 1746144714818.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/stable-diffusion2-train-250501170821306610851-01--timestamp=1746144878395.0-step=5328-consumed_samples=3068928.0.ckpt' as top 6
 0: :::MLLOG {"namespace": "", "time_ms": 1746144878926, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 436, "samples_count": 3068928}}
 0: `Trainer.fit` stopped: `max_steps=6000` reached.
 0: [rank0]:[W501 17:15:17.925515519 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
16: [rank16]:[W501 17:15:17.656277905 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 4: [rank4]:[W501 17:15:17.663217215 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 8: [rank8]:[W501 17:15:17.331487957 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
12: [rank12]:[W501 17:15:17.177777848 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
24: [rank24]:[W501 17:15:17.086291487 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
28: [rank28]:[W501 17:15:17.781673943 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
32: [rank32]:[W501 17:15:17.694768798 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
36: [rank36]:[W501 17:15:17.084257723 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
40: [rank40]:[W501 17:15:17.556938633 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
44: [rank44]:[W501 17:15:17.634197574 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
48: [rank48]:[W501 17:15:18.707163763 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
52: [rank52]:[W501 17:15:18.958522953 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
56: [rank56]:[W501 17:15:18.141320630 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
60: [rank60]:[W501 17:15:18.684185877 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
64: [rank64]:[W501 17:15:18.500441412 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
68: [rank68]:[W501 17:15:18.793204183 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 1: [rank1]:[W501 17:15:18.401926194 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 2: [rank2]:[W501 17:15:18.411971883 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 3: [rank3]:[W501 17:15:18.422031204 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 5: [rank5]:[W501 17:15:18.168556914 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 6: [rank6]:[W501 17:15:18.178633194 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 7: [rank7]:[W501 17:15:18.188738721 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 9: [rank9]:[W501 17:15:18.827914083 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
10: [rank10]:[W501 17:15:18.837977415 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
11: [rank11]:[W501 17:15:18.848114475 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
13: [rank13]:[W501 17:15:18.707614813 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
14: [rank14]:[W501 17:15:18.717719630 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
20: [rank20]:[W501 17:15:18.265817618 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
15: [rank15]:[W501 17:15:18.727722846 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
17: [rank17]:[W501 17:15:18.293296036 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
18: [rank18]:[W501 17:15:18.303331810 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
19: [rank19]:[W501 17:15:18.313406048 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
21: [rank21]:[W501 17:15:18.329558541 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
22: [rank22]:[W501 17:15:18.337580016 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
23: [rank23]:[W501 17:15:18.347609100 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
25: [rank25]:[W501 17:15:18.703470154 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
26: [rank26]:[W501 17:15:18.713535117 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
27: [rank27]:[W501 17:15:18.725833866 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
29: [rank29]:[W501 17:15:18.400801375 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
30: [rank30]:[W501 17:15:18.410862626 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
31: [rank31]:[W501 17:15:18.420983332 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
34: [rank34]:[W501 17:15:18.314240549 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
33: [rank33]:[W501 17:15:18.314280677 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
35: [rank35]:[W501 17:15:18.324332594 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
37: [rank37]:[W501 17:15:18.693512570 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
38: [rank38]:[W501 17:15:18.693584730 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
39: [rank39]:[W501 17:15:18.710548520 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
41: [rank41]:[W501 17:15:18.153137606 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
42: [rank42]:[W501 17:15:18.163054994 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
43: [rank43]:[W501 17:15:18.163067602 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
45: [rank45]:[W501 17:15:18.220832736 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
47: [rank47]:[W501 17:15:18.220892513 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
46: [rank46]:[W501 17:15:18.220954081 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
49: [rank49]:[W501 17:15:18.263387687 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
50: [rank50]:[W501 17:15:18.263460519 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
51: [rank51]:[W501 17:15:18.263611687 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
54: [rank54]:[W501 17:15:18.525034310 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
53: [rank53]:[W501 17:15:18.525063622 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
57: [rank57]:[W501 17:15:18.668061064 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
55: [rank55]:[W501 17:15:18.525143846 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
59: [rank59]:[W501 17:15:18.668214185 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
58: [rank58]:[W501 17:15:18.668235369 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
61: [rank61]:[W501 17:15:18.190852295 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
65: [rank65]:[W501 17:15:18.017461574 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
66: [rank66]:[W501 17:15:18.027459469 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
67: [rank67]:[W501 17:15:18.037423573 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
69: [rank69]:[W501 17:15:18.330240433 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
70: [rank70]:[W501 17:15:18.330364305 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
71: [rank71]:[W501 17:15:18.340431396 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
63: [rank63]:[W501 17:15:18.372024679 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
62: [rank62]:[W501 17:15:18.452512359 ProcessGroupNCCL.cpp:1477] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
 0: CKPT_PATH=/tmp/nemologs/stable-diffusion2-train-250501170821306610851-01/checkpoints/
 0: Using 16bit Automatic Mixed Precision (AMP)
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: setting number of microbatches to constant 1
51: Initializing distributed: GLOBAL_RANK: 51, MEMBER: 52/72
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/72
55: Initializing distributed: GLOBAL_RANK: 55, MEMBER: 56/72
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/72
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/72
38: Initializing distributed: GLOBAL_RANK: 38, MEMBER: 39/72
58: Initializing distributed: GLOBAL_RANK: 58, MEMBER: 59/72
54: Initializing distributed: GLOBAL_RANK: 54, MEMBER: 55/72
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/72
52: Initializing distributed: GLOBAL_RANK: 52, MEMBER: 53/72
37: Initializing distributed: GLOBAL_RANK: 37, MEMBER: 38/72
66: Initializing distributed: GLOBAL_RANK: 66, MEMBER: 67/72
36: Initializing distributed: GLOBAL_RANK: 36, MEMBER: 37/72
53: Initializing distributed: GLOBAL_RANK: 53, MEMBER: 54/72
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/72
41: Initializing distributed: GLOBAL_RANK: 41, MEMBER: 42/72
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/72
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/72
49: Initializing distributed: GLOBAL_RANK: 49, MEMBER: 50/72
61: Initializing distributed: GLOBAL_RANK: 61, MEMBER: 62/72
32: Initializing distributed: GLOBAL_RANK: 32, MEMBER: 33/72
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/72
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/72
63: Initializing distributed: GLOBAL_RANK: 63, MEMBER: 64/72
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/72
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/72
48: Initializing distributed: GLOBAL_RANK: 48, MEMBER: 49/72
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/72
60: Initializing distributed: GLOBAL_RANK: 60, MEMBER: 61/72
64: Initializing distributed: GLOBAL_RANK: 64, MEMBER: 65/72
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/72
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/72
46: Initializing distributed: GLOBAL_RANK: 46, MEMBER: 47/72
56: Initializing distributed: GLOBAL_RANK: 56, MEMBER: 57/72
59: Initializing distributed: GLOBAL_RANK: 59, MEMBER: 60/72
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/72
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/72
35: Initializing distributed: GLOBAL_RANK: 35, MEMBER: 36/72
34: Initializing distributed: GLOBAL_RANK: 34, MEMBER: 35/72
62: Initializing distributed: GLOBAL_RANK: 62, MEMBER: 63/72
71: Initializing distributed: GLOBAL_RANK: 71, MEMBER: 72/72
70: Initializing distributed: GLOBAL_RANK: 70, MEMBER: 71/72
67: Initializing distributed: GLOBAL_RANK: 67, MEMBER: 68/72
42: Initializing distributed: GLOBAL_RANK: 42, MEMBER: 43/72
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/72
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/72
47: Initializing distributed: GLOBAL_RANK: 47, MEMBER: 48/72
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/72
44: Initializing distributed: GLOBAL_RANK: 44, MEMBER: 45/72
68: Initializing distributed: GLOBAL_RANK: 68, MEMBER: 69/72
33: Initializing distributed: GLOBAL_RANK: 33, MEMBER: 34/72
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/72
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/72
65: Initializing distributed: GLOBAL_RANK: 65, MEMBER: 66/72
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/72
43: Initializing distributed: GLOBAL_RANK: 43, MEMBER: 44/72
69: Initializing distributed: GLOBAL_RANK: 69, MEMBER: 70/72
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/72
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/72
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/72
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/72
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/72
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/72
39: Initializing distributed: GLOBAL_RANK: 39, MEMBER: 40/72
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/72
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/72
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/72
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/72
50: Initializing distributed: GLOBAL_RANK: 50, MEMBER: 51/72
57: Initializing distributed: GLOBAL_RANK: 57, MEMBER: 58/72
45: Initializing distributed: GLOBAL_RANK: 45, MEMBER: 46/72
40: Initializing distributed: GLOBAL_RANK: 40, MEMBER: 41/72
 0: ----------------------------------------------------------------------------------------------------
 0: distributed_backend=nccl
 0: All distributed processes registered. Starting with 72 processes
 0: ----------------------------------------------------------------------------------------------------
 0: 
36: [rank36]:[W501 17:15:56.742394478 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 36]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
37: [rank37]:[W501 17:15:56.748584208 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 37]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
26: [rank26]:[W501 17:15:56.851189141 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 26]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
20: [rank20]:[W501 17:15:56.551450566 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 20]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
19: [rank19]:[W501 17:15:56.557282864 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 19]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 9: [rank9]:[W501 17:15:56.174559165 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
10: [rank10]:[W501 17:15:56.174553213 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
11: [rank11]:[W501 17:15:56.174553149 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 0: [rank0]:[W501 17:15:56.831358128 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 1: [rank1]:[W501 17:15:56.831396848 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
21: [rank21]:[W501 17:15:56.558268238 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 21]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
56: [rank56]:[W501 17:15:56.706436153 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 56]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
32: [rank32]:[W501 17:15:56.454965463 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 32]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 5: [rank5]:[W501 17:15:56.578182822 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
33: [rank33]:[W501 17:15:56.462421633 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 33]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
52: [rank52]:[W501 17:15:56.593305685 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 52]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
28: [rank28]:[W501 17:15:56.589275501 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 28]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
29: [rank29]:[W501 17:15:56.589275629 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 29]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
60: [rank60]:[W501 17:15:56.259854440 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 60]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
61: [rank61]:[W501 17:15:56.259887720 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 61]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
12: [rank12]:[W501 17:15:56.070248154 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 12]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
14: [rank14]:[W501 17:15:56.070248122 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 14]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 4: [rank4]:[W501 17:15:56.613453912 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
13: [rank13]:[W501 17:15:56.078062151 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 13]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
15: [rank15]:[W501 17:15:56.078113959 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 15]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
38: [rank38]:[W501 17:15:56.877365153 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 38]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
67: [rank67]:[W501 17:15:56.114710106 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 67]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
64: [rank64]:[W501 17:15:56.114761050 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 64]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
25: [rank25]:[W501 17:15:56.993870329 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 25]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
27: [rank27]:[W501 17:15:56.993870393 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 27]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 2: [rank2]:[W501 17:15:56.938970210 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
24: [rank24]:[W501 17:15:56.000412998 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 24]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
18: [rank18]:[W501 17:15:56.682252916 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 18]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
16: [rank16]:[W501 17:15:56.682352596 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 16]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
58: [rank58]:[W501 17:15:56.827166519 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 58]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
59: [rank59]:[W501 17:15:56.827168055 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 59]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
17: [rank17]:[W501 17:15:56.688713618 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 17]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
70: [rank70]:[W501 17:15:56.413768393 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 70]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
71: [rank71]:[W501 17:15:56.413752393 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 71]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
69: [rank69]:[W501 17:15:56.413897160 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 69]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
49: [rank49]:[W501 17:15:56.449503994 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 49]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
66: [rank66]:[W501 17:15:56.144686319 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 66]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
68: [rank68]:[W501 17:15:56.420505056 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 68]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 6: [rank6]:[W501 17:15:56.696881977 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 7: [rank7]:[W501 17:15:56.696917977 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
44: [rank44]:[W501 17:15:56.449827627 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 44]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
54: [rank54]:[W501 17:15:56.739316970 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 54]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
55: [rank55]:[W501 17:15:56.739506602 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 55]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
53: [rank53]:[W501 17:15:56.746914137 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 53]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
23: [rank23]:[W501 17:15:56.742881108 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 23]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
39: [rank39]:[W501 17:15:56.987935050 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 39]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
22: [rank22]:[W501 17:15:56.750845208 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 22]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
35: [rank35]:[W501 17:15:56.642032331 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 35]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
30: [rank30]:[W501 17:15:56.761177108 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 30]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
31: [rank31]:[W501 17:15:56.762134001 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 31]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
34: [rank34]:[W501 17:15:56.648520211 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 34]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
63: [rank63]:[W501 17:15:56.429514418 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 63]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
62: [rank62]:[W501 17:15:56.429833523 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 62]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 8: [rank8]:[W501 17:15:56.403679210 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 3: [rank3]:[W501 17:15:56.070957004 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
51: [rank51]:[W501 17:15:56.588291534 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 51]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
48: [rank48]:[W501 17:15:56.595033180 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 48]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
47: [rank47]:[W501 17:15:56.582174775 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 47]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
46: [rank46]:[W501 17:15:56.582191415 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 46]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
65: [rank65]:[W501 17:15:56.325870991 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 65]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
57: [rank57]:[W501 17:15:56.017287719 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 57]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
41: [rank41]:[W501 17:15:56.551668894 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 41]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
42: [rank42]:[W501 17:15:57.653295182 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 42]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
50: [rank50]:[W501 17:15:57.790032576 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 50]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
45: [rank45]:[W501 17:15:57.807979207 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 45]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
43: [rank43]:[W501 17:15:57.779812812 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 43]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
40: [rank40]:[W501 17:15:57.924532676 ProcessGroupNCCL.cpp:4751] [PG ID 0 PG GUID 0 Rank 40]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
 0: :::MLLOG {"namespace": "", "time_ms": 1746144960795, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1022976}}
 1: ninja: no work to do.
21: ninja: no work to do.
51: ninja: no work to do.
66: ninja: no work to do.
19: ninja: no work to do.
27: ninja: no work to do.
71: ninja: no work to do.
29: ninja: no work to do.
46: ninja: no work to do.
 5: ninja: no work to do.
59: ninja: no work to do.
11: ninja: no work to do.
36: ninja: no work to do.
43: ninja: no work to do.
49: ninja: no work to do.
63: ninja: no work to do.
15: ninja: no work to do.
32: ninja: no work to do.
52: ninja: no work to do.
39: ninja: no work to do.
18: ninja: no work to do.
 8: ninja: no work to do.
48: ninja: no work to do.
67: ninja: no work to do.
42: ninja: no work to do.
22: ninja: no work to do.
 2: ninja: no work to do.
69: ninja: no work to do.
24: ninja: no work to do.
44: ninja: no work to do.
31: ninja: no work to do.
 7: ninja: no work to do.
58: ninja: no work to do.
40: ninja: no work to do.
50: ninja: no work to do.
45: ninja: no work to do.
 0: :::MLLOG {"namespace": "", "time_ms": 1746145057311, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 146.37680582270832, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 194, "samples_count": 1022976, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145072545, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11993511766195297, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 224, "samples_count": 1022976, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145072546, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 235, "samples_count": 1022976}}
 0: Using 16bit Automatic Mixed Precision (AMP)
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: :::MLLOG {"namespace": "", "time_ms": 1746145086057, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1534464}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145167532, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 114.18644522375445, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 194, "samples_count": 1534464, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145182081, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.15158340334892273, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 224, "samples_count": 1534464, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145182081, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 235, "samples_count": 1534464}}
 0: Using 16bit Automatic Mixed Precision (AMP)
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: :::MLLOG {"namespace": "", "time_ms": 1746145194984, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2045952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145276744, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 84.86125511623237, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 194, "samples_count": 2045952, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145291207, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1743071973323822, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 224, "samples_count": 2045952, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746145291207, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 235, "samples_count": 2045952}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746144812726, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.12/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 3552}}
++ date +%s
+ echo 'RUNANDTIME_STOP 1746145296'
RUNANDTIME_STOP 1746145296
+ set -e
