+ echo 'Beginning trial 02 of 10'
Beginning trial 02 of 10
+ echo ':::DLPAL /home/nvcr.io+nvdlfwea+mlperftv50+bert-amd+20250423.sqsh 2 1 sys-a21ge-nbrt '\''unknown'\'' SYS-A21GE-NBRT_1x8x48x1_pack'
:::DLPAL /home/nvcr.io+nvdlfwea+mlperftv50+bert-amd+20250423.sqsh 2 1 sys-a21ge-nbrt 'unknown' SYS-A21GE-NBRT_1x8x48x1_pack
++ srun -N1 -n1 --container-name=language_model_2 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) GOLD 6548Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.8.0-58-generic","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) GOLD 6548Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.8.0-58-generic","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=language_model_2 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID 8c262b08b227bd43cefaeedd061fe71d67271031 
+ '[' 1 -eq 1 ']'
+ srun --ntasks-per-node=1 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on sys-a21ge-nbrt
vm.drop_caches = 3
+ srun --ntasks-per-node=1 --container-name=language_model_2 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1745468307136, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1745468307'
RUNANDTIME_START 1745468307
+ srun -l --mpi=none --ntasks-per-node=8 --time=12 --container-name=language_model_2 --no-container-mount-home --container-remap-root --container-writable --container-mounts=/mnt/raid0/bert/packed_data:/workspace/data_phase2,/mnt/raid0/bert/phase1:/workspace/phase1,/mnt/raid0/bert/hdf5/eval_varlength:/workspace/evaldata,/root/SYS-A21GE-NBRT/bert:/results --container-workdir=/workspace/bert --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
1: Run vars: id 2 gpus 8 mparams ''
0: Run vars: id 2 gpus 8 mparams ''
5: Run vars: id 2 gpus 8 mparams ''
4: Run vars: id 2 gpus 8 mparams ''
7: Run vars: id 2 gpus 8 mparams ''
6: Run vars: id 2 gpus 8 mparams ''
3: Run vars: id 2 gpus 8 mparams ''
2: Run vars: id 2 gpus 8 mparams ''
0: [W424 04:18:31.821126668 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: [W424 04:18:31.821131716 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [W424 04:18:31.821131093 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [W424 04:18:31.821133068 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: [W424 04:18:31.821132979 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
5: [W424 04:18:31.821133905 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
6: [W424 04:18:31.821131119 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: [W424 04:18:31.821135900 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
0:   warnings.warn(msg, DeprecatedFeatureWarning)
1: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
1:   warnings.warn(msg, DeprecatedFeatureWarning)
2: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
2:   warnings.warn(msg, DeprecatedFeatureWarning)
3: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
3:   warnings.warn(msg, DeprecatedFeatureWarning)
4: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
4:   warnings.warn(msg, DeprecatedFeatureWarning)
5: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
5:   warnings.warn(msg, DeprecatedFeatureWarning)
6: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
6:   warnings.warn(msg, DeprecatedFeatureWarning)
7: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
7:   warnings.warn(msg, DeprecatedFeatureWarning)
6: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
6:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
6: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
6:   warnings.warn(msg)
6: [W424 04:18:43.708741946 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
6: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
6:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
6: :::MLLOG {"namespace": "", "time_ms": 1745468323202, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
7: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
7:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
7: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
7:   warnings.warn(msg)
7: [W424 04:18:43.052762783 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
7:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
7: :::MLLOG {"namespace": "", "time_ms": 1745468323546, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
5: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
5:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
5: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
5:   warnings.warn(msg)
5: [W424 04:18:44.812907299 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
5: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
5:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
5: :::MLLOG {"namespace": "", "time_ms": 1745468324306, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
1: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
1:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
1: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
1:   warnings.warn(msg)
1: [W424 04:18:44.977792742 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
1:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
1: :::MLLOG {"namespace": "", "time_ms": 1745468324471, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
0: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
0:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
0: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
0:   warnings.warn(msg)
4: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
4:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
4: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
4:   warnings.warn(msg)
0: [W424 04:18:44.040900618 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: [W424 04:18:44.042754710 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
0:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
4: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
4:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
0: :::MLLOG {"namespace": "", "time_ms": 1745468324534, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
4: :::MLLOG {"namespace": "", "time_ms": 1745468324536, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
2: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
2:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
3: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
3:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
2: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
2:   warnings.warn(msg)
3: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
3:   warnings.warn(msg)
2: [W424 04:18:44.066079062 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [W424 04:18:44.066182538 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
2:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
3: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
3:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
2: :::MLLOG {"namespace": "", "time_ms": 1745468324559, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
3: :::MLLOG {"namespace": "", "time_ms": 1745468324559, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
6: [W424 04:18:45.418984035 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
6: device: cuda:6 n_gpu: 8, distributed training: True, 16-bits training: True
6: Torch distributed is available.
6: Torch distributed is initialized.
7: [W424 04:18:46.489910724 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
7: device: cuda:7 n_gpu: 8, distributed training: True, 16-bits training: True
7: Torch distributed is available.
7: Torch distributed is initialized.
2: [W424 04:18:47.822645507 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
4: [W424 04:18:47.822736512 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2: device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
4: device: cuda:4 n_gpu: 8, distributed training: True, 16-bits training: True
1: [W424 04:18:47.822996990 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
1: device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
5: [W424 04:18:47.823364631 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
5: device: cuda:5 n_gpu: 8, distributed training: True, 16-bits training: True
3: [W424 04:18:47.823848778 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
3: device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
0: [W424 04:18:47.828307502 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
0: device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "seed", "value": 32175, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1399}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 768, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1401}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1403}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327318, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1405}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327319, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1407}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327319, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 3680.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1409}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468327319, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1411}}
0: parsed args:
0: Namespace(input_dir='/workspace/data_phase2', packed_samples=True, order_samples=False, max_pack_factor=3, average_packing_rate=2, synthetic_input=False, bert_model='bert-large-uncased', cuda_graph_mode='segmented', max_iterations_per_graph=4, output_dir='/results', eval_dir='/workspace/evaldata', eval_iter_start_samples=150000, eval_iter_samples=150000, num_eval_examples=10000, cache_eval_data=True, load_eval_synchronously=False, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, max_seq_length=512, max_predictions_per_seq=76, train_batch_size=48, eval_batch_size=16, learning_rate=0.00096, weight_decay_rate=0.1, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, max_steps=3680.0, sustained_training_time=0, max_samples_termination=4500000.0, warmup_proportion=0.0, warmup_steps=0.0, start_warmup_step=0.0, local_rank=0, seed=32175, gradient_accumulation_steps=1, fp16=True, loss_scale=0.0, log_freq=0.0, checkpoint_activations=False, resume_from_checkpoint=False, keep_n_most_recent_c
0: heckpoints=20, num_samples_per_checkpoint=500000, min_samples_to_start_checkpoints=3000000, skip_checkpoint=True, phase2=True, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, do_train=True, exchange_padding=False, unpad=False, unpad_fmha=False, pad_fmha=True, pad=False, enable_fuse_dropout=False, disable_fuse_mask=False, disable_fuse_scale=False, disable_fuse_qkv=False, disable_apex_softmax=False, enable_stream=False, fused_gemm_gelu=True, fused_mha=False, fused_gelu_bias=False, fused_dropout_add=True, fused_bias_mha=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, dense_seq_output=True, use_env=False, bert_config_path='/workspace/phase1/bert_config.json', target_mlm_accuracy=0.72, train_mlm_accuracy_window_size=0, num_epochs_to_generate_seeds_for=2, use_cuda_graph=True, eval_cuda_graph=True, use_ddp=False, ddp_type='apex', use_gradient_as_bucket_view=False, bypass_amp=False, distributed_lamb=True, dwu_group_size=0, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_nu
0: m_ar_pg=1, dwu_num_ag_pg=1, dwu_overlap_reductions=False, dwu_e5m2_allgather=False, use_transformer_engine=False, use_transformer_engine2=True, n_gpu=8, device=device(type='cuda', index=0))
2: Torch distributed is available.
2: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
4: Torch distributed is available.
4: Torch distributed is initialized.
5: Torch distributed is available.
5: Torch distributed is initialized.
3: Torch distributed is available.
3: Torch distributed is initialized.
0: Torch distributed is available.
0: Torch distributed is initialized.
0: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
0:   warnings.warn(
2: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
2:   warnings.warn(
4: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
4:   warnings.warn(
7: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
7:   warnings.warn(
1: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
1:   warnings.warn(
3: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
3:   warnings.warn(
5: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
5:   warnings.warn(
6: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
6:   warnings.warn(
1: BertForPreTrainingSegmented(
1:   (bert_model_segment): BertForPreTrainingModelOnly(
1:     (bert): BertModel(
1:       (embeddings): BertEmbeddings(
1:         (word_embeddings): Embedding(30528, 1024)
1:         (position_embeddings): Embedding(512, 1024)
1:         (token_type_embeddings): Embedding(2, 1024)
1:         (LayerNorm): FastLayerNorm()
1:         (dropout): Dropout(p=0.1, inplace=False)
1:       )
1:       (encoder): BertEncoder(
1:         (layer): ModuleList(
1:           (0-23): 24 x BertTransformerLayer2(
1:             (attention): FP8_MHA()
1:             (layernorm_mlp): LayerNormMLP()
1:             (output_LayerNorm): FastLayerNorm()
1:           )
1:         )
1:       )
1:       (pooler): BertPooler(
1:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
1:         (activation): Tanh()
1:       )
1:     )
1:   )
1:   (heads_only_segment): BertForPreTrainingHeadsOnly(
1:     (cls): BertPreTrainingHeads(
1:       (predictions): BertLMPredictionHead(
1:         (transform): BertPredictionHeadTransform(
1:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
1:           (LayerNorm): FastLayerNorm()
1:         )
1:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
1:       )
1:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
1:     )
1:   )
1: )
3: BertForPreTrainingSegmented(
3:   (bert_model_segment): BertForPreTrainingModelOnly(
3:     (bert): BertModel(
3:       (embeddings): BertEmbeddings(
3:         (word_embeddings): Embedding(30528, 1024)
3:         (position_embeddings): Embedding(512, 1024)
3:         (token_type_embeddings): Embedding(2, 1024)
3:         (LayerNorm): FastLayerNorm()
3:         (dropout): Dropout(p=0.1, inplace=False)
3:       )
3:       (encoder): BertEncoder(
3:         (layer): ModuleList(
3:           (0-23): 24 x BertTransformerLayer2(
3:             (attention): FP8_MHA()
3:             (layernorm_mlp): LayerNormMLP()
3:             (output_LayerNorm): FastLayerNorm()
3:           )
3:         )
3:       )
3:       (pooler): BertPooler(
3:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
3:         (activation): Tanh()
3:       )
3:     )
3:   )
3:   (heads_only_segment): BertForPreTrainingHeadsOnly(
3:     (cls): BertPreTrainingHeads(
3:       (predictions): BertLMPredictionHead(
3:         (transform): BertPredictionHeadTransform(
3:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
3:           (LayerNorm): FastLayerNorm()
3:         )
3:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
3:       )
3:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
3:     )
3:   )
3: )
0: :::MLLOG {"namespace": "", "time_ms": 1745468332199, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/word_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332199, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/position_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332199, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/token_type_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
4: BertForPreTrainingSegmented(
4:   (bert_model_segment): BertForPreTrainingModelOnly(
4:     (bert): BertModel(
4:       (embeddings): BertEmbeddings(
4:         (word_embeddings): Embedding(30528, 1024)
4:         (position_embeddings): Embedding(512, 1024)
4:         (token_type_embeddings): Embedding(2, 1024)
4:         (LayerNorm): FastLayerNorm()
4:         (dropout): Dropout(p=0.1, inplace=False)
4:       )
4:       (encoder): BertEncoder(
4:         (layer): ModuleList(
4:           (0-23): 24 x BertTransformerLayer2(
4:             (attention): FP8_MHA()
4:             (layernorm_mlp): LayerNormMLP()
4:             (output_LayerNorm): FastLayerNorm()
4:           )
4:         )
4:       )
4:       (pooler): BertPooler(
4:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
4:         (activation): Tanh()
4:       )
4:     )
4:   )
4:   (heads_only_segment): BertForPreTrainingHeadsOnly(
4:     (cls): BertPreTrainingHeads(
4:       (predictions): BertLMPredictionHead(
4:         (transform): BertPredictionHeadTransform(
4:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
4:           (LayerNorm): FastLayerNorm()
4:         )
4:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
4:       )
4:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
4:     )
4:   )
4: )
7: BertForPreTrainingSegmented(
7:   (bert_model_segment): BertForPreTrainingModelOnly(
7:     (bert): BertModel(
7:       (embeddings): BertEmbeddings(
7:         (word_embeddings): Embedding(30528, 1024)
7:         (position_embeddings): Embedding(512, 1024)
7:         (token_type_embeddings): Embedding(2, 1024)
7:         (LayerNorm): FastLayerNorm()
7:         (dropout): Dropout(p=0.1, inplace=False)
7:       )
7:       (encoder): BertEncoder(
7:         (layer): ModuleList(
7:           (0-23): 24 x BertTransformerLayer2(
7:             (attention): FP8_MHA()
7:             (layernorm_mlp): LayerNormMLP()
7:             (output_LayerNorm): FastLayerNorm()
7:           )
7:         )
7:       )
7:       (pooler): BertPooler(
7:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
7:         (activation): Tanh()
7:       )
7:     )
7:   )
7:   (heads_only_segment): BertForPreTrainingHeadsOnly(
7:     (cls): BertPreTrainingHeads(
7:       (predictions): BertLMPredictionHead(
7:         (transform): BertPredictionHeadTransform(
7:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
7:           (LayerNorm): FastLayerNorm()
7:         )
7:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
7:       )
7:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
7:     )
7:   )
7: )
2: BertForPreTrainingSegmented(
2:   (bert_model_segment): BertForPreTrainingModelOnly(
2:     (bert): BertModel(
2:       (embeddings): BertEmbeddings(
2:         (word_embeddings): Embedding(30528, 1024)
2:         (position_embeddings): Embedding(512, 1024)
2:         (token_type_embeddings): Embedding(2, 1024)
2:         (LayerNorm): FastLayerNorm()
2:         (dropout): Dropout(p=0.1, inplace=False)
2:       )
2:       (encoder): BertEncoder(
2:         (layer): ModuleList(
2:           (0-23): 24 x BertTransformerLayer2(
2:             (attention): FP8_MHA()
2:             (layernorm_mlp): LayerNormMLP()
2:             (output_LayerNorm): FastLayerNorm()
2:           )
2:         )
2:       )
2:       (pooler): BertPooler(
2:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
2:         (activation): Tanh()
2:       )
2:     )
2:   )
2:   (heads_only_segment): BertForPreTrainingHeadsOnly(
2:     (cls): BertPreTrainingHeads(
2:       (predictions): BertLMPredictionHead(
2:         (transform): BertPredictionHeadTransform(
2:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
2:           (LayerNorm): FastLayerNorm()
2:         )
2:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
2:       )
2:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
2:     )
2:   )
2: )
5: BertForPreTrainingSegmented(
5:   (bert_model_segment): BertForPreTrainingModelOnly(
5:     (bert): BertModel(
5:       (embeddings): BertEmbeddings(
5:         (word_embeddings): Embedding(30528, 1024)
5:         (position_embeddings): Embedding(512, 1024)
5:         (token_type_embeddings): Embedding(2, 1024)
5:         (LayerNorm): FastLayerNorm()
5:         (dropout): Dropout(p=0.1, inplace=False)
5:       )
5:       (encoder): BertEncoder(
5:         (layer): ModuleList(
5:           (0-23): 24 x BertTransformerLayer2(
5:             (attention): FP8_MHA()
5:             (layernorm_mlp): LayerNormMLP()
5:             (output_LayerNorm): FastLayerNorm()
5:           )
5:         )
5:       )
5:       (pooler): BertPooler(
5:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
5:         (activation): Tanh()
5:       )
5:     )
5:   )
5:   (heads_only_segment): BertForPreTrainingHeadsOnly(
5:     (cls): BertPreTrainingHeads(
5:       (predictions): BertLMPredictionHead(
5:         (transform): BertPredictionHeadTransform(
5:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
5:           (LayerNorm): FastLayerNorm()
5:         )
5:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
5:       )
5:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
5:     )
5:   )
5: )
6: BertForPreTrainingSegmented(
6:   (bert_model_segment): BertForPreTrainingModelOnly(
6:     (bert): BertModel(
6:       (embeddings): BertEmbeddings(
6:         (word_embeddings): Embedding(30528, 1024)
6:         (position_embeddings): Embedding(512, 1024)
6:         (token_type_embeddings): Embedding(2, 1024)
6:         (LayerNorm): FastLayerNorm()
6:         (dropout): Dropout(p=0.1, inplace=False)
6:       )
6:       (encoder): BertEncoder(
6:         (layer): ModuleList(
6:           (0-23): 24 x BertTransformerLayer2(
6:             (attention): FP8_MHA()
6:             (layernorm_mlp): LayerNormMLP()
6:             (output_LayerNorm): FastLayerNorm()
6:           )
6:         )
6:       )
6:       (pooler): BertPooler(
6:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
6:         (activation): Tanh()
6:       )
6:     )
6:   )
6:   (heads_only_segment): BertForPreTrainingHeadsOnly(
6:     (cls): BertPreTrainingHeads(
6:       (predictions): BertLMPredictionHead(
6:         (transform): BertPredictionHeadTransform(
6:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
6:           (LayerNorm): FastLayerNorm()
6:         )
6:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
6:       )
6:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
6:     )
6:   )
6: )
0: :::MLLOG {"namespace": "", "time_ms": 1745468332200, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332203, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332205, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332206, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332209, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332212, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332216, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332218, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332219, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332220, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332221, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332222, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332223, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332225, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332226, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332227, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332228, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332229, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332230, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332231, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332232, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332233, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/pooler/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/pooler/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/output_bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/seq_relationship/output_weights"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468332240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/seq_relationship/output_bias"}}
0: BertForPreTrainingSegmented(
0:   (bert_model_segment): BertForPreTrainingModelOnly(
0:     (bert): BertModel(
0:       (embeddings): BertEmbeddings(
0:         (word_embeddings): Embedding(30528, 1024)
0:         (position_embeddings): Embedding(512, 1024)
0:         (token_type_embeddings): Embedding(2, 1024)
0:         (LayerNorm): FastLayerNorm()
0:         (dropout): Dropout(p=0.1, inplace=False)
0:       )
0:       (encoder): BertEncoder(
0:         (layer): ModuleList(
0:           (0-23): 24 x BertTransformerLayer2(
0:             (attention): FP8_MHA()
0:             (layernorm_mlp): LayerNormMLP()
0:             (output_LayerNorm): FastLayerNorm()
0:           )
0:         )
0:       )
0:       (pooler): BertPooler(
0:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
0:         (activation): Tanh()
0:       )
0:     )
0:   )
0:   (heads_only_segment): BertForPreTrainingHeadsOnly(
0:     (cls): BertPreTrainingHeads(
0:       (predictions): BertLMPredictionHead(
0:         (transform): BertPredictionHeadTransform(
0:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
0:           (LayerNorm): FastLayerNorm()
0:         )
0:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
0:       )
0:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
0:     )
0:   )
0: )
3: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
3:   self._overflow_buf = torch.cuda.IntTensor([0])
3: [rank3]:[W424 04:18:52.960727172 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
1: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
1:   self._overflow_buf = torch.cuda.IntTensor([0])
1: [rank1]:[W424 04:18:52.987563227 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
7: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
7:   self._overflow_buf = torch.cuda.IntTensor([0])
4: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
4:   self._overflow_buf = torch.cuda.IntTensor([0])
7: [rank7]:[W424 04:18:52.995441466 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
4: [rank4]:[W424 04:18:52.995665919 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
5: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
5:   self._overflow_buf = torch.cuda.IntTensor([0])
6: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
6:   self._overflow_buf = torch.cuda.IntTensor([0])
2: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
2:   self._overflow_buf = torch.cuda.IntTensor([0])
5: [rank5]:[W424 04:18:52.999207814 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
2: [rank2]:[W424 04:18:52.999656429 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
6: [rank6]:[W424 04:18:52.999661817 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1745468332519, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00096, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 991}}
0: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
0:   self._overflow_buf = torch.cuda.IntTensor([0])
0: [rank0]:[W424 04:18:52.032628428 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1745468334305, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1030}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334305, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1031}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334306, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.60466, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1033}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334306, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.85437, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1034}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334306, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1035}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334372, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334372, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468334372, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
4: Torch distributed is available.
4: Torch distributed is initialized.
7: Torch distributed is available.
7: Torch distributed is initialized.
5: Torch distributed is available.
5: Torch distributed is initialized.
2: Torch distributed is available.
2: Torch distributed is initialized.
6: Torch distributed is available.
6: Torch distributed is initialized.
3: Torch distributed is available.
3: Torch distributed is initialized.
0: Torch distributed is available.
0: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
4: Enabling make_graphed_callables for encoder!!
2: Enabling make_graphed_callables for encoder!!
1: Enabling make_graphed_callables for encoder!!
7: Enabling make_graphed_callables for encoder!!
5: Enabling make_graphed_callables for encoder!!
0: Enabling make_graphed_callables for encoder!!
6: Enabling make_graphed_callables for encoder!!
3: Enabling make_graphed_callables for encoder!!
0: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
6: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
4: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
5: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
1: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
3: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
7: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
2:   warnings.warn(
0: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
0:   warnings.warn(
1: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
1:   warnings.warn(
3: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
3:   warnings.warn(
4: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
4:   warnings.warn(
7: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
7:   warnings.warn(
5: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
5:   warnings.warn(
6: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
6:   warnings.warn(
0: :::MLLOG {"namespace": "", "time_ms": 1745468345172, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1783}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468345173, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1783}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468345206, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1805, "epoch_num": 0}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468345207, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1807, "first_epoch_num": 1, "epoch_count": 1}}
0: parsed args:
0: Namespace(input_dir='/workspace/data_phase2', packed_samples=True, order_samples=False, max_pack_factor=3, average_packing_rate=2, synthetic_input=False, bert_model='bert-large-uncased', cuda_graph_mode='segmented', max_iterations_per_graph=4, output_dir='/results', eval_dir='/workspace/evaldata', eval_iter_start_samples=150000, eval_iter_samples=150000, num_eval_examples=10000, cache_eval_data=True, load_eval_synchronously=False, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, max_seq_length=512, max_predictions_per_seq=76, train_batch_size=48, eval_batch_size=16, learning_rate=0.00096, weight_decay_rate=0.1, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, max_steps=3680.0, sustained_training_time=0, max_samples_termination=4500000.0, warmup_proportion=0.0, warmup_steps=0.0, start_warmup_step=0.0, local_rank=0, seed=32175, gradient_accumulation_steps=1, fp16=True, loss_scale=0.0, log_freq=0.0, checkpoint_activations=False, resume_from_checkpoint=False, keep_n_most_recent_c
0: heckpoints=20, num_samples_per_checkpoint=500000, min_samples_to_start_checkpoints=3000000, skip_checkpoint=True, phase2=True, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, do_train=True, exchange_padding=False, unpad=False, unpad_fmha=False, pad_fmha=True, pad=False, enable_fuse_dropout=False, disable_fuse_mask=False, disable_fuse_scale=False, disable_fuse_qkv=False, disable_apex_softmax=False, enable_stream=False, fused_gemm_gelu=True, fused_mha=False, fused_gelu_bias=False, fused_dropout_add=True, fused_bias_mha=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, dense_seq_output=True, use_env=False, bert_config_path='/workspace/phase1/bert_config.json', target_mlm_accuracy=0.72, train_mlm_accuracy_window_size=0, num_epochs_to_generate_seeds_for=2, use_cuda_graph=True, eval_cuda_graph=True, use_ddp=False, ddp_type='apex', use_gradient_as_bucket_view=False, bypass_amp=False, distributed_lamb=True, dwu_group_size=0, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_nu
0: m_ar_pg=1, dwu_num_ag_pg=1, dwu_overlap_reductions=False, dwu_e5m2_allgather=False, use_transformer_engine=False, use_transformer_engine2=True, n_gpu=8, device=device(type='cuda', index=0), resume_step=0)
0: epoch: 1
0: :::MLLOG {"namespace": "", "time_ms": 1745468345208, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_01680", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1844}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468358158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11600.75552219913}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 150232}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468358160, "event_type": "INTERVAL_START", "key": "eval_start", "value": 150232, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 150232}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468359149, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 150232, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 150232}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468359150, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.37855851650238037, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 150232}}
0: {'global_steps': 196, 'eval_loss': 4.063041687011719, 'eval_mlm_accuracy': 0.37855851650238037}
0: :::MLLOG {"namespace": "", "time_ms": 1745468371539, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11165.682067010914}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 299637}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468371540, "event_type": "INTERVAL_START", "key": "eval_start", "value": 299637, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 299637}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468372129, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 299637, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 299637}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468372130, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4080633223056793, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 299637}}
0: {'global_steps': 391, 'eval_loss': 3.781501293182373, 'eval_mlm_accuracy': 0.4080633223056793}
0: :::MLLOG {"namespace": "", "time_ms": 1745468384137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11873.001118940361}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 449214}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468384138, "event_type": "INTERVAL_START", "key": "eval_start", "value": 449214, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 449214}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468384726, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 449214, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 449214}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468384728, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.49173468351364136, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 449214}}
0: {'global_steps': 586, 'eval_loss': 3.06709623336792, 'eval_mlm_accuracy': 0.49173468351364136}
0: :::MLLOG {"namespace": "", "time_ms": 1745468397283, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11406.151828745777}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 599164}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468397285, "event_type": "INTERVAL_START", "key": "eval_start", "value": 599164, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 599164}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468397875, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 599164, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 599164}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468397876, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6473851799964905, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 599164}}
0: {'global_steps': 782, 'eval_loss': 1.8042783737182617, 'eval_mlm_accuracy': 0.6473851799964905}
0: :::MLLOG {"namespace": "", "time_ms": 1745468409901, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11854.601363358848}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 748737}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468409902, "event_type": "INTERVAL_START", "key": "eval_start", "value": 748737, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 748737}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468410490, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 748737, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 748737}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468410491, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.699912428855896, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 748737}}
0: {'global_steps': 977, 'eval_loss': 1.4307861328125, 'eval_mlm_accuracy': 0.699912428855896}
0: :::MLLOG {"namespace": "", "time_ms": 1745468423246, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11212.363356033627}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 898366}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468423247, "event_type": "INTERVAL_START", "key": "eval_start", "value": 898366, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 898366}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468423837, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 898366, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 898366}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468423838, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7076324820518494, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 898366}}
0: {'global_steps': 1172, 'eval_loss': 1.3790630102157593, 'eval_mlm_accuracy': 0.7076324820518494}
0: :::MLLOG {"namespace": "", "time_ms": 1745468436196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11642.663810865077}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1049142}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468436197, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1049142, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1049142}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468436786, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1049142, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1049142}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468436787, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7112730145454407, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1049142}}
0: {'global_steps': 1368, 'eval_loss': 1.3607697486877441, 'eval_mlm_accuracy': 0.7112730145454407}
0: :::MLLOG {"namespace": "", "time_ms": 1745468449297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11401.248906714645}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1198504}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468449298, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1198504, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1198504}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468449888, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1198504, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1198504}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468449889, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.713339626789093, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1198504}}
0: {'global_steps': 1563, 'eval_loss': 1.35029137134552, 'eval_mlm_accuracy': 0.713339626789093}
0: :::MLLOG {"namespace": "", "time_ms": 1745468461851, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11928.10472510238}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1348250}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468461852, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1348250, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1348250}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468462439, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1348250, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1348250}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468462441, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7147103548049927, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1348250}}
0: {'global_steps': 1758, 'eval_loss': 1.339077115058899, 'eval_mlm_accuracy': 0.7147103548049927}
0: :::MLLOG {"namespace": "", "time_ms": 1745468474981, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11451.055844828017}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1498611}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468474983, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1498611, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1498611}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468475574, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1498611, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1498611}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468475575, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7155954241752625, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1498611}}
0: {'global_steps': 1954, 'eval_loss': 1.333085060119629, 'eval_mlm_accuracy': 0.7155954241752625}
0: :::MLLOG {"namespace": "", "time_ms": 1745468487556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11894.485207756697}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1648177}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468487557, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1648177, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1648177}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468488146, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1648177, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1648177}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468488147, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7168633937835693, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1648177}}
0: {'global_steps': 2149, 'eval_loss': 1.3266315460205078, 'eval_mlm_accuracy': 0.7168633937835693}
0: :::MLLOG {"namespace": "", "time_ms": 1745468500668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11405.987827058903}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1797740}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468500670, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1797740, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1797740}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468501261, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1797740, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1797740}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468501262, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7172954082489014, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1797740}}
0: {'global_steps': 2344, 'eval_loss': 1.3217440843582153, 'eval_mlm_accuracy': 0.7172954082489014}
0: :::MLLOG {"namespace": "", "time_ms": 1745468513295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11949.996728789407}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1948629}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468513296, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1948629, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1948629}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468513883, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1948629, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1948629}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468513884, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7186918258666992, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1948629}}
0: {'global_steps': 2540, 'eval_loss': 1.3169857263565063, 'eval_mlm_accuracy': 0.7186918258666992}
0: :::MLLOG {"namespace": "", "time_ms": 1745468526406, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11402.576948097034}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2098123}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468526407, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2098123, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2098123}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468526999, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2098123, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2098123}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468527000, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7190747857093811, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2098123}}
0: {'global_steps': 2735, 'eval_loss': 1.3115891218185425, 'eval_mlm_accuracy': 0.7190747857093811}
0: :::MLLOG {"namespace": "", "time_ms": 1745468538987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11911.931204029725}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2247993}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468538988, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2247993, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2247993}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468539577, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2247993, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2247993}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468539578, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.719784677028656, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2247993}}
0: {'global_steps': 2930, 'eval_loss': 1.3081806898117065, 'eval_mlm_accuracy': 0.719784677028656}
0: :::MLLOG {"namespace": "", "time_ms": 1745468552090, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11405.937596946493}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2397442}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468552091, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2397442, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2397442}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468552682, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2397442, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2397442}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468552683, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7199785113334656, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2397442}}
0: {'global_steps': 3125, 'eval_loss': 1.3073277473449707, 'eval_mlm_accuracy': 0.7199785113334656}
0: :::MLLOG {"namespace": "", "time_ms": 1745468564730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11921.597579558429}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2548136}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468564731, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2548136, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2548136}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565319, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2548136, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2548136}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565320, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.720321774482727, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2548136}}
0: {'global_steps': 3321, 'eval_loss': 1.304202675819397, 'eval_mlm_accuracy': 0.720321774482727}
0: 0.720322 > 0.720000, Target MLM Accuracy reached at 3321
0: Training runs 3.843463043371836 mins sustained_training_time 0
0: (1, 3321.0) {'final_loss': 0.0}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565321, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2157, "first_epoch_num": 1}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565323, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2160, "epoch_num": 2548136}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565324, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2548136, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2162}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565325, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2165}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565326, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2168, "status": "success"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745468565328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11574.357654186302, "epoch_num": 2548136}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2207, "step": [2, 3321]}}
0: {'e2e_time': 241.05310535430908, 'training_sequences_per_second': 12255.613272949471, 'final_loss': 0.0, 'raw_train_time': 230.60779881477356}
++ date +%s
+ echo 'RUNANDTIME_STOP 1745468580'
RUNANDTIME_STOP 1745468580
+ set -e
