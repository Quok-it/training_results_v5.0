+ echo 'Beginning trial 5 of 10'
Beginning trial 5 of 10
+ echo ':::DLPAL nvcr.io/nvdlfwea/mlperftv50/bert-amd:20250423 143 1 localhost '\''unknown'\'' DGXB200_1x8x48x1_pack'
:::DLPAL nvcr.io/nvdlfwea/mlperftv50/bert-amd:20250423 143 1 localhost 'unknown' DGXB200_1x8x48x1_pack
++ srun -N1 -n1 --container-name=language_model_143 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"AMD EPYC 9575F 64-Core Processor","host_processor_core_count":"64","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-138-generic","nvidia_kernel_driver":"570.133.20"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"AMD EPYC 9575F 64-Core Processor","host_processor_core_count":"64","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-138-generic","nvidia_kernel_driver":"570.133.20"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=language_model_143 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID 8c262b08b227bd43cefaeedd061fe71d67271031 
+ '[' 1 -eq 1 ']'
+ srun --ntasks-per-node=1 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && echo '\''Super123'\'' | sudo -S /sbin/sysctl vm.drop_caches=3'
Clearing cache on as-a126gs-tnbr
vm.drop_caches = 3
[sudo] password for smci: + srun --ntasks-per-node=1 --container-name=language_model_143 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1745769145980, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1745769146'
RUNANDTIME_START 1745769146
+ srun -l --mpi=none --ntasks-per-node=8 --time=12 --container-name=language_model_143 --no-container-mount-home --container-remap-root --container-writable --container-mounts=/home/smci/mlperf-training-v50/dataset/bert/packed_data:/workspace/data_phase2,/home/smci/mlperf-training-v50/dataset/bert/phase1:/workspace/phase1,/home/smci/mlperf-training-v50/dataset/bert/hdf5/eval_varlength:/workspace/evaldata,/home/smci/mlperf-training-v50/logs/bert:/results --container-workdir=/workspace/bert --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
5: Run vars: id 143 gpus 8 mparams ''
6: Run vars: id 143 gpus 8 mparams ''
7: Run vars: id 143 gpus 8 mparams ''
4: Run vars: id 143 gpus 8 mparams ''
2: Run vars: id 143 gpus 8 mparams ''
3: Run vars: id 143 gpus 8 mparams ''
0: Run vars: id 143 gpus 8 mparams ''
1: Run vars: id 143 gpus 8 mparams ''
6: [W427 15:52:29.617098962 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
5: [W427 15:52:29.617143392 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: [W427 15:52:29.617238662 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
6: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
6:   warnings.warn(msg, DeprecatedFeatureWarning)
7: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
7:   warnings.warn(msg, DeprecatedFeatureWarning)
5: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
5:   warnings.warn(msg, DeprecatedFeatureWarning)
4: [W427 15:52:29.635800075 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
4:   warnings.warn(msg, DeprecatedFeatureWarning)
1: [W427 15:52:29.647556981 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [W427 15:52:29.648911040 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
1:   warnings.warn(msg, DeprecatedFeatureWarning)
3: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
3:   warnings.warn(msg, DeprecatedFeatureWarning)
0: [W427 15:52:29.655865868 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
0:   warnings.warn(msg, DeprecatedFeatureWarning)
2: [W427 15:52:29.726728552 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
2:   warnings.warn(msg, DeprecatedFeatureWarning)
0: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
0:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
0: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
0:   warnings.warn(msg)
0: [W427 15:52:40.165435573 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
0:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
0: :::MLLOG {"namespace": "", "time_ms": 1745769160703, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
6: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
6:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
6: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
6:   warnings.warn(msg)
6: [W427 15:52:40.346530587 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
6: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
6:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
6: :::MLLOG {"namespace": "", "time_ms": 1745769160881, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
5: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
5:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
5: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
5:   warnings.warn(msg)
5: [W427 15:52:41.682377805 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
5: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
5:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
5: :::MLLOG {"namespace": "", "time_ms": 1745769161217, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
1: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
1:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
1: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
1:   warnings.warn(msg)
1: [W427 15:52:41.693326271 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
1:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
1: :::MLLOG {"namespace": "", "time_ms": 1745769161228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
3: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
3:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
2: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
2:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
3: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
3:   warnings.warn(msg)
2: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
2:   warnings.warn(msg)
3: [W427 15:52:41.147877266 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [W427 15:52:41.147924076 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
2:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
3: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
3:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
3: :::MLLOG {"namespace": "", "time_ms": 1745769161683, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
2: :::MLLOG {"namespace": "", "time_ms": 1745769161683, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
7: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
7:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
7: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
7:   warnings.warn(msg)
7: [W427 15:52:41.222185089 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
7:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
7: :::MLLOG {"namespace": "", "time_ms": 1745769161757, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
4: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
4:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
4: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/NVIDIA/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
4:   warnings.warn(msg)
4: [W427 15:52:41.426634745 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
4:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
4: :::MLLOG {"namespace": "", "time_ms": 1745769161963, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
6: [W427 15:52:42.866314815 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
6: device: cuda:6 n_gpu: 8, distributed training: True, 16-bits training: True
6: Torch distributed is available.
6: Torch distributed is initialized.
2: [W427 15:52:44.147545155 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2: device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
2: Torch distributed is available.
2: Torch distributed is initialized.
1: [W427 15:52:44.176586325 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
1: device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
5: [W427 15:52:44.176931365 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
5: device: cuda:5 n_gpu: 8, distributed training: True, 16-bits training: True
7: [W427 15:52:44.181029443 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
7: device: cuda:7 n_gpu: 8, distributed training: True, 16-bits training: True
5: Torch distributed is available.
5: Torch distributed is initialized.
7: Torch distributed is available.
7: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
3: [W427 15:52:44.199269826 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
3: device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
3: Torch distributed is available.
3: Torch distributed is initialized.
4: [W427 15:52:44.204926584 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
4: device: cuda:4 n_gpu: 8, distributed training: True, 16-bits training: True
0: [W427 15:52:44.207007364 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
0: device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "seed", "value": 26458, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1399}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164740, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 768, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1401}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164741, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1403}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164741, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1405}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164741, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1407}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769164741, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 3680.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1409}}
4: Torch distributed is available.
4: Torch distributed is initialized.
0: :::MLLOG {"namespace": "", "time_ms": 1745769164741, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1411}}
0: parsed args:
0: Namespace(input_dir='/workspace/data_phase2', packed_samples=True, order_samples=False, max_pack_factor=3, average_packing_rate=2, synthetic_input=False, bert_model='bert-large-uncased', cuda_graph_mode='segmented', max_iterations_per_graph=4, output_dir='/results', eval_dir='/workspace/evaldata', eval_iter_start_samples=150000, eval_iter_samples=150000, num_eval_examples=10000, cache_eval_data=True, load_eval_synchronously=False, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, max_seq_length=512, max_predictions_per_seq=76, train_batch_size=48, eval_batch_size=16, learning_rate=0.00096, weight_decay_rate=0.1, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, max_steps=3680.0, sustained_training_time=0, max_samples_termination=4500000.0, warmup_proportion=0.0, warmup_steps=0.0, start_warmup_step=0.0, local_rank=0, seed=26458, gradient_accumulation_steps=1, fp16=True, loss_scale=0.0, log_freq=0.0, checkpoint_activations=False, resume_from_checkpoint=False, keep_n_most_recent_c
0: heckpoints=20, num_samples_per_checkpoint=500000, min_samples_to_start_checkpoints=3000000, skip_checkpoint=True, phase2=True, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, do_train=True, exchange_padding=False, unpad=False, unpad_fmha=False, pad_fmha=True, pad=False, enable_fuse_dropout=False, disable_fuse_mask=False, disable_fuse_scale=False, disable_fuse_qkv=False, disable_apex_softmax=False, enable_stream=False, fused_gemm_gelu=True, fused_mha=False, fused_gelu_bias=False, fused_dropout_add=True, fused_bias_mha=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, dense_seq_output=True, use_env=False, bert_config_path='/workspace/phase1/bert_config.json', target_mlm_accuracy=0.72, train_mlm_accuracy_window_size=0, num_epochs_to_generate_seeds_for=2, use_cuda_graph=True, eval_cuda_graph=True, use_ddp=False, ddp_type='apex', use_gradient_as_bucket_view=False, bypass_amp=False, distributed_lamb=True, dwu_group_size=0, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_nu
0: m_ar_pg=1, dwu_num_ag_pg=1, dwu_overlap_reductions=False, dwu_e5m2_allgather=False, use_transformer_engine=False, use_transformer_engine2=True, n_gpu=8, device=device(type='cuda', index=0))
0: Torch distributed is available.
0: Torch distributed is initialized.
0: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
0:   warnings.warn(
4: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
4:   warnings.warn(
3: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
3:   warnings.warn(
2: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
2:   warnings.warn(
6: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
6:   warnings.warn(
1: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
1:   warnings.warn(
7: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
7:   warnings.warn(
5: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
5:   warnings.warn(
1: BertForPreTrainingSegmented(
1:   (bert_model_segment): BertForPreTrainingModelOnly(
1:     (bert): BertModel(
1:       (embeddings): BertEmbeddings(
1:         (word_embeddings): Embedding(30528, 1024)
1:         (position_embeddings): Embedding(512, 1024)
1:         (token_type_embeddings): Embedding(2, 1024)
1:         (LayerNorm): FastLayerNorm()
1:         (dropout): Dropout(p=0.1, inplace=False)
1:       )
1:       (encoder): BertEncoder(
1:         (layer): ModuleList(
1:           (0-23): 24 x BertTransformerLayer2(
1:             (attention): FP8_MHA()
1:             (layernorm_mlp): LayerNormMLP()
1:             (output_LayerNorm): FastLayerNorm()
1:           )
1:         )
1:       )
1:       (pooler): BertPooler(
1:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
1:         (activation): Tanh()
1:       )
1:     )
1:   )
1:   (heads_only_segment): BertForPreTrainingHeadsOnly(
1:     (cls): BertPreTrainingHeads(
1:       (predictions): BertLMPredictionHead(
1:         (transform): BertPredictionHeadTransform(
1:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
1:           (LayerNorm): FastLayerNorm()
1:         )
1:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
1:       )
1:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
1:     )
1:   )
1: )
0: :::MLLOG {"namespace": "", "time_ms": 1745769169279, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/word_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169279, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/position_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/token_type_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
5: BertForPreTrainingSegmented(
5:   (bert_model_segment): BertForPreTrainingModelOnly(
5:     (bert): BertModel(
5:       (embeddings): BertEmbeddings(
5:         (word_embeddings): Embedding(30528, 1024)
5:         (position_embeddings): Embedding(512, 1024)
5:         (token_type_embeddings): Embedding(2, 1024)
5:         (LayerNorm): FastLayerNorm()
5:         (dropout): Dropout(p=0.1, inplace=False)
5:       )
5:       (encoder): BertEncoder(
5:         (layer): ModuleList(
5:           (0-23): 24 x BertTransformerLayer2(
5:             (attention): FP8_MHA()
5:             (layernorm_mlp): LayerNormMLP()
5:             (output_LayerNorm): FastLayerNorm()
5:           )
5:         )
5:       )
5:       (pooler): BertPooler(
5:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
5:         (activation): Tanh()
5:       )
5:     )
5:   )
5:   (heads_only_segment): BertForPreTrainingHeadsOnly(
5:     (cls): BertPreTrainingHeads(
5:       (predictions): BertLMPredictionHead(
5:         (transform): BertPredictionHeadTransform(
5:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
5:           (LayerNorm): FastLayerNorm()
5:         )
5:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
5:       )
5:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
5:     )
5:   )
5: )
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
6: BertForPreTrainingSegmented(
6:   (bert_model_segment): BertForPreTrainingModelOnly(
6:     (bert): BertModel(
6:       (embeddings): BertEmbeddings(
6:         (word_embeddings): Embedding(30528, 1024)
6:         (position_embeddings): Embedding(512, 1024)
6:         (token_type_embeddings): Embedding(2, 1024)
6:         (LayerNorm): FastLayerNorm()
6:         (dropout): Dropout(p=0.1, inplace=False)
6:       )
6:       (encoder): BertEncoder(
6:         (layer): ModuleList(
6:           (0-23): 24 x BertTransformerLayer2(
6:             (attention): FP8_MHA()
6:             (layernorm_mlp): LayerNormMLP()
6:             (output_LayerNorm): FastLayerNorm()
6:           )
6:         )
6:       )
6:       (pooler): BertPooler(
6:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
6:         (activation): Tanh()
6:       )
6:     )
6:   )
6:   (heads_only_segment): BertForPreTrainingHeadsOnly(
6:     (cls): BertPreTrainingHeads(
6:       (predictions): BertLMPredictionHead(
6:         (transform): BertPredictionHeadTransform(
6:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
6:           (LayerNorm): FastLayerNorm()
6:         )
6:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
6:       )
6:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
6:     )
6:   )
6: )
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
7: BertForPreTrainingSegmented(
7:   (bert_model_segment): BertForPreTrainingModelOnly(
7:     (bert): BertModel(
7:       (embeddings): BertEmbeddings(
7:         (word_embeddings): Embedding(30528, 1024)
7:         (position_embeddings): Embedding(512, 1024)
7:         (token_type_embeddings): Embedding(2, 1024)
7:         (LayerNorm): FastLayerNorm()
7:         (dropout): Dropout(p=0.1, inplace=False)
7:       )
7:       (encoder): BertEncoder(
7:         (layer): ModuleList(
7:           (0-23): 24 x BertTransformerLayer2(
7:             (attention): FP8_MHA()
7:             (layernorm_mlp): LayerNormMLP()
7:             (output_LayerNorm): FastLayerNorm()
7:           )
7:         )
7:       )
7:       (pooler): BertPooler(
7:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
7:         (activation): Tanh()
7:       )
7:     )
7:   )
7:   (heads_only_segment): BertForPreTrainingHeadsOnly(
7:     (cls): BertPreTrainingHeads(
7:       (predictions): BertLMPredictionHead(
7:         (transform): BertPredictionHeadTransform(
7:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
7:           (LayerNorm): FastLayerNorm()
7:         )
7:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
7:       )
7:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
7:     )
7:   )
7: )
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
3: BertForPreTrainingSegmented(
3:   (bert_model_segment): BertForPreTrainingModelOnly(
3:     (bert): BertModel(
3:       (embeddings): BertEmbeddings(
3:         (word_embeddings): Embedding(30528, 1024)
3:         (position_embeddings): Embedding(512, 1024)
3:         (token_type_embeddings): Embedding(2, 1024)
3:         (LayerNorm): FastLayerNorm()
3:         (dropout): Dropout(p=0.1, inplace=False)
3:       )
3:       (encoder): BertEncoder(
3:         (layer): ModuleList(
3:           (0-23): 24 x BertTransformerLayer2(
3:             (attention): FP8_MHA()
3:             (layernorm_mlp): LayerNormMLP()
3:             (output_LayerNorm): FastLayerNorm()
3:           )
3:         )
3:       )
3:       (pooler): BertPooler(
3:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
3:         (activation): Tanh()
3:       )
3:     )
3:   )
3:   (heads_only_segment): BertForPreTrainingHeadsOnly(
3:     (cls): BertPreTrainingHeads(
3:       (predictions): BertLMPredictionHead(
3:         (transform): BertPredictionHeadTransform(
3:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
3:           (LayerNorm): FastLayerNorm()
3:         )
3:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
3:       )
3:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
3:     )
3:   )
3: )
4: BertForPreTrainingSegmented(
4:   (bert_model_segment): BertForPreTrainingModelOnly(
4:     (bert): BertModel(
4:       (embeddings): BertEmbeddings(
4:         (word_embeddings): Embedding(30528, 1024)
4:         (position_embeddings): Embedding(512, 1024)
4:         (token_type_embeddings): Embedding(2, 1024)
4:         (LayerNorm): FastLayerNorm()
4:         (dropout): Dropout(p=0.1, inplace=False)
4:       )
4:       (encoder): BertEncoder(
4:         (layer): ModuleList(
4:           (0-23): 24 x BertTransformerLayer2(
4:             (attention): FP8_MHA()
4:             (layernorm_mlp): LayerNormMLP()
4:             (output_LayerNorm): FastLayerNorm()
4:           )
4:         )
4:       )
4:       (pooler): BertPooler(
4:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
4:         (activation): Tanh()
4:       )
4:     )
4:   )
4:   (heads_only_segment): BertForPreTrainingHeadsOnly(
4:     (cls): BertPreTrainingHeads(
4:       (predictions): BertLMPredictionHead(
4:         (transform): BertPredictionHeadTransform(
4:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
4:           (LayerNorm): FastLayerNorm()
4:         )
4:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
4:       )
4:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
4:     )
4:   )
4: )
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
2: BertForPreTrainingSegmented(
2:   (bert_model_segment): BertForPreTrainingModelOnly(
2:     (bert): BertModel(
2:       (embeddings): BertEmbeddings(
2:         (word_embeddings): Embedding(30528, 1024)
2:         (position_embeddings): Embedding(512, 1024)
2:         (token_type_embeddings): Embedding(2, 1024)
2:         (LayerNorm): FastLayerNorm()
2:         (dropout): Dropout(p=0.1, inplace=False)
2:       )
2:       (encoder): BertEncoder(
2:         (layer): ModuleList(
2:           (0-23): 24 x BertTransformerLayer2(
2:             (attention): FP8_MHA()
2:             (layernorm_mlp): LayerNormMLP()
2:             (output_LayerNorm): FastLayerNorm()
2:           )
2:         )
2:       )
2:       (pooler): BertPooler(
2:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
2:         (activation): Tanh()
2:       )
2:     )
2:   )
2:   (heads_only_segment): BertForPreTrainingHeadsOnly(
2:     (cls): BertPreTrainingHeads(
2:       (predictions): BertLMPredictionHead(
2:         (transform): BertPredictionHeadTransform(
2:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
2:           (LayerNorm): FastLayerNorm()
2:         )
2:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
2:       )
2:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
2:     )
2:   )
2: )
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169291, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169294, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169296, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169297, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169299, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/pooler/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/pooler/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/output_bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169300, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/seq_relationship/output_weights"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769169301, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/seq_relationship/output_bias"}}
0: BertForPreTrainingSegmented(
0:   (bert_model_segment): BertForPreTrainingModelOnly(
0:     (bert): BertModel(
0:       (embeddings): BertEmbeddings(
0:         (word_embeddings): Embedding(30528, 1024)
0:         (position_embeddings): Embedding(512, 1024)
0:         (token_type_embeddings): Embedding(2, 1024)
0:         (LayerNorm): FastLayerNorm()
0:         (dropout): Dropout(p=0.1, inplace=False)
0:       )
0:       (encoder): BertEncoder(
0:         (layer): ModuleList(
0:           (0-23): 24 x BertTransformerLayer2(
0:             (attention): FP8_MHA()
0:             (layernorm_mlp): LayerNormMLP()
0:             (output_LayerNorm): FastLayerNorm()
0:           )
0:         )
0:       )
0:       (pooler): BertPooler(
0:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
0:         (activation): Tanh()
0:       )
0:     )
0:   )
0:   (heads_only_segment): BertForPreTrainingHeadsOnly(
0:     (cls): BertPreTrainingHeads(
0:       (predictions): BertLMPredictionHead(
0:         (transform): BertPredictionHeadTransform(
0:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
0:           (LayerNorm): FastLayerNorm()
0:         )
0:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
0:       )
0:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
0:     )
0:   )
0: )
7: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
7:   self._overflow_buf = torch.cuda.IntTensor([0])
7: [rank7]:[W427 15:52:49.835367411 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
5: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
5:   self._overflow_buf = torch.cuda.IntTensor([0])
5: [rank5]:[W427 15:52:49.858568182 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
6: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
6:   self._overflow_buf = torch.cuda.IntTensor([0])
6: [rank6]:[W427 15:52:49.868476809 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1745769169415, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00096, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 991}}
0: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
0:   self._overflow_buf = torch.cuda.IntTensor([0])
0: [rank0]:[W427 15:52:49.885451623 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
1: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
1:   self._overflow_buf = torch.cuda.IntTensor([0])
1: [rank1]:[W427 15:52:49.928159487 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
2: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
2:   self._overflow_buf = torch.cuda.IntTensor([0])
4: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
4:   self._overflow_buf = torch.cuda.IntTensor([0])
3: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
3:   self._overflow_buf = torch.cuda.IntTensor([0])
2: [rank2]:[W427 15:52:49.937870284 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
3: [rank3]:[W427 15:52:49.938013614 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
4: [rank4]:[W427 15:52:49.938031354 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1745769171451, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1030}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171452, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1031}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171452, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.60466, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1033}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171452, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.85437, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1034}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171452, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1035}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171484, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171484, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769171485, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
7: Torch distributed is available.
7: Torch distributed is initialized.
5: Torch distributed is available.
5: Torch distributed is initialized.
0: Torch distributed is available.
0: Torch distributed is initialized.
6: Torch distributed is available.
6: Torch distributed is initialized.
3: Torch distributed is available.
3: Torch distributed is initialized.
4: Torch distributed is available.
4: Torch distributed is initialized.
2: Torch distributed is available.
2: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
7: Enabling make_graphed_callables for encoder!!
5: Enabling make_graphed_callables for encoder!!
6: Enabling make_graphed_callables for encoder!!
4: Enabling make_graphed_callables for encoder!!
0: Enabling make_graphed_callables for encoder!!
3: Enabling make_graphed_callables for encoder!!
1: Enabling make_graphed_callables for encoder!!
2: Enabling make_graphed_callables for encoder!!
4: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
0: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
1: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
3: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
5: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
7: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
6: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
3: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
3:   warnings.warn(
4: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
4:   warnings.warn(
2: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
2:   warnings.warn(
5: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
5:   warnings.warn(
1: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
1:   warnings.warn(
0: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
0:   warnings.warn(
6: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
6:   warnings.warn(
7: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
7:   warnings.warn(
0: :::MLLOG {"namespace": "", "time_ms": 1745769176741, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1783}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769176741, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1783}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769176764, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1805, "epoch_num": 0}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769176766, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1807, "first_epoch_num": 1, "epoch_count": 1}}
0: parsed args:
0: Namespace(input_dir='/workspace/data_phase2', packed_samples=True, order_samples=False, max_pack_factor=3, average_packing_rate=2, synthetic_input=False, bert_model='bert-large-uncased', cuda_graph_mode='segmented', max_iterations_per_graph=4, output_dir='/results', eval_dir='/workspace/evaldata', eval_iter_start_samples=150000, eval_iter_samples=150000, num_eval_examples=10000, cache_eval_data=True, load_eval_synchronously=False, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, max_seq_length=512, max_predictions_per_seq=76, train_batch_size=48, eval_batch_size=16, learning_rate=0.00096, weight_decay_rate=0.1, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, max_steps=3680.0, sustained_training_time=0, max_samples_termination=4500000.0, warmup_proportion=0.0, warmup_steps=0.0, start_warmup_step=0.0, local_rank=0, seed=26458, gradient_accumulation_steps=1, fp16=True, loss_scale=0.0, log_freq=0.0, checkpoint_activations=False, resume_from_checkpoint=False, keep_n_most_recent_c
0: heckpoints=20, num_samples_per_checkpoint=500000, min_samples_to_start_checkpoints=3000000, skip_checkpoint=True, phase2=True, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, do_train=True, exchange_padding=False, unpad=False, unpad_fmha=False, pad_fmha=True, pad=False, enable_fuse_dropout=False, disable_fuse_mask=False, disable_fuse_scale=False, disable_fuse_qkv=False, disable_apex_softmax=False, enable_stream=False, fused_gemm_gelu=True, fused_mha=False, fused_gelu_bias=False, fused_dropout_add=True, fused_bias_mha=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, dense_seq_output=True, use_env=False, bert_config_path='/workspace/phase1/bert_config.json', target_mlm_accuracy=0.72, train_mlm_accuracy_window_size=0, num_epochs_to_generate_seeds_for=2, use_cuda_graph=True, eval_cuda_graph=True, use_ddp=False, ddp_type='apex', use_gradient_as_bucket_view=False, bypass_amp=False, distributed_lamb=True, dwu_group_size=0, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_nu
0: m_ar_pg=1, dwu_num_ag_pg=1, dwu_overlap_reductions=False, dwu_e5m2_allgather=False, use_transformer_engine=False, use_transformer_engine2=True, n_gpu=8, device=device(type='cuda', index=0), resume_step=0)
0: epoch: 1
0: :::MLLOG {"namespace": "", "time_ms": 1745769176766, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_02969", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1844}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769189723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11614.11588217849}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 150484}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769189724, "event_type": "INTERVAL_START", "key": "eval_start", "value": 150484, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 150484}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769190663, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 150484, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 150484}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769190664, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.38043129444122314, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 150484}}
0: {'global_steps': 196, 'eval_loss': 4.053715705871582, 'eval_mlm_accuracy': 0.38043129444122314}
0: :::MLLOG {"namespace": "", "time_ms": 1745769203059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11245.679624750792}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 300460}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769203060, "event_type": "INTERVAL_START", "key": "eval_start", "value": 300460, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 300460}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769203644, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 300460, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 300460}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769203644, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4028535783290863, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 300460}}
0: {'global_steps': 391, 'eval_loss': 3.818850040435791, 'eval_mlm_accuracy': 0.4028535783290863}
0: :::MLLOG {"namespace": "", "time_ms": 1745769215590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11954.548097858256}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 450257}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769215591, "event_type": "INTERVAL_START", "key": "eval_start", "value": 450257, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 450257}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769216173, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 450257, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 450257}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769216173, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5048629641532898, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 450257}}
0: {'global_steps': 586, 'eval_loss': 2.9335458278656006, 'eval_mlm_accuracy': 0.5048629641532898}
0: :::MLLOG {"namespace": "", "time_ms": 1745769228587, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11558.456991990344}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 600488}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769228588, "event_type": "INTERVAL_START", "key": "eval_start", "value": 600488, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 600488}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769229172, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 600488, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 600488}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769229173, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6400901079177856, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 600488}}
0: {'global_steps': 782, 'eval_loss': 1.868666410446167, 'eval_mlm_accuracy': 0.6400901079177856}
0: :::MLLOG {"namespace": "", "time_ms": 1745769241118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11952.23842250116}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 750262}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769241119, "event_type": "INTERVAL_START", "key": "eval_start", "value": 750262, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 750262}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769241700, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 750262, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 750262}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769241701, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6992632746696472, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 750262}}
0: {'global_steps': 977, 'eval_loss': 1.4363484382629395, 'eval_mlm_accuracy': 0.6992632746696472}
0: :::MLLOG {"namespace": "", "time_ms": 1745769254670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11027.100342356469}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 899697}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769254671, "event_type": "INTERVAL_START", "key": "eval_start", "value": 899697, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 899697}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769255253, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 899697, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 899697}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769255253, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7078893780708313, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 899697}}
0: {'global_steps': 1172, 'eval_loss': 1.3863728046417236, 'eval_mlm_accuracy': 0.7078893780708313}
0: :::MLLOG {"namespace": "", "time_ms": 1745769267505, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11695.784798631741}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1049815}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769267506, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1049815, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1049815}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769268087, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1049815, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1049815}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769268088, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7115392088890076, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1049815}}
0: {'global_steps': 1368, 'eval_loss': 1.3602893352508545, 'eval_mlm_accuracy': 0.7115392088890076}
0: :::MLLOG {"namespace": "", "time_ms": 1745769280456, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11542.325174377022}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1199292}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769280456, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1199292, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1199292}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769281044, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1199292, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1199292}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769281045, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.713129460811615, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1199292}}
0: {'global_steps': 1563, 'eval_loss': 1.3478237390518188, 'eval_mlm_accuracy': 0.713129460811615}
0: :::MLLOG {"namespace": "", "time_ms": 1745769292986, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11920.933532780131}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1348671}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769292987, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1348671, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1348671}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769293569, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1348671, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1348671}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769293570, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7148715257644653, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1348671}}
0: {'global_steps': 1758, 'eval_loss': 1.3410794734954834, 'eval_mlm_accuracy': 0.7148715257644653}
0: :::MLLOG {"namespace": "", "time_ms": 1745769305971, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11598.986243492913}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1499283}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769305972, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1499283, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1499283}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769306556, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1499283, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1499283}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769306556, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7160857915878296, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1499283}}
0: {'global_steps': 1954, 'eval_loss': 1.3340555429458618, 'eval_mlm_accuracy': 0.7160857915878296}
0: :::MLLOG {"namespace": "", "time_ms": 1745769318521, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11908.417529160422}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1648734}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769318522, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1648734, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1648734}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769319104, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1648734, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1648734}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769319105, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.716812014579773, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1648734}}
0: {'global_steps': 2149, 'eval_loss': 1.3256745338439941, 'eval_mlm_accuracy': 0.716812014579773}
0: :::MLLOG {"namespace": "", "time_ms": 1745769331463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11548.954280007687}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1798196}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769331464, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1798196, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1798196}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769332046, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1798196, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1798196}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769332047, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7175055742263794, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1798196}}
0: {'global_steps': 2344, 'eval_loss': 1.322941541671753, 'eval_mlm_accuracy': 0.7175055742263794}
0: :::MLLOG {"namespace": "", "time_ms": 1745769344046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11940.154379224903}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1948434}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769344046, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1948434, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1948434}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769344632, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1948434, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1948434}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769344632, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7185984253883362, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1948434}}
0: {'global_steps': 2540, 'eval_loss': 1.3196008205413818, 'eval_mlm_accuracy': 0.7185984253883362}
0: :::MLLOG {"namespace": "", "time_ms": 1745769357006, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11579.122095249806}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2098504}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769357007, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2098504, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2098504}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769357591, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2098504, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2098504}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769357592, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7189813852310181, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2098504}}
0: {'global_steps': 2735, 'eval_loss': 1.3143126964569092, 'eval_mlm_accuracy': 0.7189813852310181}
0: :::MLLOG {"namespace": "", "time_ms": 1745769369553, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11961.105015883686}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2248582}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769369554, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2248582, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2248582}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769370136, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2248582, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2248582}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769370137, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.719702959060669, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2248582}}
0: {'global_steps': 2930, 'eval_loss': 1.3111318349838257, 'eval_mlm_accuracy': 0.719702959060669}
0: :::MLLOG {"namespace": "", "time_ms": 1745769382484, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11536.702042436194}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2397758}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769382484, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2397758, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2397758}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769383068, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2397758, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2397758}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769383069, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7199504971504211, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2397758}}
0: {'global_steps': 3125, 'eval_loss': 1.306992530822754, 'eval_mlm_accuracy': 0.7199504971504211}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395068, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11938.502099665591}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2548002}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395069, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2548002, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2548002}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395651, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2548002, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2548002}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395652, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7205809950828552, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2548002}}
0: {'global_steps': 3321, 'eval_loss': 1.3029364347457886, 'eval_mlm_accuracy': 0.7205809950828552}
0: 0.720581 > 0.720000, Target MLM Accuracy reached at 3321
0: Training runs 3.7330806692441305 mins sustained_training_time 0
0: (1, 3321.0) {'final_loss': 0.0}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395653, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2157, "first_epoch_num": 1}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395654, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2160, "epoch_num": 2548002}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395654, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2548002, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2162}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395655, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2165}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395656, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2168, "status": "success"}}
0: :::MLLOG {"namespace": "", "time_ms": 1745769395656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11639.243923359896, "epoch_num": 2548002}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2207, "step": [2, 3321]}}
0: {'e2e_time': 235.17281222343445, 'training_sequences_per_second': 12617.996319479293, 'final_loss': 0.0, 'raw_train_time': 223.98484897613525}
++ date +%s
+ echo 'RUNANDTIME_STOP 1745769404'
RUNANDTIME_STOP 1745769404
+ set -e
