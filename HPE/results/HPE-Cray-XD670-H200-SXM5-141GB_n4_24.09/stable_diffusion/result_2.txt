+ echo 'Beginning trial 04 of 15'
Beginning trial 04 of 15
+ echo ':::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32'
:::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32
++ srun --ntasks=1 --container-name=stable_diffusion_7260 mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=stable_diffusion_7260 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 -N4 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /usr/local/bin/drop_cache'
Clearing cache on sith4
Clearing cache on sith6
Clearing cache on sith5
Clearing cache on sith7
+ srun --ntasks=4 -N4 --mpi=pmi2 --container-name=stable_diffusion_7260 python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746946058390, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746946058390, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746946058399, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746946058433, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=26118
+ RANDOM_SEED=26118
+ export EXP_NAME=stable-diffusion2-train-250510231743609457887-04
+ EXP_NAME=stable-diffusion2-train-250510231743609457887-04
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746946058'
RUNANDTIME_START 1746946058
+ srun -l --mpi=pmi2 -N4 --cpu-bind=none --ntasks=32 --ntasks-per-node=8 --time=120 --container-name=stable_diffusion_7260 --container-mounts=/hpelustre/monnetb/mlcommons_mlperf_training/results/4-node-test-sd:/results,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion:/datasets,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion/checkpoints:/checkpoints,/hpelustre/monnetb/mlcommons_mlperf_training/SD-NEMO-monnetb/nemo-logs:/nemologs,/hpelustre/monnetb/mlcommons_mlperf_training/HPE/benchmarks/stable_diffusion/implementations/nemo-20250331:/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: STARTING TIMING RUN AT 2025-05-11 01:47:40 AM
 0: RANDOM_SEED=26118
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-e73r2c2y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-fzg353hw because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-zags6v7l because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-hr6szxbi because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-v9d4fokr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-vaceac92 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-cqi0fnbv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-ymb48a3g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-5fmn7gqm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-nmyq88tc because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-rrc1keiu because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-75zh34k0 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-q1uxptfd because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-1kjr5sc7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-zennokuv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-n_fju6vt because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-4ra7g_wn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-a30t0nvo because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-0zwjwpkm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-ed2fw9xc because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-tpe480_o because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-vvuq4v39 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-3hjiseiz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-air9rtnw because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-9hcsxmfy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-oieohhw3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-oe05byot because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-vwf9pqrd because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-so5ck303 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-f1yek0jd because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-lj7ejxim because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-b7ekc0e6 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 01:47:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
 0: :::MLLOG {"namespace": "", "time_ms": 1746946076732, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 77}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946077505, "event_type": "POINT_IN_TIME", "key": "seed", "value": 99347861, "metadata": {"file": "/workspace/sd/main.py", "lineno": 95}}
 0: [NeMo E 2025-05-11 01:47:57 exp_manager:652] You are running multi-node training without SLURM handling the processes. Please note that this is not tested in NeMo and could result in errors.
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105747, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 255}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105776, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 259}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105776, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 263}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105776, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105776, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105776, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 266}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105776, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 267}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00012288, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 269}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 276}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HPE", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946105777, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946166403, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946166405, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946166406, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946186795, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946186795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5022.384191254977}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946186796, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946209184, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946209184, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4573.919485884563}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946209185, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946231758, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946231758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4536.380999961354}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946231759, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946254433, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946254433, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4516.107845690532}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946254434, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946277143, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946277143, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4509.160179295042}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946279279, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946300055, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946300055, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4928.923025547031}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946300056, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946322874, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946322874, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4487.783379916281}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946322875, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946345705, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946345705, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4485.318620634659}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946345798, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946369447, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946369447, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4330.075578304447}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946369448, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946392295, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946392295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4481.983762811143}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946394548, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946415437, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946415437, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4902.048231995118}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946415438, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946438334, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946438335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4472.331302728026}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946438335, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946461252, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946461253, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4468.271876743121}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946461253, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946484152, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946484152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4471.816775624614}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946484153, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946507046, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946507046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4473.048110461131}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946509290, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946530174, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946530174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4903.2047976925505}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946530335, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946553899, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946553900, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4345.569298318752}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946553900, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946576805, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946576805, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4470.70548978268}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946576806, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946599732, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946599732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4466.57510337213}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946599733, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946622660, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946622660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4466.242623124473}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946624913, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946645831, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946645831, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4895.492034964571}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946645832, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946668767, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946668768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4464.704225971401}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946668768, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946691726, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946691726, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.3583727986415}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946691727, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946714656, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946714656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4465.947902991498}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946715050, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946737998, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946737998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.221525494069}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946740246, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946761166, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946761166, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4894.782988818212}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946761167, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946784126, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946784127, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.0073333549135}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946784127, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946807075, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946807075, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.27812602324}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946807076, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946830029, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946830030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.222634585441}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946830030, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946852991, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946852991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.790893620468}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946855240, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946876197, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946876197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4886.278420343348}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946876198, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946899184, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946899184, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4454.845817371523}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946899367, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946922169, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946922169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4490.894713190192}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946922170, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946945153, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946945154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4455.304700625617}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946945154, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946968144, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946968144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4454.111409312132}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946970393, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946991346, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946991346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4887.115389043651}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946991347, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947014331, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947014331, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4455.344559632906}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947014332, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947037331, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947037331, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4452.31212962115}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947037332, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947060320, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947060321, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4454.373284456861}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947060321, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947083328, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 4096000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947083329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4450.778893375654}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 4000}}
 8: [rank8]:[W511 02:04:50.917730201 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
16: [rank16]:[W511 02:04:50.279144370 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: [rank0]:[W511 02:04:50.075228052 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
24: [rank24]:[W511 02:04:50.107332198 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: [rank1]:[W511 02:04:50.178268735 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 2: [rank2]:[W511 02:04:50.197179366 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 3: [rank3]:[W511 02:04:50.207849173 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 4: [rank4]:[W511 02:04:50.217349292 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 5: [rank5]:[W511 02:04:50.217617554 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 6: [rank6]:[W511 02:04:50.227606589 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 7: [rank7]:[W511 02:04:50.237510085 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 9: [rank9]:[W511 02:04:50.215155432 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
11: [rank11]:[W511 02:04:50.215806132 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
12: [rank12]:[W511 02:04:50.215817148 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
13: [rank13]:[W511 02:04:50.215849405 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
10: [rank10]:[W511 02:04:50.215853810 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
14: [rank14]:[W511 02:04:50.216060028 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
15: [rank15]:[W511 02:04:50.226041277 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
17: [rank17]:[W511 02:04:50.514193186 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
18: [rank18]:[W511 02:04:50.514540026 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
19: [rank19]:[W511 02:04:50.524044472 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
20: [rank20]:[W511 02:04:50.534330367 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
21: [rank21]:[W511 02:04:50.534520100 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
22: [rank22]:[W511 02:04:50.544439594 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
23: [rank23]:[W511 02:04:50.544656164 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
25: [rank25]:[W511 02:04:50.305538183 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
26: [rank26]:[W511 02:04:50.305694293 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
27: [rank27]:[W511 02:04:50.315734729 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
28: [rank28]:[W511 02:04:50.315691934 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
29: [rank29]:[W511 02:04:50.315914334 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
30: [rank30]:[W511 02:04:50.325815743 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
31: [rank31]:[W511 02:04:50.326041583 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: Moving checkpoints to nemologs
 0: total 0
 0: drwxr-xr-x 4 monnetb users 300 May 11 01:51 stable-diffusion2-train-250510231743609457887-04
 0: CKPT_PATH=/nemologs/stable-diffusion2-train-250510231743609457887-04/checkpoints/
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-y5ddj0yr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-npwa8cfs because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-xhm6xwmr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-b4g31i7g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-mme3r_cn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-v0k6mjpu because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-6i76wykf because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-fzabln2t because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-8lbyw_q3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-9duvcgad because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-fbv6crbp because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-m32zqxfy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-dku9mfd1 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-o61nqt90 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-xdx8q5ur because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-ph_jog86 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-ws6b2h9c because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-erpcgz82 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-xjek_r1y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-smor0u56 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-mc5nfte3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-yga0zeoi because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-ob3y3pai because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-z3durivs because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-7id_ldxu because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-bzuwi3pa because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-mil3abzo because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-5g3q_1k8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-_g7ciwr_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-jdihrlho because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-9hq2_80u because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 02:05:17 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-nr6qlqji because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: setting number of microbatches to constant 1
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746947154949, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947431992, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947444476, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 215.08921857778114, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1024000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947457017, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06746373325586319, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1024000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947473352, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947750474, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947761123, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 149.41019474080645, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1536000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947773726, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.12084069103002548, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1536000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746947796796, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948074106, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948085852, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 111.75263375015464, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2048000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948098087, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1442815661430359, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2048000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948117573, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948394448, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948406389, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 99.74466899442768, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2560000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948418707, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.15463033318519592, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2560000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948434642, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948711237, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948723025, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 74.92676693091357, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 3072000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948735504, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.17808181047439575, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 3072000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746946852990, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 3000}}
 0: ENDING TIMING RUN AT 2025-05-11 02:32:18 AM
 0: RESULT,stable_diffusion,2678,HPE,2025-05-11 01:47:40 AM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746948741'
RUNANDTIME_STOP 1746948741
+ set -e
