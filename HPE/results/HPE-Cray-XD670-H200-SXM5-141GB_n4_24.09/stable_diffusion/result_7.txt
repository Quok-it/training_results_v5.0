+ echo 'Beginning trial 09 of 15'
Beginning trial 09 of 15
+ echo ':::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32'
:::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32
++ srun --ntasks=1 --container-name=stable_diffusion_7260 mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=stable_diffusion_7260 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 -N4 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /usr/local/bin/drop_cache'
Clearing cache on sith4
Clearing cache on sith6
Clearing cache on sith5
Clearing cache on sith7
+ srun --ntasks=4 -N4 --mpi=pmi2 --container-name=stable_diffusion_7260 python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746959872748, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746959872817, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746959872818, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746959872837, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=26123
+ RANDOM_SEED=26123
+ export EXP_NAME=stable-diffusion2-train-250510231743609457887-09
+ EXP_NAME=stable-diffusion2-train-250510231743609457887-09
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746959872'
RUNANDTIME_START 1746959872
+ srun -l --mpi=pmi2 -N4 --cpu-bind=none --ntasks=32 --ntasks-per-node=8 --time=120 --container-name=stable_diffusion_7260 --container-mounts=/hpelustre/monnetb/mlcommons_mlperf_training/results/4-node-test-sd:/results,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion:/datasets,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion/checkpoints:/checkpoints,/hpelustre/monnetb/mlcommons_mlperf_training/SD-NEMO-monnetb/nemo-logs:/nemologs,/hpelustre/monnetb/mlcommons_mlperf_training/HPE/benchmarks/stable_diffusion/implementations/nemo-20250331:/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: STARTING TIMING RUN AT 2025-05-11 05:37:54 AM
 0: RANDOM_SEED=26123
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-9i82gzb4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-syncvjp4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-u0tjpk71 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-2wcwvg5d because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-mlotrscs because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-depclxca because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-7cermh70 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-qpmy_i0s because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-5zs6dsq6 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-32lmo8c2 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-gh2ofnz7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-24yxhm3v because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-4lxxsnn2 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-a8dh3vzn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-csms18qk because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-2vmku4cv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-77y4awkh because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-upug7dzg because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-fd2s1f_g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-x9dxhsht because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-rhownzfd because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-ssvbr6vn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-fzqexxfn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-hxwf8wd0 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-51cv1_2n because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-th0zqje7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-t0bocbq4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-c5byyr6g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-_2fbyual because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-3mxuop7k because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-vd7rtap3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-eprc57_z because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 05:37:59 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
 0: :::MLLOG {"namespace": "", "time_ms": 1746959890833, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 77}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959891840, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1844583395, "metadata": {"file": "/workspace/sd/main.py", "lineno": 95}}
 0: [NeMo E 2025-05-11 05:38:11 exp_manager:652] You are running multi-node training without SLURM handling the processes. Please note that this is not tested in NeMo and could result in errors.
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920678, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 255}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920710, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 259}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920710, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 263}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 266}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 267}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00012288, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 269}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 276}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HPE", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959920711, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959983762, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959983764, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746959983765, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960003860, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960003860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5095.869168657242}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960003861, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960026271, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960026271, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4569.422424608025}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960026272, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960048815, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960048815, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4542.361856111901}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960048816, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960071452, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960071452, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4523.77437947206}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960071453, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960094157, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960094157, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4510.254794256586}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960096284, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960117022, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960117022, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4937.993515769852}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960117023, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960139810, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960139810, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4493.712151309379}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960139811, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960162617, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960162617, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4490.162058207525}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960163142, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960186784, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960186785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4331.264358746091}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960186786, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960209602, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960209602, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4487.942271627574}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960211850, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960232715, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960232715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4907.931080043979}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960232716, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960255598, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960255598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4475.0760994679}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960255599, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960278511, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960278511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.3141191421355}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960278512, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960301417, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960301417, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4470.643202117565}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960301418, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960324315, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960324315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4472.077346580453}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960326557, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960347440, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960347440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4903.511742421162}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960347640, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960370883, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960370883, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4405.8109167099055}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960370884, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960393793, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960393793, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.758883703822}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960393794, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960416691, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960416691, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4472.278029240298}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960416692, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960439591, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960439591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4471.700700938301}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960441834, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960462727, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960462728, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4900.973276354735}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960462728, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960485661, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960485662, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4465.162545793039}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960485662, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960508584, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960508584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4467.39311970435}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960508585, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960531508, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960531509, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4467.057873504977}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960531817, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960554845, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960554846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4446.692568845684}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960557092, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960578013, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960578014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4894.479911632523}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960578014, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960600973, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960600973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.125228213521}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960600974, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960623926, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960623926, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.576424112229}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960623927, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960646880, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960646880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.2015751766185}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960646881, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960669835, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960669835, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.068207157733}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960672083, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960693021, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960693021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4890.561018134595}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960693022, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960716004, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960716004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4455.635240763842}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960716175, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960738988, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960738988, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4488.727836186797}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960738989, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960761947, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960761947, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.384639507073}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960761948, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960784923, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960784923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4456.896965469657}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960787168, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960808086, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960808086, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4895.392013533563}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960808087, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960831046, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960831046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.154763941831}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960831047, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960853993, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960853993, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.663661279678}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960853994, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960876955, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960876956, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.566583628189}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960876957, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960899915, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 4096000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960899916, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.122091459615}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 4000}}
 8: [rank8]:[W511 05:55:07.477483370 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: [rank0]:[W511 05:55:07.576209921 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
16: [rank16]:[W511 05:55:07.835684554 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
24: [rank24]:[W511 05:55:07.681940425 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: [rank1]:[W511 05:55:07.727389264 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 2: [rank2]:[W511 05:55:07.747431332 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 3: [rank3]:[W511 05:55:07.747638482 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 4: [rank4]:[W511 05:55:07.757630154 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 5: [rank5]:[W511 05:55:07.776189598 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 6: [rank6]:[W511 05:55:07.777728604 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 7: [rank7]:[W511 05:55:07.788851796 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 9: [rank9]:[W511 05:55:07.766393164 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
10: [rank10]:[W511 05:55:07.766672658 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
11: [rank11]:[W511 05:55:07.776653566 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
12: [rank12]:[W511 05:55:07.776935222 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
14: [rank14]:[W511 05:55:07.787023907 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
13: [rank13]:[W511 05:55:07.787205912 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
15: [rank15]:[W511 05:55:07.797174833 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
17: [rank17]:[W511 05:55:07.094892966 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
18: [rank18]:[W511 05:55:07.095124007 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
19: [rank19]:[W511 05:55:07.095447263 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
20: [rank20]:[W511 05:55:07.105219110 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
21: [rank21]:[W511 05:55:07.105578476 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
22: [rank22]:[W511 05:55:07.105805108 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
23: [rank23]:[W511 05:55:07.105979566 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
25: [rank25]:[W511 05:55:07.876581643 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
26: [rank26]:[W511 05:55:07.876795332 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
27: [rank27]:[W511 05:55:07.877058075 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
28: [rank28]:[W511 05:55:07.886939440 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
29: [rank29]:[W511 05:55:07.887096287 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
30: [rank30]:[W511 05:55:07.897070003 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
31: [rank31]:[W511 05:55:07.897132202 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: Moving checkpoints to nemologs
 0: total 0
 0: drwxr-xr-x 5 monnetb users 280 May 11 05:41 stable-diffusion2-train-250510231743609457887-09
 0: CKPT_PATH=/nemologs/stable-diffusion2-train-250510231743609457887-09/checkpoints/
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-q7yu1k7o because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-wdhxovec because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-vs_red8u because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-tqxcqj2y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-b75lsjl2 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-fjfwf3yr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-x749xdho because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-wje18_il because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-c90843g0 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-a03wzvnx because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-npch94b8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-5r5k1x4p because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-jed8v4jn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-8oj50khs because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-530cgu6g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-7j1twfs2 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-jebsdy5a because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-t4s1psb1 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-c4lwq10u because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-kg9l7tvn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-fajqz1n3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-gt08w0wg because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-hah0zxup because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-c1qxxrid because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-zqb_egk4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-yn1b76z0 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-5oc2nxkl because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-y6k1kxf9 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-r7d6xqo4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-85eiuyo8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 05:55:33 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-xo3cies0 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-amvqemds because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: setting number of microbatches to constant 1
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746960970323, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961247379, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961259372, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 229.85797026743458, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1024000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961272275, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06676069647073746, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1024000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961288336, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961564568, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961576433, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 159.70279604977333, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1536000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961589309, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10199073702096939, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1536000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961612928, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961889450, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961901155, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 116.38633227006255, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2048000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961914272, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.12252327799797058, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2048000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746961933499, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962210179, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962222129, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 98.1740333894187, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2560000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962234565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1591181606054306, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2560000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962250280, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962526981, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962538490, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 90.0766247295989, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 3072000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962551009, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.15819677710533142, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 3072000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962567765, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962844915, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962856405, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 75.97236064664781, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 3584000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746962868851, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1760244518518448, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 3584000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746960784923, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 3500}}
 0: ENDING TIMING RUN AT 2025-05-11 06:27:53 AM
 0: RESULT,stable_diffusion,2999,HPE,2025-05-11 05:37:54 AM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746962874'
RUNANDTIME_STOP 1746962874
+ set -e
