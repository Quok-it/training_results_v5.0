+ echo 'Beginning trial 05 of 15'
Beginning trial 05 of 15
+ echo ':::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32'
:::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32
++ srun --ntasks=1 --container-name=stable_diffusion_7260 mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=stable_diffusion_7260 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 -N4 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /usr/local/bin/drop_cache'
Clearing cache on sith4
Clearing cache on sith5
Clearing cache on sith7
Clearing cache on sith6
+ srun --ntasks=4 -N4 --mpi=pmi2 --container-name=stable_diffusion_7260 python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746948819654, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746948819676, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746948819686, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746948819711, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=26119
+ RANDOM_SEED=26119
+ export EXP_NAME=stable-diffusion2-train-250510231743609457887-05
+ EXP_NAME=stable-diffusion2-train-250510231743609457887-05
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746948819'
RUNANDTIME_START 1746948819
+ srun -l --mpi=pmi2 -N4 --cpu-bind=none --ntasks=32 --ntasks-per-node=8 --time=120 --container-name=stable_diffusion_7260 --container-mounts=/hpelustre/monnetb/mlcommons_mlperf_training/results/4-node-test-sd:/results,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion:/datasets,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion/checkpoints:/checkpoints,/hpelustre/monnetb/mlcommons_mlperf_training/SD-NEMO-monnetb/nemo-logs:/nemologs,/hpelustre/monnetb/mlcommons_mlperf_training/HPE/benchmarks/stable_diffusion/implementations/nemo-20250331:/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: STARTING TIMING RUN AT 2025-05-11 02:33:41 AM
 0: RANDOM_SEED=26119
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-p324hukv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-lmw99adx because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-acq2ohpb because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-ap28kj9a because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-2hmhquom because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-90cdvnem because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-meq0qinv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-z3smi715 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-y_b73d44 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-0n0d7g9u because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-3mw5ymef because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-lifqugf4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-qm883w8y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-tvjqqlfj because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-1j7fksyi because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-aovqeo4x because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-sjtdchhc because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-bvk_wyp5 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-jao2aryz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-vpxq2913 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-kg5sr7ok because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-kkre6tiq because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-85gaqpay because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-9f97fqml because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-dwx8akxf because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-6uo5ced5 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-18yw3x9_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-93b4io90 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-gwlbntts because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-ph6tva2j because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-z_u8rel4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-oey4kcag because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 02:33:46 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
 0: :::MLLOG {"namespace": "", "time_ms": 1746948837820, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 77}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948838757, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2827272852, "metadata": {"file": "/workspace/sd/main.py", "lineno": 95}}
 0: [NeMo E 2025-05-11 02:33:58 exp_manager:652] You are running multi-node training without SLURM handling the processes. Please note that this is not tested in NeMo and could result in errors.
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866469, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 255}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866495, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 259}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 263}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 266}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 267}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00012288, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 269}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 276}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HPE", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948866496, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948927420, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948927421, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948927423, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948948337, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948948337, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4896.135666800835}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948948338, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948970760, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948970760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4566.921164800661}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948970761, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948993390, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948993390, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4525.160490223137}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746948993391, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949016085, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949016086, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4512.166170724164}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949016086, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949038854, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949038854, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4497.645537622947}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949040991, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949061792, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949061793, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4922.777576554563}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949061794, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949084617, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949084617, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4486.687034606655}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949084618, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949107468, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949107468, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4481.328334901484}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949107792, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949131106, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949131107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4392.235413233558}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949131107, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949153923, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949153923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4488.118112592903}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949156169, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949177056, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949177056, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4902.704588530739}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949177057, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949199972, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949199973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4468.521768755382}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949199973, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949222893, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949222893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4467.748565506159}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949222894, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949245797, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949245797, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4471.0934275017635}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949245798, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949268722, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949268723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4466.780717712454}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949270972, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949291865, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949291865, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4901.048863447033}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949292341, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949315258, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949315258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4468.393698458561}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949315258, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949338192, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949338193, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4464.978904897666}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949338193, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949361130, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949361130, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4464.448205405623}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949361131, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949384064, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949384065, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4465.115343185974}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949386312, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949407242, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949407242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4892.4760886638405}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949407243, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949430211, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949430212, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4458.341581414397}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949430212, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949453180, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949453181, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4458.369338865154}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949453182, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949476143, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949476143, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.577521612225}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949476258, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949499298, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949499298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4444.5955874753}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949501541, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949522446, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949522447, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4898.236910275861}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949522447, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949545358, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949545358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.5923696053505}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949545359, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949568294, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949568295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4464.642075232166}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949568295, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949591231, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949591232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4464.561205202329}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949591232, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949614175, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949614175, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4463.327743262336}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949616415, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949637360, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949637360, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4889.092552790242}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949637361, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949660346, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949660346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4455.007207899747}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949660631, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949683342, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949683343, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4508.829988353259}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949683343, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949706339, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949706339, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4453.080111130292}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949706340, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949729327, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949729327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4454.571897272713}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949731577, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949752511, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949752511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4891.601210046588}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949752512, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949775480, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949775480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4458.466279424508}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949775481, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949798446, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949798447, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4458.756411014668}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949798447, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949821405, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949821405, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.3508886831105}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949821406, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949844355, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 4096000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949844355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.156406826334}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 4000}}
 8: [rank8]:[W511 02:50:51.896483725 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
16: [rank16]:[W511 02:50:51.264918964 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: [rank0]:[W511 02:50:51.048005440 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
24: [rank24]:[W511 02:50:51.109413601 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: [rank1]:[W511 02:50:51.186889119 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 2: [rank2]:[W511 02:50:51.192325206 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 3: [rank3]:[W511 02:50:51.197821037 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 4: [rank4]:[W511 02:50:51.210742429 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 5: [rank5]:[W511 02:50:51.210909732 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 6: [rank6]:[W511 02:50:51.210952823 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 7: [rank7]:[W511 02:50:51.211081752 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 9: [rank9]:[W511 02:50:51.178552943 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
11: [rank11]:[W511 02:50:51.188619224 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
12: [rank12]:[W511 02:50:51.188816526 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
10: [rank10]:[W511 02:50:51.189075863 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
13: [rank13]:[W511 02:50:51.198850733 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
14: [rank14]:[W511 02:50:51.199029643 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
15: [rank15]:[W511 02:50:51.209179183 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
17: [rank17]:[W511 02:50:51.497336055 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
18: [rank18]:[W511 02:50:51.497611992 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
20: [rank20]:[W511 02:50:51.497682301 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
19: [rank19]:[W511 02:50:51.497766114 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
21: [rank21]:[W511 02:50:51.497808725 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
22: [rank22]:[W511 02:50:51.497922116 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
23: [rank23]:[W511 02:50:51.497927850 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
25: [rank25]:[W511 02:50:51.268907749 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
26: [rank26]:[W511 02:50:51.269196966 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
27: [rank27]:[W511 02:50:51.278946253 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
28: [rank28]:[W511 02:50:51.278987331 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
29: [rank29]:[W511 02:50:51.279070687 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
30: [rank30]:[W511 02:50:51.279134560 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
31: [rank31]:[W511 02:50:51.279361087 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: Moving checkpoints to nemologs
 0: total 0
 0: drwxr-xr-x 5 monnetb users 240 May 11 02:37 stable-diffusion2-train-250510231743609457887-05
 0: CKPT_PATH=/nemologs/stable-diffusion2-train-250510231743609457887-05/checkpoints/
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-rx1g7j6m because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-b68do2js because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-_u_bq_4l because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-isree00z because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-2na5qjug because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-q940h6mc because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-f_0tt2kl because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-p5akpw_z because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-h1kzoulm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-ees76cw6 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-nvlgujnr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-m0o1zb3d because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-8rcyl8rw because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-iw9o4z6r because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-0d0u6dwp because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-wvth_i_m because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-_p1faeab because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-t1c8ekt9 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-0tso7rjt because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-wz5v9v00 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-sjm2yisq because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-7vmq1279 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-h2rsf6mk because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-32alwnt7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-65svl5bj because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-7139t_gp because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-ai4_cem7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-tas3z64g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-tv6jdcmz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-0hm53_9y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-wxrrga4l because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-zgk5qdyo because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 02:51:19 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
 0: setting number of microbatches to constant 1
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746949920146, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950197506, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950209286, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 210.77699739289585, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1024000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950222018, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07369738072156906, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1024000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950241503, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950518326, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950529378, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 168.66565524319788, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1536000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950542569, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.100773386657238, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1536000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950558396, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950835229, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950846466, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 123.46694836864418, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2048000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950859413, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.13390758633613586, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2048000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746950876208, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951152938, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951163962, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 102.56175940284521, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2560000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951176742, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1601666659116745, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2560000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951200098, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951476520, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951487611, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 82.2247531196133, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 3072000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951500503, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1668228805065155, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 3072000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746949614174, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 3000}}
 0: ENDING TIMING RUN AT 2025-05-11 03:18:23 AM
 0: RESULT,stable_diffusion,2682,HPE,2025-05-11 02:33:41 AM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746951506'
RUNANDTIME_STOP 1746951506
+ set -e
