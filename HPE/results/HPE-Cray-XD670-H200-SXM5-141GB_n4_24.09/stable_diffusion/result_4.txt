+ echo 'Beginning trial 06 of 15'
Beginning trial 06 of 15
+ echo ':::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32'
:::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32
++ srun --ntasks=1 --container-name=stable_diffusion_7260 mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=stable_diffusion_7260 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 -N4 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /usr/local/bin/drop_cache'
Clearing cache on sith4
Clearing cache on sith7
Clearing cache on sith6
Clearing cache on sith5
+ srun --ntasks=4 -N4 --mpi=pmi2 --container-name=stable_diffusion_7260 python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746951585746, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746951585768, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746951585771, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746951585778, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=26120
+ RANDOM_SEED=26120
+ export EXP_NAME=stable-diffusion2-train-250510231743609457887-06
+ EXP_NAME=stable-diffusion2-train-250510231743609457887-06
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746951585'
RUNANDTIME_START 1746951585
+ srun -l --mpi=pmi2 -N4 --cpu-bind=none --ntasks=32 --ntasks-per-node=8 --time=120 --container-name=stable_diffusion_7260 --container-mounts=/hpelustre/monnetb/mlcommons_mlperf_training/results/4-node-test-sd:/results,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion:/datasets,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion/checkpoints:/checkpoints,/hpelustre/monnetb/mlcommons_mlperf_training/SD-NEMO-monnetb/nemo-logs:/nemologs,/hpelustre/monnetb/mlcommons_mlperf_training/HPE/benchmarks/stable_diffusion/implementations/nemo-20250331:/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: STARTING TIMING RUN AT 2025-05-11 03:19:47 AM
 0: RANDOM_SEED=26120
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-7ob3iupu because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-vfhgqr2_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-m9acnp92 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-ul5h7wr4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-i61esijj because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-scyus401 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-qghqm892 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-_zaylw74 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-zbckbfvq because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-_8uu3a5o because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-2amxp9t3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-bil6emy8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-xkirne8f because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-vkq6xccw because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-s8hhl5f2 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-pwykwknf because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-662lzot8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-wd2sge1p because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-lfud0jjy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-o3z8e3ps because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-_fcsx7s7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-yeij3dr3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-3nxjh2ad because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-v6c9k7so because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-45oh5bf2 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-thnsr315 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-vdntw9p3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-lfc380t1 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-s1p450oy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-qtre5ipv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-oyjxnvbb because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-5cl7p362 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 03:19:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
 0: :::MLLOG {"namespace": "", "time_ms": 1746951603973, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 77}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951605008, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1831393078, "metadata": {"file": "/workspace/sd/main.py", "lineno": 95}}
 0: [NeMo E 2025-05-11 03:20:05 exp_manager:652] You are running multi-node training without SLURM handling the processes. Please note that this is not tested in NeMo and could result in errors.
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633210, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 255}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633237, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 259}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 263}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 266}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 267}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00012288, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 269}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 276}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HPE", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951633238, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951694521, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951694523, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951694524, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951714622, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951714622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5095.037656584045}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951714623, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951737043, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951737043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4567.317461654768}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951737044, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951759645, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951759645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4530.839097675769}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951759646, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951782332, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951782333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4513.6934792843385}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951782333, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951805078, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951805078, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4502.158415447186}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951807217, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951828006, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951828006, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4925.804976169378}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951828007, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951850832, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951850833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4486.162846575794}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951850833, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951873666, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951873666, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4484.717434343764}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951874004, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951897175, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951897175, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4419.361537891605}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951897175, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951920031, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951920031, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4480.39526630971}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951922267, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951943132, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951943132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4907.889251233273}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951943133, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951966043, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951966043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.598952137571}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951966044, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951988969, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951988969, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4466.746026957024}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746951988970, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952011881, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952011881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.446147146081}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952011882, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952034803, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952034804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4467.40342496571}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952037045, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952057952, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952057953, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4897.8029387824145}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952058281, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952081158, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952081158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4476.157741338461}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952081159, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952104105, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952104105, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.676113675731}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952104106, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952127037, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952127037, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4465.483019354019}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952127038, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952149961, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952149961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4467.209572166956}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952152194, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952173097, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952173098, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4898.655456562531}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952173098, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952196053, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952196053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.039154810565}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952196054, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952219029, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952219029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4456.954692320894}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952219030, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952242002, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952242003, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4457.438470747554}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952242400, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952265417, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952265417, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4449.140664777371}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952267660, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952288591, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952288591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4892.179349911692}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952288592, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952311554, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952311554, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.610107794785}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952311555, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952334529, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952334530, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4457.026366415831}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952334531, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952357503, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952357503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4457.526547166251}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952357504, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952380467, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952380467, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.282797137162}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952382713, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952403668, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952403668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4886.861417226854}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952403669, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952426669, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952426670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4451.991768070193}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952426764, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952449796, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952449796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4446.025825206105}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952449797, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952472787, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952472788, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4454.028590532352}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952472788, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952495771, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952495771, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4455.517775255811}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952498019, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952518983, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952518983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4884.582419052935}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952518984, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952541960, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952541960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4456.869660654206}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952541961, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952564964, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952564964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4451.585892576282}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952564965, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952587959, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952587959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4453.23932308454}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952587960, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952610960, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 4096000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952610960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4452.168782588042}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 4000}}
 8: [rank8]:[W511 03:36:58.492052919 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
16: [rank16]:[W511 03:36:58.858224533 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: [rank0]:[W511 03:36:58.631771185 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
24: [rank24]:[W511 03:36:58.694078189 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: [rank1]:[W511 03:36:58.770328534 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 2: [rank2]:[W511 03:36:58.770428292 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 3: [rank3]:[W511 03:36:58.786219132 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 4: [rank4]:[W511 03:36:58.786422743 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 5: [rank5]:[W511 03:36:58.786671919 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 6: [rank6]:[W511 03:36:58.786975746 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 7: [rank7]:[W511 03:36:58.796812846 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 9: [rank9]:[W511 03:36:58.764391284 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
10: [rank10]:[W511 03:36:58.773791349 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
12: [rank12]:[W511 03:36:58.784029476 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
13: [rank13]:[W511 03:36:58.784256070 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
11: [rank11]:[W511 03:36:58.784406890 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
14: [rank14]:[W511 03:36:58.784424918 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
15: [rank15]:[W511 03:36:58.784472401 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
18: [rank18]:[W511 03:36:58.072762620 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
17: [rank17]:[W511 03:36:58.073210787 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
19: [rank19]:[W511 03:36:58.082650427 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
20: [rank20]:[W511 03:36:58.082810399 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
21: [rank21]:[W511 03:36:58.082908682 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
22: [rank22]:[W511 03:36:58.083068037 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
23: [rank23]:[W511 03:36:58.093130531 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
25: [rank25]:[W511 03:36:58.863729506 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
26: [rank26]:[W511 03:36:58.863999765 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
27: [rank27]:[W511 03:36:58.873806666 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
28: [rank28]:[W511 03:36:58.873847734 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
29: [rank29]:[W511 03:36:58.873919414 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
30: [rank30]:[W511 03:36:58.874089877 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
31: [rank31]:[W511 03:36:58.874287544 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: Moving checkpoints to nemologs
 0: total 0
 0: drwxr-xr-x 5 monnetb users 280 May 11 03:23 stable-diffusion2-train-250510231743609457887-06
 0: CKPT_PATH=/nemologs/stable-diffusion2-train-250510231743609457887-06/checkpoints/
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-1hyhvsq5 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-vk5jc0um because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-v1q5_7zz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-mtjo80o_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-8z766q16 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-5yd8cccm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-srq2vhky because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-1g03f1fa because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-_9i5xcl3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-isri36h4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-se9yi2oc because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-eyn5xnqp because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-5k5pdih3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-ay_wnky9 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-d9hcrcy3 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-s24hy2t_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-ne9a8jx8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-zy24jn72 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-vu5vntq9 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-hks0_k7o because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-vknj4t3y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-816k4kvc because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-zvju25hd because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-e2w5rbs7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-dmhtvumz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-b6x3prs4 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-dny8012o because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-rvjs8ige because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-lw5jw0iz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-o8xx3wkh because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-s2rzy_fr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 03:37:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-hmo3zozn because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: setting number of microbatches to constant 1
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746952682287, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952960381, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952971550, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 238.5847594709403, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1024000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952984098, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07374920696020126, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1024000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953000942, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953277730, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953288786, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 150.81769557447427, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1536000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953301151, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11676352471113205, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1536000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953325164, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953602363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953613205, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 123.01516764801198, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2048000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953625530, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1282992660999298, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2048000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953645371, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953922590, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953933444, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 96.96048956682932, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2560000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953945695, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1525527834892273, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2560000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746953961394, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746954237937, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746954249139, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 85.27469173290831, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 3072000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746954261550, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.16811324656009674, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 3072000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746952380466, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 3000}}
 0: ENDING TIMING RUN AT 2025-05-11 04:04:25 AM
 0: RESULT,stable_diffusion,2678,HPE,2025-05-11 03:19:47 AM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746954267'
RUNANDTIME_STOP 1746954267
+ set -e
