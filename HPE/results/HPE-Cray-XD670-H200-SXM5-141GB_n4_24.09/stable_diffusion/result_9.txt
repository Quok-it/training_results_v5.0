+ echo 'Beginning trial 11 of 15'
Beginning trial 11 of 15
+ echo ':::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32'
:::DLPAL /hpelustre/SHARED/containers/enroot/mlperftv50-sd-20250331.pytorch.sqsh 7260 4 sith[4-7] HPE Cray XD670 DGXH200_04x08x32
++ srun --ntasks=1 --container-name=stable_diffusion_7260 mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"HPE","division":"closed","status":"Available on-premise","system_name":"HPE Cray XD670","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.14.0-427.13.1.el9_4.x86_64","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=stable_diffusion_7260 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 -N4 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /usr/local/bin/drop_cache'
Clearing cache on sith4
Clearing cache on sith6
Clearing cache on sith7
Clearing cache on sith5
+ srun --ntasks=4 -N4 --mpi=pmi2 --container-name=stable_diffusion_7260 python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746965397453, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746965397521, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746965397525, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746965397528, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export RANDOM_SEED=26125
+ RANDOM_SEED=26125
+ export EXP_NAME=stable-diffusion2-train-250510231743609457887-11
+ EXP_NAME=stable-diffusion2-train-250510231743609457887-11
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746965397'
RUNANDTIME_START 1746965397
+ srun -l --mpi=pmi2 -N4 --cpu-bind=none --ntasks=32 --ntasks-per-node=8 --time=120 --container-name=stable_diffusion_7260 --container-mounts=/hpelustre/monnetb/mlcommons_mlperf_training/results/4-node-test-sd:/results,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion:/datasets,/hpelustre/SHARED/datasets/MLPERF/training5.0/stable-diffusion/checkpoints:/checkpoints,/hpelustre/monnetb/mlcommons_mlperf_training/SD-NEMO-monnetb/nemo-logs:/nemologs,/hpelustre/monnetb/mlcommons_mlperf_training/HPE/benchmarks/stable_diffusion/implementations/nemo-20250331:/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: STARTING TIMING RUN AT 2025-05-11 07:09:59 AM
 0: RANDOM_SEED=26125
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-229m0a86 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-_6v5qp06 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-64mio7y7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-voxii3cs because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-bclsvaf7 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-jq6zg69x because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-uzotbexe because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-l24qgy79 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-fndy_557 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-0fycnt42 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-m6lqdwkm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-5nkefmir because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-xnkz46pm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-bupbe5sy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-hdpzrxdd because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-tb7jbdwb because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-o_fpk6hy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-o1g4t1jr because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-f9w5fsvb because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-i6rsjnyz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-omrltrhv because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-tcsuwzxb because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-cl3l3kvg because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-9sofocl_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-zb0ka36c because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-9424u3_z because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-kcjibx2q because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-tyxnhb_g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-4nycss8c because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-5c8efgil because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-tdpolq7x because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-dofw1fsb because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 07:10:03 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
 0: :::MLLOG {"namespace": "", "time_ms": 1746965415523, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 77}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965416533, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2804291078, "metadata": {"file": "/workspace/sd/main.py", "lineno": 95}}
 0: [NeMo E 2025-05-11 07:10:16 exp_manager:652] You are running multi-node training without SLURM handling the processes. Please note that this is not tested in NeMo and could result in errors.
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445898, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 255}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445930, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 259}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 263}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 266}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 267}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00012288, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 269}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 275}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 276}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HPE", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965445931, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965506688, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965506690, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 405}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965506691, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965527232, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965527232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4985.201316962147}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965527233, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 102400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965549650, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965549651, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4567.847759666548}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965549652, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 204800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965572268, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965572269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4527.568622880028}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965572270, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 307200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965594959, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965594959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4513.183058216518}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965594960, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 409600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965617713, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965617713, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4500.514380855412}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965619847, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 512000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965640631, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965640632, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4926.9048865778495}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965640633, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 614400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965663467, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965663468, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4484.412408894077}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965663468, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 716800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965686305, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965686305, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4483.9571260272805}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965686758, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 819200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965710505, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965710505, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4312.101009013688}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965710506, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 921600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965733358, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965733358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4481.048018406292}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965735593, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965756453, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965756453, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4908.83766056485}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965756454, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1126400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965779350, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965779350, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4472.35810249068}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965779351, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1228800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965802262, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965802262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.436110609522}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965802263, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1331200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965825175, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965825175, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4469.281133025358}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965825176, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1433600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965848093, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965848093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4468.377038120079}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965850328, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965871210, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965871210, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4903.759185193732}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965871384, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1638400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965894849, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965894849, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4364.036944000019}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965894850, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1740800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965917766, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965917766, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4468.4958649423215}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965917767, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1843200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965940693, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965940693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4466.53766856784}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 1900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965940694, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 1945600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965963621, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965963621, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4466.280749919388}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965965862, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965986784, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965986784, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4894.363210707411}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746965986785, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2150400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966009749, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966009749, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.066055915852}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966009750, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2252800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966032705, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966032706, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.786571638541}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966032706, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2355200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966055655, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966055655, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.116292928048}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966055817, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2457600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966079071, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966079071, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4403.60799418431}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966081308, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966102229, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966102229, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4894.565438936298}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966102230, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2662400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966125185, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966125185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.920749298587}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966125186, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2764800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966148137, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966148137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.669469067419}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966148138, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2867200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966171083, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966171083, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.8088646104925}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 2900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966171084, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 2969600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966194021, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966194021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4464.4325868840415}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966196263, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966217208, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966217208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4888.968953303594}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3100}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966217209, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3174400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966240188, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966240188, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4456.117388224635}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966240454, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3276800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966263387, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966263387, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4465.218525349798}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3300}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966263388, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3379200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966286365, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966286365, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4456.62762355532}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966286366, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3481600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966309313, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966309313, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4462.545662162734}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3500}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966311561, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3584000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966332493, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966332493, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4891.9651337328205}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966332494, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3686400}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966355446, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966355446, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.533717501413}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3700}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966355447, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3788800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966378402, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966378402, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.750769091546}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3800}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966378403, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3891200}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966401354, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966401354, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.704472537215}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 3900}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966401355, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 415, "samples_count": 3993600}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966424315, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 449, "samples_count": 4096000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966424315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4459.960068086067}, "metadata": {"file": "/workspace/sd/callbacks.py", "lineno": 471, "step_num": 4000}}
 8: [rank8]:[W511 07:27:11.781482602 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: [rank0]:[W511 07:27:11.885638679 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
16: [rank16]:[W511 07:27:11.149841521 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
24: [rank24]:[W511 07:27:11.968915110 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: [rank1]:[W511 07:27:11.048317538 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 2: [rank2]:[W511 07:27:11.058325822 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 3: [rank3]:[W511 07:27:11.071759058 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 4: [rank4]:[W511 07:27:11.073324626 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 5: [rank5]:[W511 07:27:11.086344575 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 6: [rank6]:[W511 07:27:11.086450062 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 7: [rank7]:[W511 07:27:11.096449468 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 9: [rank9]:[W511 07:27:11.073587046 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
10: [rank10]:[W511 07:27:11.074048073 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
12: [rank12]:[W511 07:27:11.074212550 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
11: [rank11]:[W511 07:27:11.074879694 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
13: [rank13]:[W511 07:27:11.084317733 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
14: [rank14]:[W511 07:27:11.094202903 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
15: [rank15]:[W511 07:27:11.094465344 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
17: [rank17]:[W511 07:27:11.402786214 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
18: [rank18]:[W511 07:27:11.402933519 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
19: [rank19]:[W511 07:27:11.403296050 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
20: [rank20]:[W511 07:27:11.413142769 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
21: [rank21]:[W511 07:27:11.413235975 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
22: [rank22]:[W511 07:27:11.413199624 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
23: [rank23]:[W511 07:27:11.423327397 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
25: [rank25]:[W511 07:27:11.184096247 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
26: [rank26]:[W511 07:27:11.184152595 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
28: [rank28]:[W511 07:27:11.184281778 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
27: [rank27]:[W511 07:27:11.184359584 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
29: [rank29]:[W511 07:27:11.184333822 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
30: [rank30]:[W511 07:27:11.194504795 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
31: [rank31]:[W511 07:27:11.194685053 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: Moving checkpoints to nemologs
 0: total 0
 0: drwxr-xr-x 5 monnetb users 300 May 11 07:13 stable-diffusion2-train-250510231743609457887-11
 0: CKPT_PATH=/nemologs/stable-diffusion2-train-250510231743609457887-11/checkpoints/
22: Matplotlib created a temporary cache directory at /tmp/matplotlib-bch_l9mx because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 1: Matplotlib created a temporary cache directory at /tmp/matplotlib-luqtuuwz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12: Matplotlib created a temporary cache directory at /tmp/matplotlib-tjqjabg1 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
18: Matplotlib created a temporary cache directory at /tmp/matplotlib-jfcfwpdj because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
20: Matplotlib created a temporary cache directory at /tmp/matplotlib-i51zyv5r because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 5: Matplotlib created a temporary cache directory at /tmp/matplotlib-do_urx8d because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
21: Matplotlib created a temporary cache directory at /tmp/matplotlib-y5_wi9l0 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: Matplotlib created a temporary cache directory at /tmp/matplotlib-hvr4b84g because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 9: Matplotlib created a temporary cache directory at /tmp/matplotlib-ausb9bo8 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 3: Matplotlib created a temporary cache directory at /tmp/matplotlib-1y8jvuk_ because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
14: Matplotlib created a temporary cache directory at /tmp/matplotlib-_ux_te5f because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
10: Matplotlib created a temporary cache directory at /tmp/matplotlib-ecg1nsfo because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 6: Matplotlib created a temporary cache directory at /tmp/matplotlib-hzdtl56d because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 2: Matplotlib created a temporary cache directory at /tmp/matplotlib-r7apgyzy because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
16: Matplotlib created a temporary cache directory at /tmp/matplotlib-wchqyi_t because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
11: Matplotlib created a temporary cache directory at /tmp/matplotlib-soqgm5lq because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 8: Matplotlib created a temporary cache directory at /tmp/matplotlib-1m3eredx because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
23: Matplotlib created a temporary cache directory at /tmp/matplotlib-dac2dle9 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
19: Matplotlib created a temporary cache directory at /tmp/matplotlib-o3f3wh8e because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
25: Matplotlib created a temporary cache directory at /tmp/matplotlib-b3cbb7sk because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
13: Matplotlib created a temporary cache directory at /tmp/matplotlib-gjdga3qm because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
31: Matplotlib created a temporary cache directory at /tmp/matplotlib-4uenl8og because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
28: Matplotlib created a temporary cache directory at /tmp/matplotlib-edvjw3ui because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 4: Matplotlib created a temporary cache directory at /tmp/matplotlib-fsa3lojh because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
29: Matplotlib created a temporary cache directory at /tmp/matplotlib-5y1zch50 because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
26: Matplotlib created a temporary cache directory at /tmp/matplotlib-h6tf1sqz because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
27: Matplotlib created a temporary cache directory at /tmp/matplotlib-4nsqf0kf because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
30: Matplotlib created a temporary cache directory at /tmp/matplotlib-91c7l1it because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
17: Matplotlib created a temporary cache directory at /tmp/matplotlib-9sjypmyl because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
15: Matplotlib created a temporary cache directory at /tmp/matplotlib-udon5ypo because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 7: Matplotlib created a temporary cache directory at /tmp/matplotlib-fewi5vqh because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: [NeMo W 2025-05-11 07:27:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
 0:       warnings.warn(
 0:     
24: Matplotlib created a temporary cache directory at /tmp/matplotlib-iazuil0y because the default path (/home/users/monnetb/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
 0: setting number of microbatches to constant 1
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
 0: :::MLLOG {"namespace": "", "time_ms": 1746966499959, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966777669, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1024000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966790194, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 233.64457184082477, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1024000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966802279, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08418971300125122, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1024000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966819543, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967096315, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 1536000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967107405, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 162.4870856134164, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 1536000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967120405, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11893339455127716, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 1536000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967137065, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967413766, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2048000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967424969, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 108.87184898999243, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2048000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967438159, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.14378874003887177, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2048000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967462136, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967738479, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 2560000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967750269, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 97.96091048689004, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 2560000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967763174, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.159847229719162, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 2560000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746967783668, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 98, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746968060062, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 155, "samples_count": 3072000}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746968071277, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 79.16141027637588, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 199, "samples_count": 3072000, "metric": "FID"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746968084237, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.18016092479228973, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 229, "samples_count": 3072000, "metric": "CLIP"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1746966194020, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 3000}}
 0: ENDING TIMING RUN AT 2025-05-11 07:54:47 AM
 0: RESULT,stable_diffusion,2688,HPE,2025-05-11 07:09:59 AM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746968089'
RUNANDTIME_STOP 1746968089
+ set -e
