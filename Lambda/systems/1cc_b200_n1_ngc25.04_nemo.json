{
    "submitter": "Lambda",
    "division": "closed",
    "status": "Available cloud",
    "system_name": "Lambda-1-Click-Cluster_B200_n1",
    "number_of_nodes": "1",
    "host_processors_per_node": "2",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processor_core_count": "56",
    "host_processor_vcpu_count": "",
    "host_processor_frequency": "",
    "host_processor_caches": "",
    "host_processor_interconnect": "",
    "host_memory_capacity": "2.0 TB",
    "host_storage_type": "Local NVMe + Shared File System",
    "host_storage_capacity": "22 TB Local NVMe, Unlmited Shared File System",
    "host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "host_networking_topology": "Ethernet/Infiniband on switching network",
    "host_memory_configuration": "32x 64GB HMCG94AGBRA179N",
    "accelerators_per_node": "8",
    "accelerator_model_name": "NVIDIA Blackwell GPU (B200-SXM-180GB)",
    "accelerator_host_interconnect": "PCIe Gen5 x16",
    "accelerator_frequency": "",
    "accelerator_on-chip_memories": "",
    "accelerator_memory_configuration": "HBM3e",
    "accelerator_memory_capacity": "180 GB",
    "accelerator_interconnect": "18x 5th Gen NVLink, 14.4 TB/s aggregated bandwidth",
    "accelerator_interconnect_topology": "",
    "cooling": "Air-cooled",
    "hw_notes": "B200 1000W",
    "framework": "PyTorch NVIDIA Release 25.04",
    "framework_name": "ngc25.04_pytorch_nemo_2.0.0",
    "other_software_stack": {
        "cuda_version": "12.9.0.034",
        "cuda_driver_version": "575.50",
        "nccl_version": "2.26.3",
        "cublas_version": "12.9.0.2",
        "cudnn_version": "9.9.0.52",
        "trt_version": "10.9.0.34+cuda12.8",
        "dali_version": "1.48.0",
        "mofed_version": "5.4-rdmacore50.0",
        "openmpi_version": "4.1.7",
        "kernel_version": "Linux 6.8.0-52-generic",
        "nvidia_kernel_driver": "570.124.06"
    },
    "operating_system": "Ubuntu 24.04.2 LTS",
    "sw_notes": ""
}